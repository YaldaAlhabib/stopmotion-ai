<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.24">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>m2_training_testing_pix2pix â€“ Thesis Documentation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-e31584831b205ffbb2d98406f31c2a5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Thesis Documentation</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.ipynb"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-notebooks" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Notebooks</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-notebooks">    
        <li>
    <a class="dropdown-item" href="../notebooks/Results.html">
 <span class="dropdown-text">Results</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../notebooks/M1_training_testing_cycleGAN.html">
 <span class="dropdown-text">CycleGAN (M1)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../notebooks/M2_training_testing_pix2pix.html">
 <span class="dropdown-text">Pix2Pix (M2)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../notebooks/M3_training_testing_pix2pix.html">
 <span class="dropdown-text">Pix2Pix (M3)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../notebooks/M4_training_testing_pix2pix.html">
 <span class="dropdown-text">Pix2Pix (M4)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../notebooks/CycleGAN.html">
 <span class="dropdown-text">CycleGAN (core)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../notebooks/pix2pix.html">
 <span class="dropdown-text">Pix2Pix (core)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../notebooks/video_creation.html">
 <span class="dropdown-text">Video creation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../notebooks/Gradio_Setup.html">
 <span class="dropdown-text">Gradio setup</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<div id="68991ad4-dbbb-466f-bb9c-4135a1ba449d" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, math</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># === CONFIG ===</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>repo_dir <span class="op">=</span> <span class="vs">r"C:</span><span class="er">\</span><span class="vs">Users</span><span class="er">\</span><span class="vs">yalda</span><span class="er">\</span><span class="vs">OneDrive</span><span class="dv">\D</span><span class="vs">esktop</span><span class="er">\</span><span class="vs">Thesis apps</span><span class="er">\</span><span class="vs">Project Folder</span><span class="er">\</span><span class="vs">pytorch-CycleGAN-and-pix2pix"</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>srcA <span class="op">=</span> Path(repo_dir) <span class="op">/</span> <span class="st">"datasets"</span> <span class="op">/</span> <span class="st">"stopmotion"</span> <span class="op">/</span> <span class="st">"trainA"</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>srcB <span class="op">=</span> Path(repo_dir) <span class="op">/</span> <span class="st">"datasets"</span> <span class="op">/</span> <span class="st">"stopmotion"</span> <span class="op">/</span> <span class="st">"trainB"</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>out_root <span class="op">=</span> Path(repo_dir) <span class="op">/</span> <span class="st">"datasets"</span> <span class="op">/</span> <span class="st">"stopmotion_pix2pix"</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>out_train <span class="op">=</span> out_root <span class="op">/</span> <span class="st">"train"</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>out_test  <span class="op">=</span> out_root <span class="op">/</span> <span class="st">"test"</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>out_train.mkdir(parents<span class="op">=</span><span class="va">True</span>, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>out_test.mkdir(parents<span class="op">=</span><span class="va">True</span>, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>target_size <span class="op">=</span> <span class="dv">1024</span>     </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>test_ratio  <span class="op">=</span> <span class="fl">0.10</span>     </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> stemset(p):</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {p.name <span class="cf">for</span> p <span class="kw">in</span> p.glob(<span class="st">"*"</span>) <span class="cf">if</span> p.suffix.lower() <span class="kw">in</span> [<span class="st">".png"</span>, <span class="st">".jpg"</span>, <span class="st">".jpeg"</span>]}</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>filesA <span class="op">=</span> <span class="bu">sorted</span>([p <span class="cf">for</span> p <span class="kw">in</span> srcA.glob(<span class="st">"*"</span>) <span class="cf">if</span> p.suffix.lower() <span class="kw">in</span> [<span class="st">".png"</span>, <span class="st">".jpg"</span>, <span class="st">".jpeg"</span>]])</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>namesB <span class="op">=</span> stemset(srcB)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>pairs <span class="op">=</span> [ (a, srcB <span class="op">/</span> a.name) <span class="cf">for</span> a <span class="kw">in</span> filesA <span class="cf">if</span> a.name <span class="kw">in</span> namesB ]</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> pairs:</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">RuntimeError</span>(<span class="st">"No matching filenames between trainA and trainB. Make sure names match 1-to-1."</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>train_pairs, test_pairs <span class="op">=</span> train_test_split(pairs, test_size<span class="op">=</span>test_ratio, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> center_square_crop(im: Image.Image) <span class="op">-&gt;</span> Image.Image:</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    w, h <span class="op">=</span> im.size</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> <span class="bu">min</span>(w, h)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    left <span class="op">=</span> (w <span class="op">-</span> s) <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    top  <span class="op">=</span> (h <span class="op">-</span> s) <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> im.crop((left, top, left <span class="op">+</span> s, top <span class="op">+</span> s))</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prepare_AB(a_path: Path, b_path: Path) <span class="op">-&gt;</span> Image.Image:</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> Image.<span class="bu">open</span>(a_path).convert(<span class="st">"RGB"</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    B <span class="op">=</span> Image.<span class="bu">open</span>(b_path).convert(<span class="st">"RGB"</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> center_square_crop(A).resize((target_size, target_size), Image.BICUBIC)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    B <span class="op">=</span> center_square_crop(B).resize((target_size, target_size), Image.BICUBIC)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    AB <span class="op">=</span> Image.new(<span class="st">"RGB"</span>, (target_size <span class="op">*</span> <span class="dv">2</span>, target_size))</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>    AB.paste(A, (<span class="dv">0</span>, <span class="dv">0</span>))</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>    AB.paste(B, (target_size, <span class="dv">0</span>))</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> AB</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> export_split(pairs, out_dir: Path):</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> a_path, b_path <span class="kw">in</span> pairs:</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>        AB <span class="op">=</span> prepare_AB(a_path, b_path)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>        out_path <span class="op">=</span> out_dir <span class="op">/</span> (a_path.stem <span class="op">+</span> <span class="st">".png"</span>)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>        AB.save(out_path)</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Preparing </span><span class="sc">{</span><span class="bu">len</span>(train_pairs)<span class="sc">}</span><span class="ss"> train pairs and </span><span class="sc">{</span><span class="bu">len</span>(test_pairs)<span class="sc">}</span><span class="ss"> test pairs..."</span>)</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>export_split(train_pairs, out_train)</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>export_split(test_pairs, out_test)</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Done. Aligned dataset created at:"</span>, out_root)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Preparing 867 train pairs and 97 test pairs...
Done. Aligned dataset created at: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\datasets\stopmotion_pix2pix</code></pre>
</div>
</div>
<div id="c2de524c-c1c9-4cc2-a7dd-d1a2ed8d2400" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>pip install scikit<span class="op">-</span>learn</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Collecting scikit-learn
  Downloading scikit_learn-1.7.1-cp310-cp310-win_amd64.whl.metadata (11 kB)
Requirement already satisfied: numpy&gt;=1.22.0 in c:\users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages (from scikit-learn) (2.1.2)
Collecting scipy&gt;=1.8.0 (from scikit-learn)
  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)
Collecting joblib&gt;=1.2.0 (from scikit-learn)
  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)
Collecting threadpoolctl&gt;=3.1.0 (from scikit-learn)
  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)
Downloading scikit_learn-1.7.1-cp310-cp310-win_amd64.whl (8.9 MB)
   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--
   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--
   -- ------------------------------------- 0.5/8.9 MB 2.8 MB/s eta 0:00:04
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ---- ----------------------------------- 1.0/8.9 MB 3.0 MB/s eta 0:00:03
   ----- ---------------------------------- 1.3/8.9 MB 126.4 kB/s eta 0:01:01
   ----- ---------------------------------- 1.3/8.9 MB 126.4 kB/s eta 0:01:01
   ----- ---------------------------------- 1.3/8.9 MB 126.4 kB/s eta 0:01:01
   ----- ---------------------------------- 1.3/8.9 MB 126.4 kB/s eta 0:01:01
   ----- ---------------------------------- 1.3/8.9 MB 126.4 kB/s eta 0:01:01
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   ------- -------------------------------- 1.6/8.9 MB 140.5 kB/s eta 0:00:53
   -------- ------------------------------- 1.8/8.9 MB 112.0 kB/s eta 0:01:04
   -------- ------------------------------- 1.8/8.9 MB 112.0 kB/s eta 0:01:04
   -------- ------------------------------- 1.8/8.9 MB 112.0 kB/s eta 0:01:04
   -------- ------------------------------- 1.8/8.9 MB 112.0 kB/s eta 0:01:04
   --------- ------------------------------ 2.1/8.9 MB 123.1 kB/s eta 0:00:56
   --------- ------------------------------ 2.1/8.9 MB 123.1 kB/s eta 0:00:56
   --------- ------------------------------ 2.1/8.9 MB 123.1 kB/s eta 0:00:56
   --------- ------------------------------ 2.1/8.9 MB 123.1 kB/s eta 0:00:56
   --------- ------------------------------ 2.1/8.9 MB 123.1 kB/s eta 0:00:56
   --------- ------------------------------ 2.1/8.9 MB 123.1 kB/s eta 0:00:56
   ---------- ----------------------------- 2.4/8.9 MB 130.3 kB/s eta 0:00:51
   ----------- ---------------------------- 2.6/8.9 MB 144.8 kB/s eta 0:00:44
   ----------- ---------------------------- 2.6/8.9 MB 144.8 kB/s eta 0:00:44
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   ------------ --------------------------- 2.9/8.9 MB 156.1 kB/s eta 0:00:39
   -------------- ------------------------- 3.1/8.9 MB 128.8 kB/s eta 0:00:45
   -------------- ------------------------- 3.1/8.9 MB 128.8 kB/s eta 0:00:45
   --------------- ------------------------ 3.4/8.9 MB 138.2 kB/s eta 0:00:40
   ----------------- ---------------------- 3.9/8.9 MB 159.0 kB/s eta 0:00:32
   ------------------ --------------------- 4.2/8.9 MB 168.8 kB/s eta 0:00:28
   --------------------- ------------------ 4.7/8.9 MB 189.4 kB/s eta 0:00:23
   --------------------- ------------------ 4.7/8.9 MB 189.4 kB/s eta 0:00:23
   ----------------------- ---------------- 5.2/8.9 MB 208.5 kB/s eta 0:00:18
   ----------------------- ---------------- 5.2/8.9 MB 208.5 kB/s eta 0:00:18
   ------------------------ --------------- 5.5/8.9 MB 215.1 kB/s eta 0:00:16
   --------------------------- ------------ 6.0/8.9 MB 234.6 kB/s eta 0:00:13
   ---------------------------- ----------- 6.3/8.9 MB 243.5 kB/s eta 0:00:11
   ---------------------------- ----------- 6.3/8.9 MB 243.5 kB/s eta 0:00:11
   ----------------------------- ---------- 6.6/8.9 MB 249.3 kB/s eta 0:00:10
   ----------------------------- ---------- 6.6/8.9 MB 249.3 kB/s eta 0:00:10
   ----------------------------- ---------- 6.6/8.9 MB 249.3 kB/s eta 0:00:10
   ----------------------------- ---------- 6.6/8.9 MB 249.3 kB/s eta 0:00:10
   ----------------------------- ---------- 6.6/8.9 MB 249.3 kB/s eta 0:00:10
   ----------------------------- ---------- 6.6/8.9 MB 249.3 kB/s eta 0:00:10
   ----------------------------- ---------- 6.6/8.9 MB 249.3 kB/s eta 0:00:10
   ----------------------------- ---------- 6.6/8.9 MB 249.3 kB/s eta 0:00:10
   ----------------------------- ---------- 6.6/8.9 MB 249.3 kB/s eta 0:00:10
   ----------------------------- ---------- 6.6/8.9 MB 249.3 kB/s eta 0:00:10
   ------------------------------ --------- 6.8/8.9 MB 240.2 kB/s eta 0:00:09
   -------------------------------- ------- 7.3/8.9 MB 257.2 kB/s eta 0:00:07
   ----------------------------------- ---- 7.9/8.9 MB 274.0 kB/s eta 0:00:04
   ------------------------------------- -- 8.4/8.9 MB 290.4 kB/s eta 0:00:02
   ---------------------------------------- 8.9/8.9 MB 306.0 kB/s eta 0:00:00
Downloading joblib-1.5.1-py3-none-any.whl (307 kB)
Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)
   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--
   ---------------------------------------- 0.3/41.3 MB ? eta -:--:--
    --------------------------------------- 0.8/41.3 MB 2.4 MB/s eta 0:00:17
   - -------------------------------------- 1.3/41.3 MB 2.6 MB/s eta 0:00:16
   - -------------------------------------- 1.6/41.3 MB 2.1 MB/s eta 0:00:19
   -- ------------------------------------- 2.1/41.3 MB 2.1 MB/s eta 0:00:19
   -- ------------------------------------- 2.6/41.3 MB 2.2 MB/s eta 0:00:18
   -- ------------------------------------- 2.9/41.3 MB 2.2 MB/s eta 0:00:18
   --- ------------------------------------ 3.4/41.3 MB 2.1 MB/s eta 0:00:18
   --- ------------------------------------ 3.7/41.3 MB 2.0 MB/s eta 0:00:19
   --- ------------------------------------ 3.9/41.3 MB 1.9 MB/s eta 0:00:20
   --- ------------------------------------ 3.9/41.3 MB 1.9 MB/s eta 0:00:20
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.5/41.3 MB 1.8 MB/s eta 0:00:21
   ---- ----------------------------------- 4.7/41.3 MB 744.7 kB/s eta 0:00:50
   ---- ----------------------------------- 5.0/41.3 MB 758.9 kB/s eta 0:00:48
   ---- ----------------------------------- 5.0/41.3 MB 758.9 kB/s eta 0:00:48
   ---- ----------------------------------- 5.0/41.3 MB 758.9 kB/s eta 0:00:48
   ---- ----------------------------------- 5.0/41.3 MB 758.9 kB/s eta 0:00:48
   ---- ----------------------------------- 5.0/41.3 MB 758.9 kB/s eta 0:00:48
   ---- ----------------------------------- 5.0/41.3 MB 758.9 kB/s eta 0:00:48
   ---- ----------------------------------- 5.0/41.3 MB 758.9 kB/s eta 0:00:48
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.2/41.3 MB 644.0 kB/s eta 0:00:56
   ----- ---------------------------------- 5.5/41.3 MB 377.9 kB/s eta 0:01:35
   ----- ---------------------------------- 5.5/41.3 MB 377.9 kB/s eta 0:01:35
   ----- ---------------------------------- 5.5/41.3 MB 377.9 kB/s eta 0:01:35
   ----- ---------------------------------- 5.5/41.3 MB 377.9 kB/s eta 0:01:35
   ----- ---------------------------------- 5.8/41.3 MB 376.0 kB/s eta 0:01:35
   ----- ---------------------------------- 5.8/41.3 MB 376.0 kB/s eta 0:01:35
   ----- ---------------------------------- 5.8/41.3 MB 376.0 kB/s eta 0:01:35
   ----- ---------------------------------- 5.8/41.3 MB 376.0 kB/s eta 0:01:35
   ----- ---------------------------------- 5.8/41.3 MB 376.0 kB/s eta 0:01:35
   ----- ---------------------------------- 5.8/41.3 MB 376.0 kB/s eta 0:01:35
   ----- ---------------------------------- 6.0/41.3 MB 363.7 kB/s eta 0:01:37
   ------ --------------------------------- 6.3/41.3 MB 374.3 kB/s eta 0:01:34
   ------ --------------------------------- 6.3/41.3 MB 374.3 kB/s eta 0:01:34
   ------ --------------------------------- 6.3/41.3 MB 374.3 kB/s eta 0:01:34
   ------ --------------------------------- 6.3/41.3 MB 374.3 kB/s eta 0:01:34
   ------ --------------------------------- 6.6/41.3 MB 369.1 kB/s eta 0:01:35
   ------ --------------------------------- 6.6/41.3 MB 369.1 kB/s eta 0:01:35
   ------ --------------------------------- 6.6/41.3 MB 369.1 kB/s eta 0:01:35
   ------ --------------------------------- 6.6/41.3 MB 369.1 kB/s eta 0:01:35
   ------ --------------------------------- 6.6/41.3 MB 369.1 kB/s eta 0:01:35
   ------ --------------------------------- 6.8/41.3 MB 362.8 kB/s eta 0:01:35
   ------ --------------------------------- 7.1/41.3 MB 373.8 kB/s eta 0:01:32
   ------- -------------------------------- 7.3/41.3 MB 385.5 kB/s eta 0:01:28
   ------- -------------------------------- 7.9/41.3 MB 404.8 kB/s eta 0:01:23
   ------- -------------------------------- 8.1/41.3 MB 416.3 kB/s eta 0:01:20
   ------- -------------------------------- 8.1/41.3 MB 416.3 kB/s eta 0:01:20
   ------- -------------------------------- 8.1/41.3 MB 416.3 kB/s eta 0:01:20
   ------- -------------------------------- 8.1/41.3 MB 416.3 kB/s eta 0:01:20
   ------- -------------------------------- 8.1/41.3 MB 416.3 kB/s eta 0:01:20
   ------- -------------------------------- 8.1/41.3 MB 416.3 kB/s eta 0:01:20
   ------- -------------------------------- 8.1/41.3 MB 416.3 kB/s eta 0:01:20
   ------- -------------------------------- 8.1/41.3 MB 416.3 kB/s eta 0:01:20
   ------- -------------------------------- 8.1/41.3 MB 416.3 kB/s eta 0:01:20
   ------- -------------------------------- 8.1/41.3 MB 416.3 kB/s eta 0:01:20
   ------- -------------------------------- 8.1/41.3 MB 416.3 kB/s eta 0:01:20
   ------- -------------------------------- 8.1/41.3 MB 416.3 kB/s eta 0:01:20
   ------- -------------------------------- 8.1/41.3 MB 416.3 kB/s eta 0:01:20
   ------- -------------------------------- 8.1/41.3 MB 416.3 kB/s eta 0:01:20
   -------- ------------------------------- 8.4/41.3 MB 373.4 kB/s eta 0:01:29
   -------- ------------------------------- 8.7/41.3 MB 382.1 kB/s eta 0:01:26
   -------- ------------------------------- 8.9/41.3 MB 388.5 kB/s eta 0:01:24
   -------- ------------------------------- 8.9/41.3 MB 388.5 kB/s eta 0:01:24
   -------- ------------------------------- 9.2/41.3 MB 394.8 kB/s eta 0:01:22
   -------- ------------------------------- 9.2/41.3 MB 394.8 kB/s eta 0:01:22
   --------- ------------------------------ 9.4/41.3 MB 397.3 kB/s eta 0:01:21
   --------- ------------------------------ 9.4/41.3 MB 397.3 kB/s eta 0:01:21
   --------- ------------------------------ 9.4/41.3 MB 397.3 kB/s eta 0:01:21
   --------- ------------------------------ 9.4/41.3 MB 397.3 kB/s eta 0:01:21
   --------- ------------------------------ 9.7/41.3 MB 394.2 kB/s eta 0:01:21
   --------- ------------------------------ 9.7/41.3 MB 394.2 kB/s eta 0:01:21
   --------- ------------------------------ 9.7/41.3 MB 394.2 kB/s eta 0:01:21
   --------- ------------------------------ 9.7/41.3 MB 394.2 kB/s eta 0:01:21
   --------- ------------------------------ 9.7/41.3 MB 394.2 kB/s eta 0:01:21
   --------- ------------------------------ 9.7/41.3 MB 394.2 kB/s eta 0:01:21
   --------- ------------------------------ 9.7/41.3 MB 394.2 kB/s eta 0:01:21
   --------- ------------------------------ 9.7/41.3 MB 394.2 kB/s eta 0:01:21
   --------- ------------------------------ 9.7/41.3 MB 394.2 kB/s eta 0:01:21
   --------- ------------------------------ 10.0/41.3 MB 375.5 kB/s eta 0:01:24
   --------- ------------------------------ 10.0/41.3 MB 375.5 kB/s eta 0:01:24
   --------- ------------------------------ 10.0/41.3 MB 375.5 kB/s eta 0:01:24
   --------- ------------------------------ 10.0/41.3 MB 375.5 kB/s eta 0:01:24
   --------- ------------------------------ 10.2/41.3 MB 374.1 kB/s eta 0:01:23
   --------- ------------------------------ 10.2/41.3 MB 374.1 kB/s eta 0:01:23
   --------- ------------------------------ 10.2/41.3 MB 374.1 kB/s eta 0:01:23
   --------- ------------------------------ 10.2/41.3 MB 374.1 kB/s eta 0:01:23
   --------- ------------------------------ 10.2/41.3 MB 374.1 kB/s eta 0:01:23
   --------- ------------------------------ 10.2/41.3 MB 374.1 kB/s eta 0:01:23
   --------- ------------------------------ 10.2/41.3 MB 374.1 kB/s eta 0:01:23
   --------- ------------------------------ 10.2/41.3 MB 374.1 kB/s eta 0:01:23
   --------- ------------------------------ 10.2/41.3 MB 374.1 kB/s eta 0:01:23
   --------- ------------------------------ 10.2/41.3 MB 374.1 kB/s eta 0:01:23
   --------- ------------------------------ 10.2/41.3 MB 374.1 kB/s eta 0:01:23
   --------- ------------------------------ 10.2/41.3 MB 374.1 kB/s eta 0:01:23
   ---------- ----------------------------- 10.5/41.3 MB 351.6 kB/s eta 0:01:28
   ---------- ----------------------------- 10.5/41.3 MB 351.6 kB/s eta 0:01:28
   ---------- ----------------------------- 10.5/41.3 MB 351.6 kB/s eta 0:01:28
   ---------- ----------------------------- 10.7/41.3 MB 353.0 kB/s eta 0:01:27
   ---------- ----------------------------- 10.7/41.3 MB 353.0 kB/s eta 0:01:27
   ---------- ----------------------------- 11.0/41.3 MB 341.5 kB/s eta 0:01:29
   ---------- ----------------------------- 11.0/41.3 MB 341.5 kB/s eta 0:01:29
   ---------- ----------------------------- 11.3/41.3 MB 323.5 kB/s eta 0:01:33
   ---------- ----------------------------- 11.3/41.3 MB 323.5 kB/s eta 0:01:33
   ---------- ----------------------------- 11.3/41.3 MB 323.5 kB/s eta 0:01:33
   ----------- ---------------------------- 11.5/41.3 MB 281.2 kB/s eta 0:01:46
   ----------- ---------------------------- 11.5/41.3 MB 281.2 kB/s eta 0:01:46
   ----------- ---------------------------- 11.8/41.3 MB 270.9 kB/s eta 0:01:49
   ----------- ---------------------------- 11.8/41.3 MB 270.9 kB/s eta 0:01:49
   ----------- ---------------------------- 11.8/41.3 MB 270.9 kB/s eta 0:01:49
   ----------- ---------------------------- 11.8/41.3 MB 270.9 kB/s eta 0:01:49
   ----------- ---------------------------- 11.8/41.3 MB 270.9 kB/s eta 0:01:49
   ----------- ---------------------------- 11.8/41.3 MB 270.9 kB/s eta 0:01:49
   ----------- ---------------------------- 11.8/41.3 MB 270.9 kB/s eta 0:01:49
   ----------- ---------------------------- 11.8/41.3 MB 270.9 kB/s eta 0:01:49
   ----------- ---------------------------- 11.8/41.3 MB 270.9 kB/s eta 0:01:49
   ----------- ---------------------------- 11.8/41.3 MB 270.9 kB/s eta 0:01:49
   ----------- ---------------------------- 12.1/41.3 MB 264.2 kB/s eta 0:01:51
   ----------- ---------------------------- 12.1/41.3 MB 264.2 kB/s eta 0:01:51
   ----------- ---------------------------- 12.1/41.3 MB 264.2 kB/s eta 0:01:51
   ----------- ---------------------------- 12.1/41.3 MB 264.2 kB/s eta 0:01:51
   ----------- ---------------------------- 12.1/41.3 MB 264.2 kB/s eta 0:01:51
   ----------- ---------------------------- 12.1/41.3 MB 264.2 kB/s eta 0:01:51
   ----------- ---------------------------- 12.3/41.3 MB 261.2 kB/s eta 0:01:51
   ----------- ---------------------------- 12.3/41.3 MB 261.2 kB/s eta 0:01:51
   ----------- ---------------------------- 12.3/41.3 MB 261.2 kB/s eta 0:01:51
   ------------ --------------------------- 12.6/41.3 MB 264.3 kB/s eta 0:01:49
   ------------ --------------------------- 12.6/41.3 MB 264.3 kB/s eta 0:01:49
   ------------ --------------------------- 12.6/41.3 MB 264.3 kB/s eta 0:01:49
   ------------ --------------------------- 12.8/41.3 MB 266.3 kB/s eta 0:01:47
   ------------ --------------------------- 12.8/41.3 MB 266.3 kB/s eta 0:01:47
   ------------ --------------------------- 12.8/41.3 MB 266.3 kB/s eta 0:01:47
   ------------ --------------------------- 12.8/41.3 MB 266.3 kB/s eta 0:01:47
   ------------ --------------------------- 12.8/41.3 MB 266.3 kB/s eta 0:01:47
   ------------ --------------------------- 12.8/41.3 MB 266.3 kB/s eta 0:01:47
   ------------ --------------------------- 12.8/41.3 MB 266.3 kB/s eta 0:01:47
   ------------ --------------------------- 12.8/41.3 MB 266.3 kB/s eta 0:01:47
   ------------ --------------------------- 12.8/41.3 MB 266.3 kB/s eta 0:01:47
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.1/41.3 MB 312.1 kB/s eta 0:01:31
   ------------ --------------------------- 13.4/41.3 MB 255.8 kB/s eta 0:01:50
   ------------- -------------------------- 13.6/41.3 MB 263.1 kB/s eta 0:01:46
   ------------- -------------------------- 13.6/41.3 MB 263.1 kB/s eta 0:01:46
   ------------- -------------------------- 13.9/41.3 MB 269.6 kB/s eta 0:01:42
   ------------- -------------------------- 14.4/41.3 MB 285.9 kB/s eta 0:01:34
   -------------- ------------------------- 14.9/41.3 MB 301.2 kB/s eta 0:01:28
   -------------- ------------------------- 15.2/41.3 MB 308.6 kB/s eta 0:01:25
   -------------- ------------------------- 15.5/41.3 MB 307.4 kB/s eta 0:01:24
   --------------- ------------------------ 16.0/41.3 MB 324.4 kB/s eta 0:01:18
   ---------------- ----------------------- 16.5/41.3 MB 339.8 kB/s eta 0:01:13
   ---------------- ----------------------- 17.0/41.3 MB 355.8 kB/s eta 0:01:09
   ---------------- ----------------------- 17.3/41.3 MB 363.6 kB/s eta 0:01:06
   ----------------- ---------------------- 17.6/41.3 MB 368.0 kB/s eta 0:01:05
   ----------------- ---------------------- 18.1/41.3 MB 387.0 kB/s eta 0:01:00
   ------------------ --------------------- 18.6/41.3 MB 402.2 kB/s eta 0:00:57
   ------------------- -------------------- 19.9/41.3 MB 444.1 kB/s eta 0:00:49
   -------------------- ------------------- 21.2/41.3 MB 484.6 kB/s eta 0:00:42
   --------------------- ------------------ 21.8/41.3 MB 500.7 kB/s eta 0:00:39
   --------------------- ------------------ 22.0/41.3 MB 491.1 kB/s eta 0:00:40
   ---------------------- ----------------- 23.1/41.3 MB 518.3 kB/s eta 0:00:36
   ----------------------- ---------------- 24.4/41.3 MB 552.2 kB/s eta 0:00:31
   ------------------------ --------------- 25.4/41.3 MB 577.0 kB/s eta 0:00:28
   ------------------------- -------------- 26.0/41.3 MB 645.3 kB/s eta 0:00:24
   ------------------------- -------------- 26.0/41.3 MB 645.3 kB/s eta 0:00:24
   -------------------------- ------------- 27.3/41.3 MB 679.0 kB/s eta 0:00:21
   --------------------------- ------------ 28.8/41.3 MB 729.8 kB/s eta 0:00:18
   ---------------------------- ----------- 29.9/41.3 MB 761.3 kB/s eta 0:00:15
   ----------------------------- ---------- 30.7/41.3 MB 784.0 kB/s eta 0:00:14
   ------------------------------ --------- 31.7/41.3 MB 815.0 kB/s eta 0:00:12
   ------------------------------- -------- 32.8/41.3 MB 844.3 kB/s eta 0:00:11
   -------------------------------- ------- 33.8/41.3 MB 875.9 kB/s eta 0:00:09
   --------------------------------- ------ 34.6/41.3 MB 895.3 kB/s eta 0:00:08
   --------------------------------- ------ 34.9/41.3 MB 900.8 kB/s eta 0:00:08
   ---------------------------------- ----- 35.1/41.3 MB 904.0 kB/s eta 0:00:07
   ----------------------------------- ---- 36.2/41.3 MB 929.2 kB/s eta 0:00:06
   ------------------------------------ --- 37.2/41.3 MB 955.5 kB/s eta 0:00:05
   ------------------------------------- -- 38.3/41.3 MB 985.9 kB/s eta 0:00:04
   -------------------------------------- - 39.3/41.3 MB 1.0 MB/s eta 0:00:02
   ---------------------------------------  40.4/41.3 MB 1.0 MB/s eta 0:00:01
   ---------------------------------------  41.2/41.3 MB 1.1 MB/s eta 0:00:01
   ---------------------------------------- 41.3/41.3 MB 1.1 MB/s eta 0:00:00
Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)
Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn

   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   ---------- ----------------------------- 1/4 [scipy]
   -------------------- ------------------- 2/4 [joblib]
   -------------------- ------------------- 2/4 [joblib]
   -------------------- ------------------- 2/4 [joblib]
   -------------------- ------------------- 2/4 [joblib]
   -------------------- ------------------- 2/4 [joblib]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ------------------------------ --------- 3/4 [scikit-learn]
   ---------------------------------------- 4/4 [scikit-learn]

Successfully installed joblib-1.5.1 scikit-learn-1.7.1 scipy-1.15.3 threadpoolctl-3.6.0
Note: you may need to restart the kernel to use updated packages.</code></pre>
</div>
</div>
<div id="9ccf5043-bb25-4d42-adc8-08056f3c75ef" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, shlex, subprocess, sys, pathlib</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>repo_dir <span class="op">=</span> <span class="vs">r"C:</span><span class="er">\</span><span class="vs">Users</span><span class="er">\</span><span class="vs">yalda</span><span class="er">\</span><span class="vs">OneDrive</span><span class="dv">\D</span><span class="vs">esktop</span><span class="er">\</span><span class="vs">Thesis apps</span><span class="er">\</span><span class="vs">Project Folder</span><span class="er">\</span><span class="vs">pytorch-CycleGAN-and-pix2pix"</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>os.chdir(repo_dir)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CWD:"</span>, os.getcwd())</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>cmd <span class="op">=</span> <span class="vs">r"""</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="vs">python train</span><span class="dv">.</span><span class="vs">py</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="vs">--dataroot </span><span class="dv">.</span><span class="vs">/datasets/stopmotion_pix2pix</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="vs">--name stopmotion_pix2pix_1024</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="vs">--model pix2pix</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="vs">--dataset_mode aligned</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="vs">--direction AtoB</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="vs">--input_nc 3</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="vs">--output_nc 3</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="vs">--preprocess none</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="vs">--load_size 1024</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="vs">--crop_size 1024</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="vs">--batch_size 1</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="vs">--gpu_ids 0</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="vs">--n_epochs 10</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="vs">--n_epochs_decay 10</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="vs">--save_epoch_freq 2</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="vs">--print_freq 50</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="vs">--display_freq 200</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="vs">"""</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>proc <span class="op">=</span> subprocess.run(shlex.split(<span class="st">" "</span>.join(cmd.split())), stdout<span class="op">=</span>subprocess.PIPE, stderr<span class="op">=</span>subprocess.STDOUT, text<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(proc.stdout)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>CWD: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
W0808 14:20:53.447000 31368 site-packages\torch\_logging\_internal.py:1081] [0/0] Profiler function &lt;class 'torch.autograd.profiler.record_function'&gt; will be ignored
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] WON'T CONVERT forward C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\models\networks.py line 464 
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] due to: 
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Traceback (most recent call last):
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1446, in _call_user_compiler
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\repro\after_dynamo.py", line 129, in __call__
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\__init__.py", line 2234, in __call__
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1521, in compile_fx
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return aot_autograd(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\backends\common.py", line 72, in __call__
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 1071, in aot_module_simplified
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 1056, in dispatch_and_compile
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 522, in create_aot_dispatcher_function
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _create_aot_dispatcher_function(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 759, in _create_aot_dispatcher_function
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\_aot_autograd\jit_compile_runtime_wrappers.py", line 588, in aot_dispatch_autograd
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1350, in fw_compiler_base
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1421, in _fw_compiler_base
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return inner_compile(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 475, in compile_fx_inner
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\repro\after_aot.py", line 85, in debug_wrapper
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 661, in _compile_fx_inner
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\codecache.py", line 1334, in load
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = compile_fx_fn(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 570, in codegen_and_compile
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 878, in fx_codegen_and_compile
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1913, in compile_to_fn
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self.compile_to_module().call
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1839, in compile_to_module
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self._compile_to_module()
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1845, in _compile_to_module
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1780, in codegen
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1731, in __init__
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._init(nodes)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1749, in _init
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1749, in &lt;listcomp&gt;
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1856, in create_scheduler_node
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return SchedulerNode(self, node)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 833, in __init__
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._compute_attrs()
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 846, in _compute_attrs
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 3360, in get_backend
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 3352, in create_backend
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     raise RuntimeError(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] The above exception was the direct cause of the following exception:
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Traceback (most recent call last):
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 1064, in __call__
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     result = self._inner_convert(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 526, in __call__
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _compile(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 924, in _compile
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 666, in compile_inner
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_utils_internal.py", line 87, in wrapper_function
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return function(*args, **kwargs)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 699, in _compile_inner
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     out_code = transform_code_object(code, transform)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\bytecode_transformation.py", line 1322, in transform_code_object
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     transformations(instructions, code_options)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 219, in _fn
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return fn(*args, **kwargs)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 634, in transform
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     tracer.run()
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2796, in run
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     super().run()
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 983, in run
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     while self.step():
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 895, in step
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2987, in RETURN_VALUE
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._return(inst)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2972, in _return
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.output.compile_subgraph(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1117, in compile_subgraph
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1369, in compile_and_call_fx_graph
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1416, in call_user_compiler
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self._call_user_compiler(gm)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1465, in _call_user_compiler
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Traceback (most recent call last):
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1446, in _call_user_compiler
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\repro\after_dynamo.py", line 129, in __call__
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\__init__.py", line 2234, in __call__
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1521, in compile_fx
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return aot_autograd(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\backends\common.py", line 72, in __call__
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 1071, in aot_module_simplified
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 1056, in dispatch_and_compile
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 522, in create_aot_dispatcher_function
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _create_aot_dispatcher_function(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 759, in _create_aot_dispatcher_function
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\_aot_autograd\jit_compile_runtime_wrappers.py", line 588, in aot_dispatch_autograd
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1350, in fw_compiler_base
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1421, in _fw_compiler_base
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return inner_compile(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 475, in compile_fx_inner
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\repro\after_aot.py", line 85, in debug_wrapper
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 661, in _compile_fx_inner
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\codecache.py", line 1334, in load
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = compile_fx_fn(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 570, in codegen_and_compile
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 878, in fx_codegen_and_compile
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1913, in compile_to_fn
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self.compile_to_module().call
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1839, in compile_to_module
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self._compile_to_module()
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1845, in _compile_to_module
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1780, in codegen
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1731, in __init__
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._init(nodes)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1749, in _init
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1749, in &lt;listcomp&gt;
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1856, in create_scheduler_node
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return SchedulerNode(self, node)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 833, in __init__
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._compute_attrs()
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 846, in _compute_attrs
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 3360, in get_backend
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 3352, in create_backend
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     raise RuntimeError(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] The above exception was the direct cause of the following exception:
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Traceback (most recent call last):
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 1064, in __call__
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     result = self._inner_convert(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 526, in __call__
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _compile(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 924, in _compile
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 666, in compile_inner
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_utils_internal.py", line 87, in wrapper_function
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return function(*args, **kwargs)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 699, in _compile_inner
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     out_code = transform_code_object(code, transform)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\bytecode_transformation.py", line 1322, in transform_code_object
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     transformations(instructions, code_options)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 219, in _fn
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return fn(*args, **kwargs)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 634, in transform
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     tracer.run()
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2796, in run
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     super().run()
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 983, in run
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     while self.step():
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 895, in step
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2987, in RETURN_VALUE
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._return(inst)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2972, in _return
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.output.compile_subgraph(
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1117, in compile_subgraph
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1369, in compile_and_call_fx_graph
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1416, in call_user_compiler
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self._call_user_compiler(gm)
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1465, in _call_user_compiler
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
W0808 14:21:11.040000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] WON'T CONVERT forward C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\models\networks.py line 532 
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] due to: 
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Traceback (most recent call last):
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1446, in _call_user_compiler
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\repro\after_dynamo.py", line 129, in __call__
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\__init__.py", line 2234, in __call__
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1521, in compile_fx
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return aot_autograd(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\backends\common.py", line 72, in __call__
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 1071, in aot_module_simplified
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 1056, in dispatch_and_compile
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 522, in create_aot_dispatcher_function
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _create_aot_dispatcher_function(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 759, in _create_aot_dispatcher_function
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\_aot_autograd\jit_compile_runtime_wrappers.py", line 588, in aot_dispatch_autograd
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1350, in fw_compiler_base
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1421, in _fw_compiler_base
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return inner_compile(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 475, in compile_fx_inner
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\repro\after_aot.py", line 85, in debug_wrapper
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 661, in _compile_fx_inner
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\codecache.py", line 1334, in load
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = compile_fx_fn(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 570, in codegen_and_compile
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 878, in fx_codegen_and_compile
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1913, in compile_to_fn
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self.compile_to_module().call
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1839, in compile_to_module
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self._compile_to_module()
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1845, in _compile_to_module
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1780, in codegen
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1731, in __init__
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._init(nodes)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1749, in _init
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1749, in &lt;listcomp&gt;
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1856, in create_scheduler_node
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return SchedulerNode(self, node)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 833, in __init__
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._compute_attrs()
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 846, in _compute_attrs
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 3360, in get_backend
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 3352, in create_backend
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     raise RuntimeError(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] The above exception was the direct cause of the following exception:
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Traceback (most recent call last):
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 1064, in __call__
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     result = self._inner_convert(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 526, in __call__
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _compile(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 924, in _compile
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 666, in compile_inner
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_utils_internal.py", line 87, in wrapper_function
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return function(*args, **kwargs)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 699, in _compile_inner
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     out_code = transform_code_object(code, transform)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\bytecode_transformation.py", line 1322, in transform_code_object
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     transformations(instructions, code_options)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 219, in _fn
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return fn(*args, **kwargs)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 634, in transform
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     tracer.run()
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2796, in run
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     super().run()
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 983, in run
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     while self.step():
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 895, in step
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2987, in RETURN_VALUE
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._return(inst)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2972, in _return
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.output.compile_subgraph(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1117, in compile_subgraph
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1369, in compile_and_call_fx_graph
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1416, in call_user_compiler
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self._call_user_compiler(gm)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1465, in _call_user_compiler
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Traceback (most recent call last):
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1446, in _call_user_compiler
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\repro\after_dynamo.py", line 129, in __call__
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\__init__.py", line 2234, in __call__
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1521, in compile_fx
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return aot_autograd(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\backends\common.py", line 72, in __call__
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 1071, in aot_module_simplified
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 1056, in dispatch_and_compile
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 522, in create_aot_dispatcher_function
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _create_aot_dispatcher_function(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 759, in _create_aot_dispatcher_function
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\_aot_autograd\jit_compile_runtime_wrappers.py", line 588, in aot_dispatch_autograd
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1350, in fw_compiler_base
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1421, in _fw_compiler_base
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return inner_compile(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 475, in compile_fx_inner
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\repro\after_aot.py", line 85, in debug_wrapper
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 661, in _compile_fx_inner
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\codecache.py", line 1334, in load
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = compile_fx_fn(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 570, in codegen_and_compile
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 878, in fx_codegen_and_compile
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1913, in compile_to_fn
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self.compile_to_module().call
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1839, in compile_to_module
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self._compile_to_module()
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1845, in _compile_to_module
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1780, in codegen
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1731, in __init__
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._init(nodes)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1749, in _init
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1749, in &lt;listcomp&gt;
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1856, in create_scheduler_node
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return SchedulerNode(self, node)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 833, in __init__
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._compute_attrs()
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 846, in _compute_attrs
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 3360, in get_backend
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 3352, in create_backend
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     raise RuntimeError(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] The above exception was the direct cause of the following exception:
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Traceback (most recent call last):
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 1064, in __call__
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     result = self._inner_convert(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 526, in __call__
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _compile(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 924, in _compile
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 666, in compile_inner
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_utils_internal.py", line 87, in wrapper_function
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return function(*args, **kwargs)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 699, in _compile_inner
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     out_code = transform_code_object(code, transform)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\bytecode_transformation.py", line 1322, in transform_code_object
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     transformations(instructions, code_options)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 219, in _fn
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return fn(*args, **kwargs)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 634, in transform
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     tracer.run()
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2796, in run
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     super().run()
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 983, in run
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     while self.step():
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 895, in step
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2987, in RETURN_VALUE
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._return(inst)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2972, in _return
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.output.compile_subgraph(
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1117, in compile_subgraph
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1369, in compile_and_call_fx_graph
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1416, in call_user_compiler
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self._call_user_compiler(gm)
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1465, in _call_user_compiler
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
W0808 14:21:20.363000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] WON'T CONVERT forward C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\models\networks.py line 582 
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] due to: 
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Traceback (most recent call last):
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1446, in _call_user_compiler
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\repro\after_dynamo.py", line 129, in __call__
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\__init__.py", line 2234, in __call__
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1521, in compile_fx
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return aot_autograd(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\backends\common.py", line 72, in __call__
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 1071, in aot_module_simplified
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 1056, in dispatch_and_compile
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 522, in create_aot_dispatcher_function
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _create_aot_dispatcher_function(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 759, in _create_aot_dispatcher_function
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\_aot_autograd\jit_compile_runtime_wrappers.py", line 588, in aot_dispatch_autograd
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1350, in fw_compiler_base
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1421, in _fw_compiler_base
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return inner_compile(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 475, in compile_fx_inner
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\repro\after_aot.py", line 85, in debug_wrapper
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 661, in _compile_fx_inner
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\codecache.py", line 1334, in load
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = compile_fx_fn(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 570, in codegen_and_compile
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 878, in fx_codegen_and_compile
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1913, in compile_to_fn
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self.compile_to_module().call
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1839, in compile_to_module
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self._compile_to_module()
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1845, in _compile_to_module
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1780, in codegen
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1731, in __init__
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._init(nodes)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1749, in _init
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1749, in &lt;listcomp&gt;
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1856, in create_scheduler_node
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return SchedulerNode(self, node)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 833, in __init__
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._compute_attrs()
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 846, in _compute_attrs
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 3360, in get_backend
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 3352, in create_backend
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     raise RuntimeError(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] The above exception was the direct cause of the following exception:
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Traceback (most recent call last):
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 1064, in __call__
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     result = self._inner_convert(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 526, in __call__
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _compile(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 924, in _compile
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 666, in compile_inner
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_utils_internal.py", line 87, in wrapper_function
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return function(*args, **kwargs)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 699, in _compile_inner
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     out_code = transform_code_object(code, transform)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\bytecode_transformation.py", line 1322, in transform_code_object
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     transformations(instructions, code_options)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 219, in _fn
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return fn(*args, **kwargs)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 634, in transform
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     tracer.run()
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2796, in run
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     super().run()
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 983, in run
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     while self.step():
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 895, in step
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2987, in RETURN_VALUE
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._return(inst)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2972, in _return
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.output.compile_subgraph(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1117, in compile_subgraph
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1369, in compile_and_call_fx_graph
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1416, in call_user_compiler
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self._call_user_compiler(gm)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1465, in _call_user_compiler
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Traceback (most recent call last):
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1446, in _call_user_compiler
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\repro\after_dynamo.py", line 129, in __call__
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\__init__.py", line 2234, in __call__
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1521, in compile_fx
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return aot_autograd(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\backends\common.py", line 72, in __call__
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 1071, in aot_module_simplified
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 1056, in dispatch_and_compile
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 522, in create_aot_dispatcher_function
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _create_aot_dispatcher_function(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 759, in _create_aot_dispatcher_function
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\_aot_autograd\jit_compile_runtime_wrappers.py", line 588, in aot_dispatch_autograd
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1350, in fw_compiler_base
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1421, in _fw_compiler_base
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return inner_compile(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 475, in compile_fx_inner
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\repro\after_aot.py", line 85, in debug_wrapper
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 661, in _compile_fx_inner
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\codecache.py", line 1334, in load
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = compile_fx_fn(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 570, in codegen_and_compile
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 878, in fx_codegen_and_compile
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1913, in compile_to_fn
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self.compile_to_module().call
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1839, in compile_to_module
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self._compile_to_module()
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1845, in _compile_to_module
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1780, in codegen
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1731, in __init__
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._init(nodes)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1749, in _init
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1749, in &lt;listcomp&gt;
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1856, in create_scheduler_node
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return SchedulerNode(self, node)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 833, in __init__
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._compute_attrs()
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 846, in _compute_attrs
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 3360, in get_backend
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 3352, in create_backend
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     raise RuntimeError(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] The above exception was the direct cause of the following exception:
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Traceback (most recent call last):
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 1064, in __call__
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     result = self._inner_convert(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 526, in __call__
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _compile(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 924, in _compile
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 666, in compile_inner
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_utils_internal.py", line 87, in wrapper_function
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return function(*args, **kwargs)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 699, in _compile_inner
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     out_code = transform_code_object(code, transform)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\bytecode_transformation.py", line 1322, in transform_code_object
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     transformations(instructions, code_options)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 219, in _fn
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return fn(*args, **kwargs)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 634, in transform
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     tracer.run()
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2796, in run
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     super().run()
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 983, in run
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     while self.step():
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 895, in step
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2987, in RETURN_VALUE
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self._return(inst)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2972, in _return
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.output.compile_subgraph(
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1117, in compile_subgraph
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1369, in compile_and_call_fx_graph
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1416, in call_user_compiler
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     return self._call_user_compiler(gm)
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]   File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1465, in _call_user_compiler
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
W0808 14:21:27.426000 31368 site-packages\torch\_dynamo\convert_frame.py:1125] 
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
----------------- Options ---------------
               batch_size: 1                             
                    beta1: 0.5                           
          checkpoints_dir: ./checkpoints                 
           continue_train: False                         
                crop_size: 1024                             [default: 256]
                 dataroot: ./datasets/stopmotion_pix2pix    [default: None]
             dataset_mode: aligned                       
                direction: AtoB                          
             display_freq: 200                              [default: 400]
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: vanilla                       
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                             [default: None]
                lambda_L1: 100.0                         
                load_iter: 0                                [default: 0]
                load_size: 1024                             [default: 286]
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: linear                        
         max_dataset_size: inf                           
                    model: pix2pix                          [default: cycle_gan]
                 n_epochs: 10                               [default: 100]
           n_epochs_decay: 10                               [default: 100]
               n_layers_D: 3                             
                     name: stopmotion_pix2pix_1024          [default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: unet_256                      
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: False                         
                  no_html: False                         
                     norm: batch                         
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 0                             
               preprocess: none                             [default: resize_and_crop]
               print_freq: 50                               [default: 100]
             save_by_iter: False                         
          save_epoch_freq: 2                                [default: 5]
         save_latest_freq: 5000                          
           serial_batches: False                         
                   suffix:                               
         update_html_freq: 1000                          
                use_wandb: False                         
                  verbose: False                         
       wandb_project_name: CycleGAN-and-pix2pix          
----------------- End -------------------
dataset [AlignedDataset] was created
The number of training images = 867
initialize network with normal
initialize network with normal
model [Pix2PixModel] was created
---------- Networks initialized -------------
[Network G] Total number of parameters : 54.414 M
[Network D] Total number of parameters : 2.769 M
-----------------------------------------------
[Network G] compiled with torch.compile
[Network D] compiled with torch.compile
create web directory checkpoints\stopmotion_pix2pix_1024\web...
(epoch: 1, iters: 50, time: 0.628, data: 52.207) G_GAN: 0.814 G_L1: 10.793 D_real: 0.329 D_fake: 1.122 
(epoch: 1, iters: 100, time: 0.719, data: 0.009) G_GAN: 1.000 G_L1: 11.617 D_real: 0.628 D_fake: 0.673 
(epoch: 1, iters: 150, time: 0.682, data: 0.009) G_GAN: 1.340 G_L1: 11.779 D_real: 0.272 D_fake: 0.596 
(epoch: 1, iters: 200, time: 4.123, data: 0.011) G_GAN: 1.153 G_L1: 10.284 D_real: 0.574 D_fake: 0.388 
(epoch: 1, iters: 250, time: 0.652, data: 0.014) G_GAN: 0.989 G_L1: 10.875 D_real: 0.817 D_fake: 0.337 
(epoch: 1, iters: 300, time: 0.647, data: 0.006) G_GAN: 1.479 G_L1: 13.934 D_real: 0.522 D_fake: 0.433 
(epoch: 1, iters: 350, time: 0.721, data: 0.012) G_GAN: 1.038 G_L1: 8.779 D_real: 1.007 D_fake: 0.258 
(epoch: 1, iters: 400, time: 0.666, data: 0.016) G_GAN: 1.940 G_L1: 11.292 D_real: 0.295 D_fake: 0.449 
(epoch: 1, iters: 450, time: 0.649, data: 0.010) G_GAN: 1.244 G_L1: 9.365 D_real: 0.211 D_fake: 0.798 
(epoch: 1, iters: 500, time: 0.666, data: 0.012) G_GAN: 1.106 G_L1: 10.241 D_real: 0.592 D_fake: 0.460 
(epoch: 1, iters: 550, time: 0.737, data: 0.011) G_GAN: 0.863 G_L1: 9.269 D_real: 0.973 D_fake: 0.570 
(epoch: 1, iters: 600, time: 0.668, data: 0.009) G_GAN: 1.244 G_L1: 13.765 D_real: 0.308 D_fake: 0.627 
(epoch: 1, iters: 650, time: 0.649, data: 0.015) G_GAN: 1.180 G_L1: 12.293 D_real: 0.395 D_fake: 0.533 
(epoch: 1, iters: 700, time: 0.634, data: 0.011) G_GAN: 1.693 G_L1: 9.603 D_real: 0.340 D_fake: 0.282 
(epoch: 1, iters: 750, time: 0.724, data: 0.016) G_GAN: 1.271 G_L1: 12.508 D_real: 0.257 D_fake: 0.800 
(epoch: 1, iters: 800, time: 0.715, data: 0.006) G_GAN: 1.504 G_L1: 10.995 D_real: 0.340 D_fake: 0.561 
(epoch: 1, iters: 850, time: 0.741, data: 0.010) G_GAN: 1.491 G_L1: 10.166 D_real: 0.338 D_fake: 0.391 
learning rate 0.0002000 -&gt; 0.0002000
End of epoch 1 / 20      Time Taken: 455 sec
(epoch: 2, iters: 33, time: 0.734, data: 0.012) G_GAN: 1.375 G_L1: 13.132 D_real: 0.113 D_fake: 0.598 
(epoch: 2, iters: 83, time: 0.681, data: 0.011) G_GAN: 0.778 G_L1: 7.760 D_real: 1.050 D_fake: 0.395 
(epoch: 2, iters: 133, time: 4.306, data: 0.008) G_GAN: 1.537 G_L1: 9.806 D_real: 0.246 D_fake: 0.556 
(epoch: 2, iters: 183, time: 0.687, data: 0.025) G_GAN: 1.271 G_L1: 8.641 D_real: 0.345 D_fake: 0.470 
(epoch: 2, iters: 233, time: 0.623, data: 0.007) G_GAN: 1.467 G_L1: 10.651 D_real: 0.438 D_fake: 1.044 
(epoch: 2, iters: 283, time: 0.677, data: 0.014) G_GAN: 1.885 G_L1: 10.717 D_real: 0.185 D_fake: 0.502 
(epoch: 2, iters: 333, time: 0.722, data: 0.015) G_GAN: 1.187 G_L1: 11.235 D_real: 0.857 D_fake: 0.296 
(epoch: 2, iters: 383, time: 0.767, data: 0.010) G_GAN: 1.133 G_L1: 10.300 D_real: 0.765 D_fake: 0.601 
(epoch: 2, iters: 433, time: 0.703, data: 0.011) G_GAN: 0.953 G_L1: 14.182 D_real: 0.220 D_fake: 1.131 
(epoch: 2, iters: 483, time: 0.693, data: 0.007) G_GAN: 0.776 G_L1: 11.802 D_real: 0.875 D_fake: 0.761 
(epoch: 2, iters: 533, time: 0.904, data: 0.008) G_GAN: 1.131 G_L1: 9.687 D_real: 0.351 D_fake: 0.476 
(epoch: 2, iters: 583, time: 0.788, data: 0.008) G_GAN: 1.203 G_L1: 10.355 D_real: 0.534 D_fake: 0.407 
(epoch: 2, iters: 633, time: 0.756, data: 0.011) G_GAN: 1.001 G_L1: 12.393 D_real: 0.182 D_fake: 0.959 
(epoch: 2, iters: 683, time: 0.770, data: 0.012) G_GAN: 0.939 G_L1: 10.221 D_real: 1.120 D_fake: 0.539 
(epoch: 2, iters: 733, time: 0.664, data: 0.011) G_GAN: 1.722 G_L1: 10.894 D_real: 0.171 D_fake: 0.373 
(epoch: 2, iters: 783, time: 0.750, data: 0.015) G_GAN: 1.048 G_L1: 10.492 D_real: 0.469 D_fake: 0.369 
(epoch: 2, iters: 833, time: 0.724, data: 0.006) G_GAN: 1.399 G_L1: 9.913 D_real: 0.461 D_fake: 0.359 
learning rate 0.0002000 -&gt; 0.0002000
saving the model at the end of epoch 2, iters 1734
End of epoch 2 / 20      Time Taken: 426 sec
(epoch: 3, iters: 16, time: 0.691, data: 0.015) G_GAN: 0.871 G_L1: 10.620 D_real: 1.463 D_fake: 0.160 
(epoch: 3, iters: 66, time: 4.394, data: 0.018) G_GAN: 1.334 G_L1: 9.422 D_real: 0.281 D_fake: 0.612 
(epoch: 3, iters: 116, time: 0.754, data: 0.011) G_GAN: 0.855 G_L1: 9.621 D_real: 1.982 D_fake: 0.914 
(epoch: 3, iters: 166, time: 0.701, data: 0.013) G_GAN: 1.374 G_L1: 12.909 D_real: 0.233 D_fake: 0.567 
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
(epoch: 3, iters: 216, time: 0.690, data: 0.013) G_GAN: 1.513 G_L1: 10.005 D_real: 0.211 D_fake: 0.303 
(epoch: 3, iters: 266, time: 4.461, data: 0.010) G_GAN: 0.946 G_L1: 9.622 D_real: 1.075 D_fake: 0.569 
(epoch: 3, iters: 316, time: 0.917, data: 0.016) G_GAN: 1.692 G_L1: 9.661 D_real: 0.092 D_fake: 0.833 
(epoch: 3, iters: 366, time: 0.706, data: 0.011) G_GAN: 1.948 G_L1: 10.092 D_real: 0.288 D_fake: 0.509 
(epoch: 3, iters: 416, time: 0.721, data: 0.015) G_GAN: 0.711 G_L1: 8.979 D_real: 1.062 D_fake: 0.564 
(epoch: 3, iters: 466, time: 0.618, data: 0.013) G_GAN: 1.586 G_L1: 9.226 D_real: 0.627 D_fake: 0.239 
(epoch: 3, iters: 516, time: 0.669, data: 0.015) G_GAN: 0.881 G_L1: 8.280 D_real: 0.638 D_fake: 0.570 
(epoch: 3, iters: 566, time: 0.627, data: 0.014) G_GAN: 2.315 G_L1: 11.227 D_real: 0.233 D_fake: 0.203 
(epoch: 3, iters: 616, time: 2.517, data: 0.015) G_GAN: 0.926 G_L1: 10.941 D_real: 0.400 D_fake: 1.031 
(epoch: 3, iters: 666, time: 2.574, data: 0.015) G_GAN: 1.140 G_L1: 7.850 D_real: 0.413 D_fake: 0.621 
(epoch: 3, iters: 716, time: 2.571, data: 0.014) G_GAN: 2.369 G_L1: 10.941 D_real: 0.151 D_fake: 0.194 
(epoch: 3, iters: 766, time: 2.675, data: 0.015) G_GAN: 1.292 G_L1: 9.566 D_real: 0.526 D_fake: 0.479 
(epoch: 3, iters: 816, time: 2.741, data: 0.014) G_GAN: 1.475 G_L1: 10.266 D_real: 0.484 D_fake: 0.346 
(epoch: 3, iters: 866, time: 2.627, data: 0.015) G_GAN: 1.472 G_L1: 8.614 D_real: 0.324 D_fake: 0.509 
learning rate 0.0002000 -&gt; 0.0002000
End of epoch 3 / 20      Time Taken: 688 sec
(epoch: 4, iters: 49, time: 7.579, data: 0.015) G_GAN: 1.271 G_L1: 10.808 D_real: 0.913 D_fake: 0.310 
(epoch: 4, iters: 99, time: 7.198, data: 0.010) G_GAN: 0.964 G_L1: 8.599 D_real: 0.636 D_fake: 0.439 
(epoch: 4, iters: 149, time: 7.184, data: 0.000) G_GAN: 1.145 G_L1: 9.137 D_real: 0.878 D_fake: 0.225 
(epoch: 4, iters: 199, time: 9.882, data: 0.016) G_GAN: 0.558 G_L1: 8.106 D_real: 1.623 D_fake: 0.492 
(epoch: 4, iters: 249, time: 7.196, data: 0.016) G_GAN: 0.743 G_L1: 10.467 D_real: 0.959 D_fake: 0.593 
(epoch: 4, iters: 299, time: 7.187, data: 0.019) G_GAN: 1.255 G_L1: 8.783 D_real: 0.789 D_fake: 0.345 
(epoch: 4, iters: 349, time: 7.186, data: 0.016) G_GAN: 1.806 G_L1: 9.989 D_real: 0.346 D_fake: 0.266 
(epoch: 4, iters: 399, time: 9.883, data: 0.022) G_GAN: 1.369 G_L1: 9.633 D_real: 0.531 D_fake: 0.615 
(epoch: 4, iters: 449, time: 7.191, data: 0.016) G_GAN: 0.644 G_L1: 9.672 D_real: 1.229 D_fake: 0.799 
(epoch: 4, iters: 499, time: 7.200, data: 0.011) G_GAN: 1.161 G_L1: 9.548 D_real: 0.611 D_fake: 0.530 
(epoch: 4, iters: 549, time: 7.200, data: 0.016) G_GAN: 0.667 G_L1: 9.469 D_real: 1.472 D_fake: 0.543 
(epoch: 4, iters: 599, time: 7.249, data: 0.000) G_GAN: 1.286 G_L1: 8.545 D_real: 0.600 D_fake: 0.335 
(epoch: 4, iters: 649, time: 7.185, data: 0.020) G_GAN: 0.914 G_L1: 9.390 D_real: 0.407 D_fake: 0.629 
(epoch: 4, iters: 699, time: 0.587, data: 0.014) G_GAN: 1.666 G_L1: 11.146 D_real: 0.271 D_fake: 0.282 
(epoch: 4, iters: 749, time: 0.525, data: 0.011) G_GAN: 1.285 G_L1: 11.131 D_real: 0.484 D_fake: 0.312 
(epoch: 4, iters: 799, time: 0.582, data: 0.010) G_GAN: 1.488 G_L1: 10.381 D_real: 0.484 D_fake: 0.405 
(epoch: 4, iters: 849, time: 0.596, data: 0.017) G_GAN: 1.166 G_L1: 9.319 D_real: 0.387 D_fake: 0.434 
learning rate 0.0002000 -&gt; 0.0002000
saving the model at the end of epoch 4, iters 3468
End of epoch 4 / 20      Time Taken: 2608 sec
(epoch: 5, iters: 32, time: 0.614, data: 0.010) G_GAN: 1.764 G_L1: 13.431 D_real: 0.420 D_fake: 0.356 
(epoch: 5, iters: 82, time: 0.632, data: 0.010) G_GAN: 1.100 G_L1: 9.181 D_real: 0.387 D_fake: 0.515 
(epoch: 5, iters: 132, time: 4.511, data: 0.015) G_GAN: 0.625 G_L1: 9.138 D_real: 0.908 D_fake: 0.390 
(epoch: 5, iters: 182, time: 0.556, data: 0.012) G_GAN: 1.383 G_L1: 7.609 D_real: 0.388 D_fake: 0.609 
(epoch: 5, iters: 232, time: 0.551, data: 0.008) G_GAN: 0.990 G_L1: 8.989 D_real: 0.989 D_fake: 0.609 
(epoch: 5, iters: 282, time: 0.545, data: 0.014) G_GAN: 1.179 G_L1: 9.745 D_real: 0.190 D_fake: 0.723 
(epoch: 5, iters: 332, time: 0.626, data: 0.012) G_GAN: 1.438 G_L1: 8.147 D_real: 1.008 D_fake: 0.305 
(epoch: 5, iters: 382, time: 0.586, data: 0.020) G_GAN: 2.648 G_L1: 10.813 D_real: 0.148 D_fake: 0.207 
(epoch: 5, iters: 432, time: 0.606, data: 0.010) G_GAN: 1.243 G_L1: 9.003 D_real: 0.880 D_fake: 0.596 
(epoch: 5, iters: 482, time: 0.612, data: 0.020) G_GAN: 0.520 G_L1: 10.547 D_real: 1.767 D_fake: 0.591 
(epoch: 5, iters: 532, time: 4.322, data: 0.021) G_GAN: 1.535 G_L1: 7.994 D_real: 0.727 D_fake: 0.417 
(epoch: 5, iters: 582, time: 0.605, data: 0.007) G_GAN: 1.160 G_L1: 8.349 D_real: 0.602 D_fake: 0.379 
(epoch: 5, iters: 632, time: 0.616, data: 0.010) G_GAN: 0.709 G_L1: 9.005 D_real: 1.162 D_fake: 0.811 
(epoch: 5, iters: 682, time: 0.633, data: 0.011) G_GAN: 1.495 G_L1: 8.121 D_real: 0.639 D_fake: 0.301 
(epoch: 5, iters: 732, time: 0.574, data: 0.010) G_GAN: 1.008 G_L1: 8.222 D_real: 0.799 D_fake: 0.436 
(epoch: 5, iters: 782, time: 0.636, data: 0.010) G_GAN: 1.588 G_L1: 10.499 D_real: 0.301 D_fake: 0.312 
(epoch: 5, iters: 832, time: 0.580, data: 0.008) G_GAN: 1.437 G_L1: 9.690 D_real: 0.822 D_fake: 0.195 
learning rate 0.0002000 -&gt; 0.0002000
End of epoch 5 / 20      Time Taken: 385 sec
(epoch: 6, iters: 15, time: 0.554, data: 0.020) G_GAN: 1.038 G_L1: 12.153 D_real: 0.491 D_fake: 0.418 
(epoch: 6, iters: 65, time: 4.399, data: 0.010) G_GAN: 0.488 G_L1: 9.512 D_real: 0.931 D_fake: 0.839 
(epoch: 6, iters: 115, time: 0.576, data: 0.010) G_GAN: 0.829 G_L1: 9.537 D_real: 2.013 D_fake: 0.349 
(epoch: 6, iters: 165, time: 0.564, data: 0.000) G_GAN: 0.937 G_L1: 10.681 D_real: 0.347 D_fake: 1.334 
(epoch: 6, iters: 215, time: 0.584, data: 0.010) G_GAN: 1.527 G_L1: 10.293 D_real: 0.355 D_fake: 0.327 
(epoch: 6, iters: 265, time: 0.523, data: 0.021) G_GAN: 2.055 G_L1: 10.253 D_real: 0.180 D_fake: 0.621 
(epoch: 6, iters: 315, time: 0.548, data: 0.020) G_GAN: 0.719 G_L1: 8.036 D_real: 1.359 D_fake: 0.249 
(epoch: 6, iters: 365, time: 0.650, data: 0.010) G_GAN: 0.563 G_L1: 8.618 D_real: 0.689 D_fake: 1.018 
(epoch: 6, iters: 415, time: 0.572, data: 0.010) G_GAN: 1.095 G_L1: 7.542 D_real: 0.862 D_fake: 0.719 
(epoch: 6, iters: 465, time: 0.592, data: 0.020) G_GAN: 2.027 G_L1: 11.315 D_real: 0.165 D_fake: 0.316 
(epoch: 6, iters: 515, time: 0.685, data: 0.015) G_GAN: 1.985 G_L1: 11.978 D_real: 0.170 D_fake: 0.458 
(epoch: 6, iters: 565, time: 0.586, data: 0.015) G_GAN: 1.331 G_L1: 10.030 D_real: 0.796 D_fake: 0.371 
(epoch: 6, iters: 615, time: 0.636, data: 0.008) G_GAN: 1.387 G_L1: 15.463 D_real: 0.031 D_fake: 0.965 
(epoch: 6, iters: 665, time: 4.078, data: 0.011) G_GAN: 2.036 G_L1: 12.481 D_real: 0.151 D_fake: 0.254 
saving the latest model (epoch 6, total_iters 5000)
(epoch: 6, iters: 715, time: 0.718, data: 0.000) G_GAN: 1.222 G_L1: 9.364 D_real: 0.812 D_fake: 0.523 
(epoch: 6, iters: 765, time: 0.612, data: 0.010) G_GAN: 0.438 G_L1: 8.591 D_real: 1.050 D_fake: 1.161 
(epoch: 6, iters: 815, time: 0.657, data: 0.010) G_GAN: 1.285 G_L1: 9.915 D_real: 0.709 D_fake: 0.541 
(epoch: 6, iters: 865, time: 0.584, data: 0.010) G_GAN: 1.436 G_L1: 9.263 D_real: 0.459 D_fake: 0.415 
learning rate 0.0002000 -&gt; 0.0002000
saving the model at the end of epoch 6, iters 5202
End of epoch 6 / 20      Time Taken: 373 sec
(epoch: 7, iters: 48, time: 0.558, data: 0.010) G_GAN: 1.136 G_L1: 10.980 D_real: 0.160 D_fake: 0.736 
(epoch: 7, iters: 98, time: 0.663, data: 0.010) G_GAN: 1.516 G_L1: 11.587 D_real: 0.144 D_fake: 0.775 
(epoch: 7, iters: 148, time: 0.626, data: 0.015) G_GAN: 1.422 G_L1: 9.358 D_real: 0.593 D_fake: 0.433 
(epoch: 7, iters: 198, time: 4.351, data: 0.012) G_GAN: 1.596 G_L1: 14.620 D_real: 0.181 D_fake: 0.525 
(epoch: 7, iters: 248, time: 0.635, data: 0.011) G_GAN: 1.881 G_L1: 8.327 D_real: 0.463 D_fake: 0.433 
(epoch: 7, iters: 298, time: 0.636, data: 0.009) G_GAN: 1.107 G_L1: 7.661 D_real: 0.698 D_fake: 0.398 
(epoch: 7, iters: 348, time: 0.594, data: 0.010) G_GAN: 1.865 G_L1: 8.809 D_real: 0.221 D_fake: 0.362 
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
(epoch: 7, iters: 398, time: 0.626, data: 0.020) G_GAN: 1.663 G_L1: 10.118 D_real: 0.531 D_fake: 0.380 
(epoch: 7, iters: 448, time: 0.595, data: 0.020) G_GAN: 1.425 G_L1: 7.966 D_real: 0.565 D_fake: 0.344 
(epoch: 7, iters: 498, time: 0.598, data: 0.020) G_GAN: 1.169 G_L1: 9.645 D_real: 0.949 D_fake: 0.343 
(epoch: 7, iters: 548, time: 0.673, data: 0.010) G_GAN: 1.352 G_L1: 12.981 D_real: 0.184 D_fake: 0.360 
(epoch: 7, iters: 598, time: 0.673, data: 0.010) G_GAN: 1.014 G_L1: 8.441 D_real: 0.863 D_fake: 0.316 
(epoch: 7, iters: 648, time: 0.708, data: 0.011) G_GAN: 2.178 G_L1: 8.299 D_real: 0.243 D_fake: 0.275 
(epoch: 7, iters: 698, time: 0.678, data: 0.017) G_GAN: 1.531 G_L1: 9.785 D_real: 0.494 D_fake: 0.484 
(epoch: 7, iters: 748, time: 0.644, data: 0.011) G_GAN: 1.243 G_L1: 12.331 D_real: 0.471 D_fake: 0.526 
(epoch: 7, iters: 798, time: 3.979, data: 0.012) G_GAN: 2.601 G_L1: 10.843 D_real: 0.155 D_fake: 0.156 
(epoch: 7, iters: 848, time: 0.657, data: 0.009) G_GAN: 1.082 G_L1: 10.324 D_real: 0.479 D_fake: 0.469 
learning rate 0.0002000 -&gt; 0.0002000
End of epoch 7 / 20      Time Taken: 399 sec
(epoch: 8, iters: 31, time: 0.605, data: 0.003) G_GAN: 2.227 G_L1: 9.399 D_real: 0.465 D_fake: 0.223 
(epoch: 8, iters: 81, time: 0.694, data: 0.021) G_GAN: 0.723 G_L1: 7.408 D_real: 1.355 D_fake: 0.458 
(epoch: 8, iters: 131, time: 4.432, data: 0.010) G_GAN: 1.511 G_L1: 9.458 D_real: 0.106 D_fake: 0.642 
(epoch: 8, iters: 181, time: 0.724, data: 0.016) G_GAN: 1.546 G_L1: 10.056 D_real: 0.392 D_fake: 0.312 
(epoch: 8, iters: 231, time: 0.655, data: 0.012) G_GAN: 1.117 G_L1: 10.092 D_real: 0.128 D_fake: 1.729 
(epoch: 8, iters: 281, time: 0.674, data: 0.012) G_GAN: 1.338 G_L1: 10.013 D_real: 0.805 D_fake: 0.546 
(epoch: 8, iters: 331, time: 0.658, data: 0.012) G_GAN: 2.415 G_L1: 9.140 D_real: 0.417 D_fake: 0.190 
(epoch: 8, iters: 381, time: 0.670, data: 0.014) G_GAN: 1.018 G_L1: 12.339 D_real: 0.792 D_fake: 0.360 
(epoch: 8, iters: 431, time: 0.672, data: 0.008) G_GAN: 0.719 G_L1: 7.657 D_real: 1.021 D_fake: 0.352 
(epoch: 8, iters: 481, time: 0.678, data: 0.012) G_GAN: 1.308 G_L1: 10.845 D_real: 0.998 D_fake: 0.335 
(epoch: 8, iters: 531, time: 0.670, data: 0.011) G_GAN: 1.117 G_L1: 9.130 D_real: 0.589 D_fake: 0.408 
(epoch: 8, iters: 581, time: 0.719, data: 0.010) G_GAN: 0.705 G_L1: 8.439 D_real: 0.983 D_fake: 0.461 
(epoch: 8, iters: 631, time: 0.686, data: 0.015) G_GAN: 0.756 G_L1: 11.076 D_real: 0.981 D_fake: 0.686 
(epoch: 8, iters: 681, time: 0.676, data: 0.020) G_GAN: 1.355 G_L1: 10.116 D_real: 0.577 D_fake: 0.278 
(epoch: 8, iters: 731, time: 0.742, data: 0.007) G_GAN: 1.654 G_L1: 10.256 D_real: 0.454 D_fake: 0.218 
(epoch: 8, iters: 781, time: 0.685, data: 0.011) G_GAN: 0.472 G_L1: 8.568 D_real: 1.408 D_fake: 0.961 
(epoch: 8, iters: 831, time: 0.704, data: 0.016) G_GAN: 1.702 G_L1: 10.893 D_real: 0.143 D_fake: 0.721 
learning rate 0.0002000 -&gt; 0.0002000
saving the model at the end of epoch 8, iters 6936
End of epoch 8 / 20      Time Taken: 419 sec
(epoch: 9, iters: 14, time: 0.604, data: 0.010) G_GAN: 2.262 G_L1: 8.305 D_real: 0.186 D_fake: 0.293 
(epoch: 9, iters: 64, time: 4.429, data: 0.016) G_GAN: 0.991 G_L1: 9.437 D_real: 1.220 D_fake: 0.404 
(epoch: 9, iters: 114, time: 0.634, data: 0.016) G_GAN: 1.113 G_L1: 8.260 D_real: 0.812 D_fake: 0.312 
(epoch: 9, iters: 164, time: 0.651, data: 0.020) G_GAN: 1.156 G_L1: 7.586 D_real: 1.011 D_fake: 0.450 
(epoch: 9, iters: 214, time: 0.647, data: 0.011) G_GAN: 1.077 G_L1: 11.138 D_real: 0.662 D_fake: 0.422 
(epoch: 9, iters: 264, time: 0.760, data: 0.021) G_GAN: 0.712 G_L1: 10.231 D_real: 1.360 D_fake: 0.419 
(epoch: 9, iters: 314, time: 0.654, data: 0.009) G_GAN: 0.714 G_L1: 9.660 D_real: 1.861 D_fake: 0.733 
(epoch: 9, iters: 364, time: 0.699, data: 0.013) G_GAN: 1.528 G_L1: 8.637 D_real: 0.323 D_fake: 0.424 
(epoch: 9, iters: 414, time: 0.728, data: 0.008) G_GAN: 1.865 G_L1: 12.152 D_real: 0.044 D_fake: 0.569 
(epoch: 9, iters: 464, time: 0.688, data: 0.010) G_GAN: 1.787 G_L1: 11.499 D_real: 0.210 D_fake: 0.454 
(epoch: 9, iters: 514, time: 0.708, data: 0.010) G_GAN: 0.904 G_L1: 7.570 D_real: 1.340 D_fake: 0.346 
(epoch: 9, iters: 564, time: 0.697, data: 0.010) G_GAN: 1.157 G_L1: 9.420 D_real: 1.332 D_fake: 0.163 
(epoch: 9, iters: 614, time: 0.706, data: 0.014) G_GAN: 0.672 G_L1: 8.880 D_real: 0.846 D_fake: 0.617 
(epoch: 9, iters: 664, time: 0.758, data: 0.010) G_GAN: 1.052 G_L1: 8.508 D_real: 0.552 D_fake: 1.110 
(epoch: 9, iters: 714, time: 0.707, data: 0.021) G_GAN: 1.759 G_L1: 9.750 D_real: 0.145 D_fake: 0.323 
(epoch: 9, iters: 764, time: 0.812, data: 0.010) G_GAN: 1.972 G_L1: 9.682 D_real: 0.101 D_fake: 0.402 
(epoch: 9, iters: 814, time: 0.767, data: 0.011) G_GAN: 1.227 G_L1: 9.218 D_real: 0.187 D_fake: 1.177 
(epoch: 9, iters: 864, time: 0.736, data: 0.010) G_GAN: 2.061 G_L1: 13.227 D_real: 0.128 D_fake: 0.372 
learning rate 0.0002000 -&gt; 0.0002000
End of epoch 9 / 20      Time Taken: 425 sec
(epoch: 10, iters: 47, time: 0.729, data: 0.014) G_GAN: 1.926 G_L1: 13.837 D_real: 0.489 D_fake: 0.201 
(epoch: 10, iters: 97, time: 0.789, data: 0.010) G_GAN: 1.999 G_L1: 10.126 D_real: 0.067 D_fake: 0.635 
(epoch: 10, iters: 147, time: 7.250, data: 0.006) G_GAN: 1.805 G_L1: 12.046 D_real: 0.120 D_fake: 0.441 
(epoch: 10, iters: 197, time: 10.013, data: 0.004) G_GAN: 0.877 G_L1: 9.378 D_real: 1.127 D_fake: 0.460 
(epoch: 10, iters: 247, time: 7.187, data: 0.016) G_GAN: 1.361 G_L1: 9.163 D_real: 0.543 D_fake: 0.371 
(epoch: 10, iters: 297, time: 7.209, data: 0.000) G_GAN: 1.268 G_L1: 9.144 D_real: 0.116 D_fake: 1.372 
(epoch: 10, iters: 347, time: 7.241, data: 0.011) G_GAN: 1.003 G_L1: 9.092 D_real: 0.639 D_fake: 0.647 
(epoch: 10, iters: 397, time: 7.249, data: 0.000) G_GAN: 1.837 G_L1: 12.173 D_real: 0.145 D_fake: 0.761 
(epoch: 10, iters: 447, time: 7.201, data: 0.010) G_GAN: 1.455 G_L1: 8.384 D_real: 0.385 D_fake: 0.332 
(epoch: 10, iters: 497, time: 7.198, data: 0.010) G_GAN: 1.158 G_L1: 9.925 D_real: 0.616 D_fake: 0.439 
(epoch: 10, iters: 547, time: 7.196, data: 0.009) G_GAN: 1.494 G_L1: 10.253 D_real: 2.301 D_fake: 0.140 
(epoch: 10, iters: 597, time: 7.202, data: 0.008) G_GAN: 2.155 G_L1: 11.576 D_real: 0.457 D_fake: 0.146 
(epoch: 10, iters: 647, time: 7.192, data: 0.009) G_GAN: 2.694 G_L1: 10.622 D_real: 0.296 D_fake: 0.379 
(epoch: 10, iters: 697, time: 7.195, data: 0.010) G_GAN: 1.340 G_L1: 10.242 D_real: 0.570 D_fake: 0.411 
(epoch: 10, iters: 747, time: 7.264, data: 0.009) G_GAN: 1.696 G_L1: 10.589 D_real: 0.311 D_fake: 0.481 
(epoch: 10, iters: 797, time: 7.196, data: 0.009) G_GAN: 1.291 G_L1: 8.791 D_real: 0.325 D_fake: 0.454 
(epoch: 10, iters: 847, time: 7.247, data: 0.008) G_GAN: 1.389 G_L1: 13.207 D_real: 0.534 D_fake: 0.681 
learning rate 0.0002000 -&gt; 0.0001818
saving the model at the end of epoch 10, iters 8670
End of epoch 10 / 20     Time Taken: 2853 sec
(epoch: 11, iters: 30, time: 7.202, data: 0.008) G_GAN: 1.136 G_L1: 12.583 D_real: 0.078 D_fake: 0.455 
(epoch: 11, iters: 80, time: 7.246, data: 0.009) G_GAN: 1.488 G_L1: 9.779 D_real: 0.443 D_fake: 0.206 
(epoch: 11, iters: 130, time: 9.937, data: 0.010) G_GAN: 1.400 G_L1: 8.423 D_real: 1.887 D_fake: 0.204 
(epoch: 11, iters: 180, time: 0.677, data: 0.009) G_GAN: 1.107 G_L1: 8.335 D_real: 0.878 D_fake: 0.261 
(epoch: 11, iters: 230, time: 0.513, data: 0.010) G_GAN: 1.923 G_L1: 9.945 D_real: 0.334 D_fake: 0.257 
(epoch: 11, iters: 280, time: 0.544, data: 0.014) G_GAN: 1.037 G_L1: 9.735 D_real: 0.654 D_fake: 0.946 
(epoch: 11, iters: 330, time: 4.341, data: 0.010) G_GAN: 1.094 G_L1: 10.746 D_real: 0.716 D_fake: 0.277 
(epoch: 11, iters: 380, time: 0.503, data: 0.016) G_GAN: 1.514 G_L1: 12.449 D_real: 0.185 D_fake: 0.572 
(epoch: 11, iters: 430, time: 0.569, data: 0.010) G_GAN: 1.375 G_L1: 10.584 D_real: 0.195 D_fake: 0.599 
(epoch: 11, iters: 480, time: 0.588, data: 0.012) G_GAN: 0.921 G_L1: 9.656 D_real: 0.626 D_fake: 0.409 
(epoch: 11, iters: 530, time: 0.581, data: 0.010) G_GAN: 1.621 G_L1: 8.517 D_real: 0.520 D_fake: 0.264 
(epoch: 11, iters: 580, time: 0.580, data: 0.004) G_GAN: 1.915 G_L1: 14.112 D_real: 0.169 D_fake: 0.277 
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
(epoch: 11, iters: 630, time: 0.606, data: 0.010) G_GAN: 1.423 G_L1: 9.225 D_real: 0.788 D_fake: 0.191 
(epoch: 11, iters: 680, time: 0.597, data: 0.015) G_GAN: 0.928 G_L1: 10.440 D_real: 1.116 D_fake: 0.350 
(epoch: 11, iters: 730, time: 0.575, data: 0.015) G_GAN: 2.592 G_L1: 10.724 D_real: 0.061 D_fake: 0.166 
(epoch: 11, iters: 780, time: 0.605, data: 0.020) G_GAN: 0.681 G_L1: 9.121 D_real: 1.157 D_fake: 0.266 
(epoch: 11, iters: 830, time: 0.673, data: 0.010) G_GAN: 1.391 G_L1: 13.679 D_real: 0.124 D_fake: 0.572 
learning rate 0.0001818 -&gt; 0.0001636
End of epoch 11 / 20     Time Taken: 906 sec
(epoch: 12, iters: 13, time: 0.590, data: 0.009) G_GAN: 1.843 G_L1: 16.157 D_real: 0.039 D_fake: 0.726 
(epoch: 12, iters: 63, time: 4.099, data: 0.012) G_GAN: 2.657 G_L1: 9.555 D_real: 0.352 D_fake: 0.161 
(epoch: 12, iters: 113, time: 0.611, data: 0.016) G_GAN: 1.155 G_L1: 8.818 D_real: 0.344 D_fake: 0.588 
(epoch: 12, iters: 163, time: 0.577, data: 0.010) G_GAN: 1.779 G_L1: 11.657 D_real: 0.234 D_fake: 0.458 
(epoch: 12, iters: 213, time: 0.609, data: 0.012) G_GAN: 1.236 G_L1: 9.648 D_real: 1.309 D_fake: 0.396 
(epoch: 12, iters: 263, time: 0.579, data: 0.015) G_GAN: 1.132 G_L1: 9.464 D_real: 0.229 D_fake: 0.531 
(epoch: 12, iters: 313, time: 0.701, data: 0.007) G_GAN: 2.084 G_L1: 14.055 D_real: 0.042 D_fake: 0.228 
(epoch: 12, iters: 363, time: 0.605, data: 0.007) G_GAN: 0.950 G_L1: 12.668 D_real: 0.790 D_fake: 0.755 
(epoch: 12, iters: 413, time: 0.595, data: 0.010) G_GAN: 1.118 G_L1: 10.382 D_real: 0.198 D_fake: 0.737 
(epoch: 12, iters: 463, time: 4.163, data: 0.010) G_GAN: 1.653 G_L1: 10.415 D_real: 0.179 D_fake: 0.565 
saving the latest model (epoch 12, total_iters 10000)
(epoch: 12, iters: 513, time: 0.604, data: 0.016) G_GAN: 1.453 G_L1: 10.743 D_real: 0.063 D_fake: 0.474 
(epoch: 12, iters: 563, time: 0.614, data: 0.010) G_GAN: 1.962 G_L1: 11.335 D_real: 0.200 D_fake: 0.240 
(epoch: 12, iters: 613, time: 0.635, data: 0.016) G_GAN: 1.605 G_L1: 12.825 D_real: 0.137 D_fake: 0.797 
(epoch: 12, iters: 663, time: 0.668, data: 0.014) G_GAN: 1.442 G_L1: 9.271 D_real: 0.059 D_fake: 0.521 
(epoch: 12, iters: 713, time: 0.574, data: 0.013) G_GAN: 1.071 G_L1: 9.511 D_real: 1.421 D_fake: 0.472 
(epoch: 12, iters: 763, time: 0.605, data: 0.010) G_GAN: 1.750 G_L1: 8.504 D_real: 0.395 D_fake: 0.226 
(epoch: 12, iters: 813, time: 0.589, data: 0.016) G_GAN: 1.495 G_L1: 12.866 D_real: 0.329 D_fake: 0.292 
(epoch: 12, iters: 863, time: 0.611, data: 0.013) G_GAN: 1.326 G_L1: 8.916 D_real: 0.337 D_fake: 0.429 
learning rate 0.0001636 -&gt; 0.0001455
saving the model at the end of epoch 12, iters 10404
End of epoch 12 / 20     Time Taken: 401 sec
(epoch: 13, iters: 46, time: 0.584, data: 0.010) G_GAN: 0.949 G_L1: 9.384 D_real: 0.744 D_fake: 0.459 
(epoch: 13, iters: 96, time: 0.656, data: 0.010) G_GAN: 1.393 G_L1: 8.249 D_real: 1.039 D_fake: 0.345 
(epoch: 13, iters: 146, time: 0.614, data: 0.010) G_GAN: 2.136 G_L1: 10.622 D_real: 0.084 D_fake: 0.380 
(epoch: 13, iters: 196, time: 4.569, data: 0.010) G_GAN: 1.608 G_L1: 8.978 D_real: 0.922 D_fake: 0.162 
(epoch: 13, iters: 246, time: 0.574, data: 0.016) G_GAN: 1.418 G_L1: 9.175 D_real: 0.106 D_fake: 0.757 
(epoch: 13, iters: 296, time: 0.569, data: 0.010) G_GAN: 1.322 G_L1: 9.856 D_real: 0.539 D_fake: 0.467 
(epoch: 13, iters: 346, time: 0.658, data: 0.013) G_GAN: 1.232 G_L1: 8.542 D_real: 1.013 D_fake: 0.208 
(epoch: 13, iters: 396, time: 0.699, data: 0.011) G_GAN: 0.638 G_L1: 8.683 D_real: 1.216 D_fake: 0.394 
(epoch: 13, iters: 446, time: 0.578, data: 0.010) G_GAN: 1.359 G_L1: 10.706 D_real: 0.992 D_fake: 0.228 
(epoch: 13, iters: 496, time: 0.580, data: 0.010) G_GAN: 1.375 G_L1: 9.361 D_real: 0.237 D_fake: 0.990 
(epoch: 13, iters: 546, time: 0.605, data: 0.013) G_GAN: 1.252 G_L1: 9.405 D_real: 0.186 D_fake: 0.594 
(epoch: 13, iters: 596, time: 4.176, data: 0.010) G_GAN: 1.408 G_L1: 9.856 D_real: 0.317 D_fake: 0.332 
(epoch: 13, iters: 646, time: 0.626, data: 0.018) G_GAN: 1.950 G_L1: 13.597 D_real: 0.282 D_fake: 0.346 
(epoch: 13, iters: 696, time: 0.677, data: 0.010) G_GAN: 1.249 G_L1: 13.702 D_real: 0.444 D_fake: 0.770 
(epoch: 13, iters: 746, time: 0.647, data: 0.020) G_GAN: 1.629 G_L1: 9.662 D_real: 0.639 D_fake: 0.256 
(epoch: 13, iters: 796, time: 0.666, data: 0.010) G_GAN: 2.287 G_L1: 13.896 D_real: 0.133 D_fake: 0.156 
(epoch: 13, iters: 846, time: 0.617, data: 0.010) G_GAN: 1.176 G_L1: 9.655 D_real: 0.559 D_fake: 0.465 
learning rate 0.0001455 -&gt; 0.0001273
End of epoch 13 / 20     Time Taken: 394 sec
(epoch: 14, iters: 29, time: 0.579, data: 0.010) G_GAN: 1.318 G_L1: 12.268 D_real: 0.767 D_fake: 0.630 
(epoch: 14, iters: 79, time: 0.598, data: 0.012) G_GAN: 1.477 G_L1: 10.148 D_real: 0.628 D_fake: 0.181 
(epoch: 14, iters: 129, time: 4.306, data: 0.010) G_GAN: 1.955 G_L1: 10.556 D_real: 0.107 D_fake: 0.301 
(epoch: 14, iters: 179, time: 0.594, data: 0.011) G_GAN: 1.326 G_L1: 9.080 D_real: 0.115 D_fake: 0.533 
(epoch: 14, iters: 229, time: 0.554, data: 0.010) G_GAN: 1.527 G_L1: 9.681 D_real: 0.044 D_fake: 0.382 
(epoch: 14, iters: 279, time: 0.656, data: 0.000) G_GAN: 0.957 G_L1: 10.664 D_real: 0.948 D_fake: 0.526 
(epoch: 14, iters: 329, time: 0.625, data: 0.010) G_GAN: 1.694 G_L1: 12.257 D_real: 0.639 D_fake: 0.764 
(epoch: 14, iters: 379, time: 0.657, data: 0.010) G_GAN: 0.891 G_L1: 8.716 D_real: 0.621 D_fake: 0.527 
(epoch: 14, iters: 429, time: 0.615, data: 0.000) G_GAN: 1.134 G_L1: 10.040 D_real: 0.258 D_fake: 0.520 
(epoch: 14, iters: 479, time: 0.631, data: 0.041) G_GAN: 1.257 G_L1: 9.286 D_real: 0.119 D_fake: 1.027 
(epoch: 14, iters: 529, time: 0.604, data: 0.015) G_GAN: 1.757 G_L1: 10.821 D_real: 0.316 D_fake: 0.405 
(epoch: 14, iters: 579, time: 0.614, data: 0.009) G_GAN: 1.824 G_L1: 8.802 D_real: 0.761 D_fake: 0.209 
(epoch: 14, iters: 629, time: 0.630, data: 0.009) G_GAN: 1.637 G_L1: 10.303 D_real: 0.323 D_fake: 0.423 
(epoch: 14, iters: 679, time: 0.664, data: 0.020) G_GAN: 1.506 G_L1: 10.023 D_real: 0.438 D_fake: 0.714 
(epoch: 14, iters: 729, time: 4.516, data: 0.007) G_GAN: 1.223 G_L1: 9.602 D_real: 0.228 D_fake: 0.702 
(epoch: 14, iters: 779, time: 0.719, data: 0.016) G_GAN: 1.120 G_L1: 9.355 D_real: 0.963 D_fake: 0.547 
(epoch: 14, iters: 829, time: 0.621, data: 0.014) G_GAN: 1.250 G_L1: 10.434 D_real: 0.478 D_fake: 0.444 
learning rate 0.0001273 -&gt; 0.0001091
saving the model at the end of epoch 14, iters 12138
End of epoch 14 / 20     Time Taken: 403 sec
(epoch: 15, iters: 12, time: 0.647, data: 0.004) G_GAN: 0.957 G_L1: 9.874 D_real: 0.337 D_fake: 0.744 
(epoch: 15, iters: 62, time: 4.626, data: 0.009) G_GAN: 0.838 G_L1: 8.217 D_real: 0.100 D_fake: 1.199 
(epoch: 15, iters: 112, time: 0.616, data: 0.011) G_GAN: 2.037 G_L1: 10.652 D_real: 0.353 D_fake: 0.158 
(epoch: 15, iters: 162, time: 0.644, data: 0.020) G_GAN: 1.067 G_L1: 8.094 D_real: 0.365 D_fake: 0.581 
(epoch: 15, iters: 212, time: 0.667, data: 0.007) G_GAN: 1.130 G_L1: 8.894 D_real: 0.896 D_fake: 0.344 
(epoch: 15, iters: 262, time: 0.671, data: 0.017) G_GAN: 0.799 G_L1: 8.909 D_real: 0.943 D_fake: 0.768 
(epoch: 15, iters: 312, time: 0.726, data: 0.012) G_GAN: 1.210 G_L1: 13.113 D_real: 0.256 D_fake: 0.723 
(epoch: 15, iters: 362, time: 0.687, data: 0.010) G_GAN: 1.244 G_L1: 9.708 D_real: 0.375 D_fake: 0.407 
(epoch: 15, iters: 412, time: 0.688, data: 0.021) G_GAN: 1.858 G_L1: 15.108 D_real: 0.063 D_fake: 0.260 
(epoch: 15, iters: 462, time: 0.707, data: 0.010) G_GAN: 1.942 G_L1: 10.671 D_real: 0.355 D_fake: 0.232 
(epoch: 15, iters: 512, time: 0.617, data: 0.010) G_GAN: 0.931 G_L1: 10.123 D_real: 0.669 D_fake: 0.777 
(epoch: 15, iters: 562, time: 0.666, data: 0.010) G_GAN: 2.017 G_L1: 12.348 D_real: 0.164 D_fake: 0.211 
(epoch: 15, iters: 612, time: 0.698, data: 0.010) G_GAN: 1.000 G_L1: 11.436 D_real: 0.702 D_fake: 0.593 
(epoch: 15, iters: 662, time: 0.671, data: 0.010) G_GAN: 1.945 G_L1: 10.275 D_real: 0.583 D_fake: 0.209 
(epoch: 15, iters: 712, time: 0.740, data: 0.008) G_GAN: 1.830 G_L1: 9.141 D_real: 0.319 D_fake: 0.240 
(epoch: 15, iters: 762, time: 0.675, data: 0.013) G_GAN: 1.025 G_L1: 8.051 D_real: 0.542 D_fake: 0.389 
(epoch: 15, iters: 812, time: 0.713, data: 0.010) G_GAN: 0.683 G_L1: 8.561 D_real: 0.517 D_fake: 0.886 
(epoch: 15, iters: 862, time: 4.318, data: 0.012) G_GAN: 1.106 G_L1: 10.352 D_real: 0.496 D_fake: 0.552 
learning rate 0.0001091 -&gt; 0.0000909
End of epoch 15 / 20     Time Taken: 420 sec
(epoch: 16, iters: 45, time: 0.698, data: 0.010) G_GAN: 1.162 G_L1: 9.160 D_real: 1.159 D_fake: 0.333 
(epoch: 16, iters: 95, time: 0.625, data: 0.012) G_GAN: 0.928 G_L1: 8.097 D_real: 0.738 D_fake: 0.471 
(epoch: 16, iters: 145, time: 0.644, data: 0.008) G_GAN: 0.830 G_L1: 7.486 D_real: 0.490 D_fake: 0.733 
(epoch: 16, iters: 195, time: 4.060, data: 0.016) G_GAN: 0.793 G_L1: 12.792 D_real: 0.327 D_fake: 0.644 
(epoch: 16, iters: 245, time: 0.650, data: 0.009) G_GAN: 1.302 G_L1: 10.269 D_real: 0.261 D_fake: 0.482 
(epoch: 16, iters: 295, time: 0.646, data: 0.010) G_GAN: 1.185 G_L1: 8.851 D_real: 0.365 D_fake: 0.595 
(epoch: 16, iters: 345, time: 0.729, data: 0.012) G_GAN: 1.228 G_L1: 9.902 D_real: 0.597 D_fake: 0.410 
(epoch: 16, iters: 395, time: 0.676, data: 0.008) G_GAN: 1.115 G_L1: 8.650 D_real: 0.227 D_fake: 0.545 
(epoch: 16, iters: 445, time: 0.718, data: 0.015) G_GAN: 0.621 G_L1: 7.480 D_real: 1.152 D_fake: 0.832 
(epoch: 16, iters: 495, time: 0.824, data: 0.006) G_GAN: 0.919 G_L1: 12.272 D_real: 0.340 D_fake: 0.859 
(epoch: 16, iters: 545, time: 0.666, data: 0.011) G_GAN: 1.172 G_L1: 10.734 D_real: 0.195 D_fake: 0.572 
(epoch: 16, iters: 595, time: 0.799, data: 0.010) G_GAN: 1.416 G_L1: 8.505 D_real: 0.752 D_fake: 0.237 
(epoch: 16, iters: 645, time: 0.702, data: 0.014) G_GAN: 1.037 G_L1: 8.790 D_real: 1.063 D_fake: 0.265 
(epoch: 16, iters: 695, time: 0.692, data: 0.020) G_GAN: 0.894 G_L1: 9.445 D_real: 0.590 D_fake: 0.700 
(epoch: 16, iters: 745, time: 0.705, data: 0.014) G_GAN: 1.216 G_L1: 11.842 D_real: 0.718 D_fake: 0.600 
(epoch: 16, iters: 795, time: 0.693, data: 0.015) G_GAN: 1.670 G_L1: 9.374 D_real: 0.928 D_fake: 0.187 
(epoch: 16, iters: 845, time: 0.731, data: 0.012) G_GAN: 1.106 G_L1: 10.089 D_real: 0.150 D_fake: 0.778 
learning rate 0.0000909 -&gt; 0.0000727
saving the model at the end of epoch 16, iters 13872
End of epoch 16 / 20     Time Taken: 421 sec
(epoch: 17, iters: 28, time: 0.679, data: 0.009) G_GAN: 1.255 G_L1: 7.845 D_real: 0.446 D_fake: 0.407 
(epoch: 17, iters: 78, time: 0.670, data: 0.010) G_GAN: 1.119 G_L1: 8.756 D_real: 0.769 D_fake: 0.301 
(epoch: 17, iters: 128, time: 4.162, data: 0.010) G_GAN: 1.054 G_L1: 9.694 D_real: 0.302 D_fake: 1.028 
(epoch: 17, iters: 178, time: 0.688, data: 0.014) G_GAN: 1.045 G_L1: 8.351 D_real: 0.639 D_fake: 0.327 
(epoch: 17, iters: 228, time: 0.738, data: 0.013) G_GAN: 1.495 G_L1: 9.631 D_real: 0.661 D_fake: 0.274 
(epoch: 17, iters: 278, time: 0.717, data: 0.011) G_GAN: 0.807 G_L1: 11.311 D_real: 0.177 D_fake: 0.751 
(epoch: 17, iters: 328, time: 0.846, data: 0.016) G_GAN: 1.452 G_L1: 9.227 D_real: 0.479 D_fake: 0.303 
(epoch: 17, iters: 378, time: 0.981, data: 0.010) G_GAN: 1.058 G_L1: 10.117 D_real: 0.262 D_fake: 1.017 
(epoch: 17, iters: 428, time: 0.799, data: 0.010) G_GAN: 1.253 G_L1: 9.666 D_real: 0.723 D_fake: 0.329 
(epoch: 17, iters: 478, time: 0.757, data: 0.014) G_GAN: 1.049 G_L1: 10.458 D_real: 0.242 D_fake: 0.641 
(epoch: 17, iters: 528, time: 0.714, data: 0.010) G_GAN: 1.304 G_L1: 9.937 D_real: 0.400 D_fake: 0.456 
(epoch: 17, iters: 578, time: 7.202, data: 0.010) G_GAN: 1.357 G_L1: 10.899 D_real: 0.061 D_fake: 0.437 
(epoch: 17, iters: 628, time: 7.242, data: 0.000) G_GAN: 1.052 G_L1: 8.294 D_real: 0.277 D_fake: 0.707 
(epoch: 17, iters: 678, time: 7.261, data: 0.016) G_GAN: 1.059 G_L1: 8.018 D_real: 0.432 D_fake: 0.634 
(epoch: 17, iters: 728, time: 7.256, data: 0.010) G_GAN: 1.285 G_L1: 9.618 D_real: 0.330 D_fake: 0.567 
(epoch: 17, iters: 778, time: 7.250, data: 0.000) G_GAN: 0.874 G_L1: 13.473 D_real: 0.131 D_fake: 1.250 
(epoch: 17, iters: 828, time: 7.194, data: 0.016) G_GAN: 1.112 G_L1: 11.345 D_real: 0.586 D_fake: 0.830 
learning rate 0.0000727 -&gt; 0.0000545
End of epoch 17 / 20     Time Taken: 1412 sec
(epoch: 18, iters: 11, time: 7.200, data: 0.004) G_GAN: 0.813 G_L1: 12.735 D_real: 0.276 D_fake: 0.737 
(epoch: 18, iters: 61, time: 9.919, data: 0.009) G_GAN: 1.125 G_L1: 7.702 D_real: 0.858 D_fake: 0.351 
(epoch: 18, iters: 111, time: 7.247, data: 0.009) G_GAN: 0.629 G_L1: 9.868 D_real: 0.726 D_fake: 1.164 
(epoch: 18, iters: 161, time: 7.256, data: 0.016) G_GAN: 0.956 G_L1: 8.837 D_real: 0.449 D_fake: 0.604 
(epoch: 18, iters: 211, time: 7.202, data: 0.016) G_GAN: 1.162 G_L1: 9.712 D_real: 0.156 D_fake: 0.784 
(epoch: 18, iters: 261, time: 9.758, data: 0.000) G_GAN: 0.852 G_L1: 12.080 D_real: 0.491 D_fake: 0.645 
saving the latest model (epoch 18, total_iters 15000)
(epoch: 18, iters: 311, time: 7.199, data: 0.016) G_GAN: 1.258 G_L1: 17.469 D_real: 0.049 D_fake: 0.577 
(epoch: 18, iters: 361, time: 0.569, data: 0.009) G_GAN: 0.862 G_L1: 13.317 D_real: 0.176 D_fake: 0.790 
(epoch: 18, iters: 411, time: 0.547, data: 0.011) G_GAN: 0.804 G_L1: 7.427 D_real: 0.781 D_fake: 0.644 
(epoch: 18, iters: 461, time: 0.604, data: 0.010) G_GAN: 1.159 G_L1: 10.033 D_real: 0.436 D_fake: 0.526 
(epoch: 18, iters: 511, time: 0.543, data: 0.020) G_GAN: 1.228 G_L1: 16.399 D_real: 0.331 D_fake: 0.427 
(epoch: 18, iters: 561, time: 0.601, data: 0.010) G_GAN: 0.737 G_L1: 11.445 D_real: 0.114 D_fake: 0.954 
(epoch: 18, iters: 611, time: 0.613, data: 0.016) G_GAN: 0.939 G_L1: 8.472 D_real: 0.674 D_fake: 0.616 
(epoch: 18, iters: 661, time: 0.612, data: 0.010) G_GAN: 0.790 G_L1: 12.359 D_real: 0.337 D_fake: 0.758 
(epoch: 18, iters: 711, time: 0.675, data: 0.010) G_GAN: 0.924 G_L1: 9.144 D_real: 0.158 D_fake: 0.790 
(epoch: 18, iters: 761, time: 0.662, data: 0.010) G_GAN: 1.068 G_L1: 7.729 D_real: 0.530 D_fake: 0.451 
(epoch: 18, iters: 811, time: 0.607, data: 0.010) G_GAN: 1.020 G_L1: 11.481 D_real: 0.546 D_fake: 0.681 
(epoch: 18, iters: 861, time: 0.636, data: 0.010) G_GAN: 1.477 G_L1: 12.462 D_real: 0.250 D_fake: 0.331 
learning rate 0.0000545 -&gt; 0.0000364
saving the model at the end of epoch 18, iters 15606
End of epoch 18 / 20     Time Taken: 1513 sec
(epoch: 19, iters: 44, time: 0.590, data: 0.021) G_GAN: 1.732 G_L1: 9.671 D_real: 1.354 D_fake: 0.179 
(epoch: 19, iters: 94, time: 0.555, data: 0.015) G_GAN: 1.368 G_L1: 11.626 D_real: 0.688 D_fake: 0.311 
(epoch: 19, iters: 144, time: 0.574, data: 0.020) G_GAN: 1.012 G_L1: 9.186 D_real: 0.489 D_fake: 0.628 
(epoch: 19, iters: 194, time: 4.179, data: 0.010) G_GAN: 0.707 G_L1: 7.888 D_real: 0.558 D_fake: 0.715 
(epoch: 19, iters: 244, time: 0.565, data: 0.016) G_GAN: 1.231 G_L1: 12.188 D_real: 0.692 D_fake: 0.418 
(epoch: 19, iters: 294, time: 0.575, data: 0.010) G_GAN: 1.262 G_L1: 9.621 D_real: 0.933 D_fake: 0.252 
(epoch: 19, iters: 344, time: 0.616, data: 0.010) G_GAN: 1.163 G_L1: 11.022 D_real: 0.315 D_fake: 0.479 
(epoch: 19, iters: 394, time: 4.033, data: 0.010) G_GAN: 1.359 G_L1: 9.972 D_real: 0.529 D_fake: 0.290 
(epoch: 19, iters: 444, time: 0.597, data: 0.047) G_GAN: 1.158 G_L1: 10.208 D_real: 0.244 D_fake: 0.541 
(epoch: 19, iters: 494, time: 0.697, data: 0.007) G_GAN: 1.113 G_L1: 14.248 D_real: 0.117 D_fake: 0.553 
(epoch: 19, iters: 544, time: 0.613, data: 0.010) G_GAN: 0.942 G_L1: 8.825 D_real: 0.941 D_fake: 0.451 
(epoch: 19, iters: 594, time: 0.655, data: 0.008) G_GAN: 1.203 G_L1: 11.578 D_real: 0.338 D_fake: 0.446 
(epoch: 19, iters: 644, time: 0.653, data: 0.012) G_GAN: 0.795 G_L1: 9.845 D_real: 0.471 D_fake: 0.899 
(epoch: 19, iters: 694, time: 0.696, data: 0.012) G_GAN: 1.172 G_L1: 10.684 D_real: 0.743 D_fake: 0.314 
(epoch: 19, iters: 744, time: 0.596, data: 0.020) G_GAN: 1.032 G_L1: 8.995 D_real: 0.808 D_fake: 0.540 
(epoch: 19, iters: 794, time: 0.683, data: 0.010) G_GAN: 1.133 G_L1: 13.388 D_real: 0.188 D_fake: 0.511 
(epoch: 19, iters: 844, time: 0.630, data: 0.016) G_GAN: 1.021 G_L1: 15.529 D_real: 0.147 D_fake: 0.595 
learning rate 0.0000364 -&gt; 0.0000182
End of epoch 19 / 20     Time Taken: 382 sec
(epoch: 20, iters: 27, time: 0.625, data: 0.008) G_GAN: 1.456 G_L1: 10.559 D_real: 0.452 D_fake: 0.330 
(epoch: 20, iters: 77, time: 0.591, data: 0.010) G_GAN: 1.222 G_L1: 8.591 D_real: 0.499 D_fake: 0.412 
(epoch: 20, iters: 127, time: 4.283, data: 0.011) G_GAN: 1.980 G_L1: 10.588 D_real: 0.281 D_fake: 0.186 
(epoch: 20, iters: 177, time: 0.642, data: 0.010) G_GAN: 1.121 G_L1: 7.062 D_real: 1.033 D_fake: 0.406 
(epoch: 20, iters: 227, time: 0.663, data: 0.010) G_GAN: 1.737 G_L1: 10.024 D_real: 0.113 D_fake: 0.231 
(epoch: 20, iters: 277, time: 0.643, data: 0.006) G_GAN: 1.339 G_L1: 8.759 D_real: 0.762 D_fake: 0.301 
(epoch: 20, iters: 327, time: 0.624, data: 0.010) G_GAN: 1.574 G_L1: 16.936 D_real: 0.091 D_fake: 0.304 
(epoch: 20, iters: 377, time: 0.656, data: 0.010) G_GAN: 1.268 G_L1: 11.698 D_real: 0.480 D_fake: 0.352 
(epoch: 20, iters: 427, time: 0.666, data: 0.010) G_GAN: 0.435 G_L1: 9.623 D_real: 0.357 D_fake: 1.399 
(epoch: 20, iters: 477, time: 0.636, data: 0.011) G_GAN: 1.077 G_L1: 8.772 D_real: 0.840 D_fake: 0.396 
(epoch: 20, iters: 527, time: 3.937, data: 0.010) G_GAN: 0.992 G_L1: 10.066 D_real: 0.408 D_fake: 0.527 
(epoch: 20, iters: 577, time: 0.648, data: 0.016) G_GAN: 1.423 G_L1: 8.487 D_real: 0.396 D_fake: 0.318 
(epoch: 20, iters: 627, time: 0.657, data: 0.010) G_GAN: 1.908 G_L1: 9.315 D_real: 0.721 D_fake: 0.164 
(epoch: 20, iters: 677, time: 0.646, data: 0.010) G_GAN: 0.980 G_L1: 9.420 D_real: 0.907 D_fake: 0.509 
(epoch: 20, iters: 727, time: 0.634, data: 0.010) G_GAN: 2.030 G_L1: 9.123 D_real: 0.338 D_fake: 0.165 
(epoch: 20, iters: 777, time: 0.615, data: 0.020) G_GAN: 0.852 G_L1: 8.986 D_real: 1.258 D_fake: 0.511 
(epoch: 20, iters: 827, time: 0.670, data: 0.010) G_GAN: 0.953 G_L1: 12.035 D_real: 0.195 D_fake: 0.590 
learning rate 0.0000182 -&gt; 0.0000000
saving the model at the end of epoch 20, iters 17340
End of epoch 20 / 20     Time Taken: 404 sec
</code></pre>
</div>
</div>
<div id="c1602439-ebf8-4680-b9dc-71712f3fe7cb" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, subprocess, shlex</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># === CONFIG ===</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>repo_dir <span class="op">=</span> <span class="vs">r"C:</span><span class="er">\</span><span class="vs">Users</span><span class="er">\</span><span class="vs">yalda</span><span class="er">\</span><span class="vs">OneDrive</span><span class="dv">\D</span><span class="vs">esktop</span><span class="er">\</span><span class="vs">Thesis apps</span><span class="er">\</span><span class="vs">Project Folder</span><span class="er">\</span><span class="vs">pytorch-CycleGAN-and-pix2pix"</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>dataroot <span class="op">=</span> os.path.join(repo_dir, <span class="st">"datasets"</span>, <span class="st">"stopmotion_pix2pix"</span>)  </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>exp_name <span class="op">=</span> <span class="st">"stopmotion_pix2pix"</span>  </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>epoch <span class="op">=</span> <span class="st">"latest"</span>  </span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>gpu_ids <span class="op">=</span> <span class="st">"0"</span>     </span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>num_test <span class="op">=</span> <span class="st">"1000"</span> </span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>os.chdir(repo_dir)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CWD:"</span>, os.getcwd())</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>cmd <span class="op">=</span> <span class="ss">f'python test.py --dataroot "</span><span class="sc">{</span>dataroot<span class="sc">}</span><span class="ss">" --name </span><span class="sc">{</span>exp_name<span class="sc">}</span><span class="ss"> --model pix2pix --direction AtoB --epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss"> --num_test </span><span class="sc">{</span>num_test<span class="sc">}</span><span class="ss"> --gpu_ids </span><span class="sc">{</span>gpu_ids<span class="sc">}</span><span class="ss"> --results_dir "</span><span class="sc">{</span>os<span class="sc">.</span>path<span class="sc">.</span>join(repo_dir, <span class="st">"results"</span>)<span class="sc">}</span><span class="ss">" --load_size 1024 --crop_size 1024'</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Running:"</span>, cmd)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>proc <span class="op">=</span> subprocess.run(shlex.split(cmd), stdout<span class="op">=</span>subprocess.PIPE, stderr<span class="op">=</span>subprocess.STDOUT, text<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(proc.stdout)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>CWD: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix
Running: python test.py --dataroot "C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\datasets\stopmotion_pix2pix" --name stopmotion_pix2pix --model pix2pix --direction AtoB --epoch latest --num_test 1000 --gpu_ids 0 --results_dir "C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results" --load_size 1024 --crop_size 1024
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
W0808 19:27:12.337000 31020 site-packages\torch\_logging\_internal.py:1081] [0/0] Profiler function &lt;class 'torch.autograd.profiler.record_function'&gt; will be ignored
----------------- Options ---------------
             aspect_ratio: 1.0                           
               batch_size: 1                             
          checkpoints_dir: ./checkpoints                 
                crop_size: 1024                             [default: 256]
                 dataroot: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\datasets\stopmotion_pix2pix  [default: None]
             dataset_mode: aligned                       
                direction: AtoB                          
          display_winsize: 256                           
                    epoch: latest                        
                     eval: False                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: False                            [default: None]
                load_iter: 0                                [default: 0]
                load_size: 1024                             [default: 256]
         max_dataset_size: inf                           
                    model: pix2pix                          [default: test]
               n_layers_D: 3                             
                     name: stopmotion_pix2pix               [default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: unet_256                      
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: False                         
                     norm: batch                         
                 num_test: 1000                             [default: 50]
              num_threads: 4                             
                output_nc: 3                             
                    phase: test                          
               preprocess: resize_and_crop               
              results_dir: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results  [default: ./results/]
           serial_batches: False                         
                   suffix:                               
                use_wandb: False                         
                  verbose: False                         
       wandb_project_name: CycleGAN-and-pix2pix          
----------------- End -------------------
dataset [AlignedDataset] was created
initialize network with normal
model [Pix2PixModel] was created
loading the model from checkpoints\stopmotion_pix2pix\latest_net_G.pth
---------- Networks initialized -------------
[Network G] Total number of parameters : 54.414 M
-----------------------------------------------
[Network G] compiled with torch.compile
creating web directory C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results\stopmotion_pix2pix\test_latest
Traceback (most recent call last):
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1446, in _call_user_compiler
    compiled_fn = compiler_fn(gm, self.example_inputs())
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\repro\after_dynamo.py", line 129, in __call__
    compiled_gm = compiler_fn(gm, example_inputs)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\__init__.py", line 2234, in __call__
    return compile_fx(model_, inputs_, config_patches=self.config)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1521, in compile_fx
    return aot_autograd(
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\backends\common.py", line 72, in __call__
    cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 1071, in aot_module_simplified
    compiled_fn = dispatch_and_compile()
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 1056, in dispatch_and_compile
    compiled_fn, _ = create_aot_dispatcher_function(
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 522, in create_aot_dispatcher_function
    return _create_aot_dispatcher_function(
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\aot_autograd.py", line 759, in _create_aot_dispatcher_function
    compiled_fn, fw_metadata = compiler_fn(
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_functorch\_aot_autograd\jit_compile_runtime_wrappers.py", line 179, in aot_dispatch_base
    compiled_fw = compiler(fw_module, updated_flat_args)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1350, in fw_compiler_base
    return _fw_compiler_base(model, example_inputs, is_inference)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 1421, in _fw_compiler_base
    return inner_compile(
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 475, in compile_fx_inner
    return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\repro\after_aot.py", line 85, in debug_wrapper
    inner_compiled_fn = compiler_fn(gm, example_inputs)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 661, in _compile_fx_inner
    compiled_graph = FxGraphCache.load(
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\codecache.py", line 1334, in load
    compiled_graph = compile_fx_fn(
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 570, in codegen_and_compile
    compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\compile_fx.py", line 878, in fx_codegen_and_compile
    compiled_fn = graph.compile_to_fn()
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1913, in compile_to_fn
    return self.compile_to_module().call
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1839, in compile_to_module
    return self._compile_to_module()
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1845, in _compile_to_module
    self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\graph.py", line 1780, in codegen
    self.scheduler = Scheduler(self.operations)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1731, in __init__
    self._init(nodes)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1749, in _init
    self.nodes = [self.create_scheduler_node(n) for n in nodes]
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1749, in &lt;listcomp&gt;
    self.nodes = [self.create_scheduler_node(n) for n in nodes]
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 1856, in create_scheduler_node
    return SchedulerNode(self, node)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 833, in __init__
    self._compute_attrs()
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 846, in _compute_attrs
    group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 3360, in get_backend
    self.backends[device] = self.create_backend(device)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_inductor\scheduler.py", line 3352, in create_backend
    raise RuntimeError(
RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\test.py", line 71, in &lt;module&gt;
    model.test()  # run inference
  File "C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\models\base_model.py", line 112, in test
    self.forward()
  File "C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\models\pix2pix_model.py", line 88, in forward
    self.fake_B = self.netG(self.real_A)  # G(A)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\eval_frame.py", line 465, in _fn
    return fn(*args, **kwargs)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\external_utils.py", line 40, in inner
    return fn(*args, **kwargs)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\nn\parallel\data_parallel.py", line 191, in forward
    return self.module(*inputs[0], **module_kwargs[0])
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 1269, in __call__
    return self._torchdynamo_orig_callable(
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 1064, in __call__
    result = self._inner_convert(
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 526, in __call__
    return _compile(
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 924, in _compile
    guarded_code = compile_inner(code, one_graph, hooks, transform)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 666, in compile_inner
    return _compile_inner(code, one_graph, hooks, transform)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_utils_internal.py", line 87, in wrapper_function
    return function(*args, **kwargs)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 699, in _compile_inner
    out_code = transform_code_object(code, transform)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\bytecode_transformation.py", line 1322, in transform_code_object
    transformations(instructions, code_options)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 219, in _fn
    return fn(*args, **kwargs)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\convert_frame.py", line 634, in transform
    tracer.run()
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2796, in run
    super().run()
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 983, in run
    while self.step():
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 895, in step
    self.dispatch_table[inst.opcode](self, inst)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2987, in RETURN_VALUE
    self._return(inst)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\symbolic_convert.py", line 2972, in _return
    self.output.compile_subgraph(
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1117, in compile_subgraph
    self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1369, in compile_and_call_fx_graph
    compiled_fn = self.call_user_compiler(gm)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1416, in call_user_compiler
    return self._call_user_compiler(gm)
  File "C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\torch\_dynamo\output_graph.py", line 1465, in _call_user_compiler
    raise BackendCompilerFailed(self.compiler_fn, e) from e
torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton

Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


You can suppress this exception and fall back to eager by setting:
    import torch._dynamo
    torch._dynamo.config.suppress_errors = True

</code></pre>
</div>
</div>
<div id="cae201a2-f994-4b72-93d7-60229e81eade" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, subprocess, shlex</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"TORCHINDUCTOR_DISABLE"</span>] <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"TORCH_COMPILE_DISABLE"</span>]  <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"TORCHDYNAMO_DISABLE"</span>]    <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># === CONFIG ===</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>repo_dir <span class="op">=</span> <span class="vs">r"C:</span><span class="er">\</span><span class="vs">Users</span><span class="er">\</span><span class="vs">yalda</span><span class="er">\</span><span class="vs">OneDrive</span><span class="dv">\D</span><span class="vs">esktop</span><span class="er">\</span><span class="vs">Thesis apps</span><span class="er">\</span><span class="vs">Project Folder</span><span class="er">\</span><span class="vs">pytorch-CycleGAN-and-pix2pix"</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>dataroot <span class="op">=</span> os.path.join(repo_dir, <span class="st">"datasets"</span>, <span class="st">"stopmotion_pix2pix"</span>)  </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>exp_name <span class="op">=</span> <span class="st">"stopmotion_pix2pix"</span> </span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>epoch <span class="op">=</span> <span class="st">"latest"</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>gpu_ids <span class="op">=</span> <span class="st">"0"</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>num_test <span class="op">=</span> <span class="st">"1000"</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>os.chdir(repo_dir)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CWD:"</span>, os.getcwd())</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>cmd <span class="op">=</span> <span class="ss">f'python test.py --dataroot "</span><span class="sc">{</span>dataroot<span class="sc">}</span><span class="ss">" --name </span><span class="sc">{</span>exp_name<span class="sc">}</span><span class="ss"> --model pix2pix --direction AtoB --epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss"> --num_test </span><span class="sc">{</span>num_test<span class="sc">}</span><span class="ss"> --gpu_ids </span><span class="sc">{</span>gpu_ids<span class="sc">}</span><span class="ss"> --results_dir "</span><span class="sc">{</span>os<span class="sc">.</span>path<span class="sc">.</span>join(repo_dir, <span class="st">"results"</span>)<span class="sc">}</span><span class="ss">" --load_size 1024 --crop_size 1024'</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Running:"</span>, cmd)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>proc <span class="op">=</span> subprocess.run(shlex.split(cmd), stdout<span class="op">=</span>subprocess.PIPE, stderr<span class="op">=</span>subprocess.STDOUT, text<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(proc.stdout)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>CWD: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix
Running: python test.py --dataroot "C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\datasets\stopmotion_pix2pix" --name stopmotion_pix2pix --model pix2pix --direction AtoB --epoch latest --num_test 1000 --gpu_ids 0 --results_dir "C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results" --load_size 1024 --crop_size 1024
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
----------------- Options ---------------
             aspect_ratio: 1.0                           
               batch_size: 1                             
          checkpoints_dir: ./checkpoints                 
                crop_size: 1024                             [default: 256]
                 dataroot: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\datasets\stopmotion_pix2pix  [default: None]
             dataset_mode: aligned                       
                direction: AtoB                          
          display_winsize: 256                           
                    epoch: latest                        
                     eval: False                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: False                            [default: None]
                load_iter: 0                                [default: 0]
                load_size: 1024                             [default: 256]
         max_dataset_size: inf                           
                    model: pix2pix                          [default: test]
               n_layers_D: 3                             
                     name: stopmotion_pix2pix               [default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: unet_256                      
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: False                         
                     norm: batch                         
                 num_test: 1000                             [default: 50]
              num_threads: 4                             
                output_nc: 3                             
                    phase: test                          
               preprocess: resize_and_crop               
              results_dir: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results  [default: ./results/]
           serial_batches: False                         
                   suffix:                               
                use_wandb: False                         
                  verbose: False                         
       wandb_project_name: CycleGAN-and-pix2pix          
----------------- End -------------------
dataset [AlignedDataset] was created
initialize network with normal
model [Pix2PixModel] was created
loading the model from checkpoints\stopmotion_pix2pix\latest_net_G.pth
---------- Networks initialized -------------
[Network G] Total number of parameters : 54.414 M
-----------------------------------------------
[Network G] compiled with torch.compile
creating web directory C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results\stopmotion_pix2pix\test_latest
processing (0000)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_Hiphopdancing_20003.png']
processing (0005)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_Hiphopdancing_20049.png']
processing (0010)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20060.png']
processing (0015)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20087.png']
processing (0020)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20137.png']
processing (0025)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20210.png']
processing (0030)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20260.png']
processing (0035)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20313.png']
processing (0040)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_sittinglaughing_20034.png']
processing (0045)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_sittinglaughing_20124.png']
processing (0050)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_walking_20030.png']
processing (0055)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Hiphopdancing_20057.png']
processing (0060)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Sittinglaughing_20026.png']
processing (0065)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Sittinglaughing_20081.png']
processing (0070)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Sittinglaughing_20114.png']
processing (0075)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_dying_20002.png']
processing (0080)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_dying_20046.png']
processing (0085)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_dying_20068.png']
processing (0090)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_sittingcrawling_20016.png']
processing (0095)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_sittingcrawling_20031.png']
</code></pre>
</div>
</div>
<div id="5125b5fe-b05f-49da-b7cf-576fb8c40f61" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, shlex, subprocess</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>repo_dir <span class="op">=</span> <span class="vs">r"C:</span><span class="er">\</span><span class="vs">Users</span><span class="er">\</span><span class="vs">yalda</span><span class="er">\</span><span class="vs">OneDrive</span><span class="dv">\D</span><span class="vs">esktop</span><span class="er">\</span><span class="vs">Thesis apps</span><span class="er">\</span><span class="vs">Project Folder</span><span class="er">\</span><span class="vs">pytorch-CycleGAN-and-pix2pix"</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>os.chdir(repo_dir)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CWD:"</span>, os.getcwd())</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>cmd <span class="op">=</span> <span class="vs">r"""</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="vs">python train</span><span class="dv">.</span><span class="vs">py</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="vs">--dataroot </span><span class="dv">.</span><span class="vs">/datasets/stopmotion_pix2pix</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="vs">--name stopmotion_pix2pix_1024</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="vs">--model pix2pix</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="vs">--dataset_mode aligned</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="vs">--direction AtoB</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="vs">--input_nc 3</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="vs">--output_nc 3</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="vs">--preprocess none</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="vs">--load_size 1024</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="vs">--crop_size 1024t</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="vs">--batch_size 1</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="vs">--gpu_ids 0</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="vs">--n_epochs 50</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a><span class="vs">--n_epochs_decay 20</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a><span class="vs">--save_epoch_freq 2</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="vs">--print_freq 50</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="vs">--display_freq 200</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="vs">--continue_train</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a><span class="vs">--epoch_count 21</span></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a><span class="vs">"""</span></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>proc <span class="op">=</span> subprocess.run(shlex.split(<span class="st">" "</span>.join(cmd.split())), stdout<span class="op">=</span>subprocess.PIPE, stderr<span class="op">=</span>subprocess.STDOUT, text<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(proc.stdout)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>CWD: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix</code></pre>
</div>
</div>
<div id="e4020383-89fc-4235-846f-3d69dd15c6a9" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, subprocess, shlex</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"TORCHINDUCTOR_DISABLE"</span>] <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"TORCH_COMPILE_DISABLE"</span>]  <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"TORCHDYNAMO_DISABLE"</span>]    <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># === CONFIG ===</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>repo_dir <span class="op">=</span> <span class="vs">r"C:</span><span class="er">\</span><span class="vs">Users</span><span class="er">\</span><span class="vs">yalda</span><span class="er">\</span><span class="vs">OneDrive</span><span class="dv">\D</span><span class="vs">esktop</span><span class="er">\</span><span class="vs">Thesis apps</span><span class="er">\</span><span class="vs">Project Folder</span><span class="er">\</span><span class="vs">pytorch-CycleGAN-and-pix2pix"</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>dataroot <span class="op">=</span> os.path.join(repo_dir, <span class="st">"datasets"</span>, <span class="st">"stopmotion_pix2pix"</span>)  </span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>exp_name <span class="op">=</span> <span class="st">"stopmotion_pix2pix_1024"</span>   </span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>epoch <span class="op">=</span> <span class="st">"latest"</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>gpu_ids <span class="op">=</span> <span class="st">"0"</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>num_test <span class="op">=</span> <span class="st">"1000"</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>os.chdir(repo_dir)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CWD:"</span>, os.getcwd())</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>cmd <span class="op">=</span> <span class="ss">f'python test.py --dataroot "</span><span class="sc">{</span>dataroot<span class="sc">}</span><span class="ss">" --name </span><span class="sc">{</span>exp_name<span class="sc">}</span><span class="ss"> --model pix2pix --direction AtoB --epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss"> --num_test </span><span class="sc">{</span>num_test<span class="sc">}</span><span class="ss"> --gpu_ids </span><span class="sc">{</span>gpu_ids<span class="sc">}</span><span class="ss"> --results_dir "</span><span class="sc">{</span>os<span class="sc">.</span>path<span class="sc">.</span>join(repo_dir, <span class="st">"results"</span>)<span class="sc">}</span><span class="ss">" --load_size 1024 --crop_size 1024'</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Running:"</span>, cmd)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>proc <span class="op">=</span> subprocess.run(shlex.split(cmd), stdout<span class="op">=</span>subprocess.PIPE, stderr<span class="op">=</span>subprocess.STDOUT, text<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(proc.stdout)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>CWD: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix
Running: python test.py --dataroot "C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\datasets\stopmotion_pix2pix" --name stopmotion_pix2pix_1024 --model pix2pix --direction AtoB --epoch latest --num_test 1000 --gpu_ids 0 --results_dir "C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results" --load_size 1024 --crop_size 1024
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
----------------- Options ---------------
             aspect_ratio: 1.0                           
               batch_size: 1                             
          checkpoints_dir: ./checkpoints                 
                crop_size: 1024                             [default: 256]
                 dataroot: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\datasets\stopmotion_pix2pix  [default: None]
             dataset_mode: aligned                       
                direction: AtoB                          
          display_winsize: 256                           
                    epoch: latest                        
                     eval: False                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: False                            [default: None]
                load_iter: 0                                [default: 0]
                load_size: 1024                             [default: 256]
         max_dataset_size: inf                           
                    model: pix2pix                          [default: test]
               n_layers_D: 3                             
                     name: stopmotion_pix2pix_1024          [default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: unet_256                      
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: False                         
                     norm: batch                         
                 num_test: 1000                             [default: 50]
              num_threads: 4                             
                output_nc: 3                             
                    phase: test                          
               preprocess: resize_and_crop               
              results_dir: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results  [default: ./results/]
           serial_batches: False                         
                   suffix:                               
                use_wandb: False                         
                  verbose: False                         
       wandb_project_name: CycleGAN-and-pix2pix          
----------------- End -------------------
dataset [AlignedDataset] was created
initialize network with normal
model [Pix2PixModel] was created
loading the model from checkpoints\stopmotion_pix2pix_1024\latest_net_G.pth
---------- Networks initialized -------------
[Network G] Total number of parameters : 54.414 M
-----------------------------------------------
[Network G] compiled with torch.compile
creating web directory C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results\stopmotion_pix2pix_1024\test_latest
processing (0000)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_Hiphopdancing_20003.png']
processing (0005)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_Hiphopdancing_20049.png']
processing (0010)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20060.png']
processing (0015)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20087.png']
processing (0020)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20137.png']
processing (0025)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20210.png']
processing (0030)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20260.png']
processing (0035)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20313.png']
processing (0040)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_sittinglaughing_20034.png']
processing (0045)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_sittinglaughing_20124.png']
processing (0050)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_walking_20030.png']
processing (0055)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Hiphopdancing_20057.png']
processing (0060)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Sittinglaughing_20026.png']
processing (0065)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Sittinglaughing_20081.png']
processing (0070)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Sittinglaughing_20114.png']
processing (0075)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_dying_20002.png']
processing (0080)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_dying_20046.png']
processing (0085)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_dying_20068.png']
processing (0090)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_sittingcrawling_20016.png']
processing (0095)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_sittingcrawling_20031.png']
</code></pre>
</div>
</div>
<div id="fe2ead26-2b36-4ac0-a1a5-7b5ec8fc57b6" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, shlex, subprocess</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>repo_dir <span class="op">=</span> <span class="vs">r"C:</span><span class="er">\</span><span class="vs">Users</span><span class="er">\</span><span class="vs">yalda</span><span class="er">\</span><span class="vs">OneDrive</span><span class="dv">\D</span><span class="vs">esktop</span><span class="er">\</span><span class="vs">Thesis apps</span><span class="er">\</span><span class="vs">Project Folder</span><span class="er">\</span><span class="vs">pytorch-CycleGAN-and-pix2pix"</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>os.chdir(repo_dir)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CWD:"</span>, os.getcwd())</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>cmd <span class="op">=</span> <span class="vs">r"""</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="vs">python train</span><span class="dv">.</span><span class="vs">py</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="vs">--dataroot </span><span class="dv">.</span><span class="vs">/datasets/stopmotion_pix2pix</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="vs">--name stopmotion_pix2pix_1024</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="vs">--model pix2pix</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="vs">--dataset_mode aligned</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="vs">--direction AtoB</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="vs">--input_nc 3</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="vs">--output_nc 3</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="vs">--netG unet_256</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="vs">--lambda_L1 100</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="vs">--preprocess resize_and_crop</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="vs">--load_size 1088</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="vs">--crop_size 1024</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="vs">--batch_size 1</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="vs">--gpu_ids 0</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a><span class="vs">--continue_train</span></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a><span class="vs">--epoch_count 71</span></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a><span class="vs">--lr 0</span><span class="dv">.</span><span class="vs">0001</span></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a><span class="vs">--n_epochs 20</span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a><span class="vs">--n_epochs_decay 60</span></span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a><span class="vs">--save_epoch_freq 2</span></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a><span class="vs">--print_freq 50</span></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a><span class="vs">--display_freq 200</span></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a><span class="vs">"""</span></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>proc <span class="op">=</span> subprocess.run(shlex.split(<span class="st">" "</span>.join(cmd.split())), stdout<span class="op">=</span>subprocess.PIPE, stderr<span class="op">=</span>subprocess.STDOUT, text<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(proc.stdout)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>CWD: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
----------------- Options ---------------
               batch_size: 1                             
                    beta1: 0.5                           
          checkpoints_dir: ./checkpoints                 
           continue_train: True                             [default: False]
                crop_size: 1024                             [default: 256]
                 dataroot: ./datasets/stopmotion_pix2pix    [default: None]
             dataset_mode: aligned                       
                direction: AtoB                          
             display_freq: 200                              [default: 400]
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 71                               [default: 1]
                 gan_mode: vanilla                       
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                             [default: None]
                lambda_L1: 100.0                         
                load_iter: 0                                [default: 0]
                load_size: 1088                             [default: 286]
                       lr: 0.0001                           [default: 0.0002]
           lr_decay_iters: 50                            
                lr_policy: linear                        
         max_dataset_size: inf                           
                    model: pix2pix                          [default: cycle_gan]
                 n_epochs: 20                               [default: 100]
           n_epochs_decay: 60                               [default: 100]
               n_layers_D: 3                             
                     name: stopmotion_pix2pix_1024          [default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: unet_256                      
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: False                         
                  no_html: False                         
                     norm: batch                         
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 0                             
               preprocess: resize_and_crop               
               print_freq: 50                               [default: 100]
             save_by_iter: False                         
          save_epoch_freq: 2                                [default: 5]
         save_latest_freq: 5000                          
           serial_batches: False                         
                   suffix:                               
         update_html_freq: 1000                          
                use_wandb: False                         
                  verbose: False                         
       wandb_project_name: CycleGAN-and-pix2pix          
----------------- End -------------------
dataset [AlignedDataset] was created
The number of training images = 867
initialize network with normal
initialize network with normal
model [Pix2PixModel] was created
loading the model from checkpoints\stopmotion_pix2pix_1024\latest_net_G.pth
loading the model from checkpoints\stopmotion_pix2pix_1024\latest_net_D.pth
---------- Networks initialized -------------
[Network G] Total number of parameters : 54.414 M
[Network D] Total number of parameters : 2.769 M
-----------------------------------------------
[Network G] compiled with torch.compile
[Network D] compiled with torch.compile
create web directory checkpoints\stopmotion_pix2pix_1024\web...
(epoch: 71, iters: 50, time: 0.453, data: 35.415) G_GAN: 3.584 G_L1: 8.867 D_real: 0.109 D_fake: 0.046 
(epoch: 71, iters: 100, time: 0.463, data: 0.011) G_GAN: 4.349 G_L1: 9.699 D_real: 0.067 D_fake: 0.027 
(epoch: 71, iters: 150, time: 0.409, data: 0.008) G_GAN: 4.413 G_L1: 14.207 D_real: 0.027 D_fake: 0.024 
(epoch: 71, iters: 200, time: 2.527, data: 0.010) G_GAN: 4.042 G_L1: 10.512 D_real: 0.053 D_fake: 0.040 
(epoch: 71, iters: 250, time: 0.410, data: 0.000) G_GAN: 3.894 G_L1: 8.783 D_real: 0.075 D_fake: 0.044 
(epoch: 71, iters: 300, time: 0.405, data: 0.010) G_GAN: 4.628 G_L1: 8.736 D_real: 0.125 D_fake: 0.019 
(epoch: 71, iters: 350, time: 0.478, data: 0.010) G_GAN: 5.410 G_L1: 11.177 D_real: 0.042 D_fake: 0.017 
(epoch: 71, iters: 400, time: 0.402, data: 0.000) G_GAN: 3.351 G_L1: 13.357 D_real: 0.028 D_fake: 0.092 
(epoch: 71, iters: 450, time: 0.411, data: 0.005) G_GAN: 4.117 G_L1: 10.613 D_real: 0.126 D_fake: 0.028 
(epoch: 71, iters: 500, time: 0.456, data: 0.008) G_GAN: 4.089 G_L1: 11.125 D_real: 0.029 D_fake: 0.042 
(epoch: 71, iters: 550, time: 0.427, data: 0.007) G_GAN: 3.368 G_L1: 7.743 D_real: 0.095 D_fake: 0.057 
(epoch: 71, iters: 600, time: 0.463, data: 0.006) G_GAN: 3.692 G_L1: 12.451 D_real: 0.068 D_fake: 0.074 
(epoch: 71, iters: 650, time: 0.448, data: 0.008) G_GAN: 4.069 G_L1: 10.964 D_real: 0.038 D_fake: 0.040 
(epoch: 71, iters: 700, time: 0.460, data: 0.010) G_GAN: 4.794 G_L1: 11.140 D_real: 0.028 D_fake: 0.022 
(epoch: 71, iters: 750, time: 0.456, data: 0.004) G_GAN: 3.938 G_L1: 11.175 D_real: 0.022 D_fake: 0.035 
(epoch: 71, iters: 800, time: 0.463, data: 0.018) G_GAN: 3.060 G_L1: 8.621 D_real: 0.023 D_fake: 0.126 
(epoch: 71, iters: 850, time: 0.470, data: 0.010) G_GAN: 4.136 G_L1: 8.949 D_real: 0.071 D_fake: 0.065 
learning rate 0.0000164 -&gt; 0.0000148
End of epoch 71 / 80     Time Taken: 283 sec
(epoch: 72, iters: 33, time: 0.454, data: 0.008) G_GAN: 4.080 G_L1: 8.320 D_real: 0.054 D_fake: 0.038 
(epoch: 72, iters: 83, time: 0.400, data: 0.010) G_GAN: 3.482 G_L1: 12.592 D_real: 0.081 D_fake: 0.089 
(epoch: 72, iters: 133, time: 2.338, data: 0.000) G_GAN: 4.084 G_L1: 9.666 D_real: 0.058 D_fake: 0.038 
(epoch: 72, iters: 183, time: 0.462, data: 0.000) G_GAN: 4.061 G_L1: 9.672 D_real: 0.065 D_fake: 0.035 
(epoch: 72, iters: 233, time: 0.404, data: 0.010) G_GAN: 3.781 G_L1: 11.875 D_real: 0.073 D_fake: 0.072 
(epoch: 72, iters: 283, time: 0.412, data: 0.011) G_GAN: 3.336 G_L1: 11.385 D_real: 0.021 D_fake: 0.120 
(epoch: 72, iters: 333, time: 0.465, data: 0.010) G_GAN: 3.686 G_L1: 10.578 D_real: 0.088 D_fake: 0.057 
(epoch: 72, iters: 383, time: 0.443, data: 0.013) G_GAN: 3.342 G_L1: 10.355 D_real: 0.036 D_fake: 0.097 
(epoch: 72, iters: 433, time: 0.463, data: 0.013) G_GAN: 5.041 G_L1: 14.211 D_real: 0.047 D_fake: 0.019 
(epoch: 72, iters: 483, time: 0.473, data: 0.008) G_GAN: 4.218 G_L1: 12.429 D_real: 0.038 D_fake: 0.037 
(epoch: 72, iters: 533, time: 0.417, data: 0.011) G_GAN: 4.966 G_L1: 11.451 D_real: 0.023 D_fake: 0.017 
(epoch: 72, iters: 583, time: 0.399, data: 0.010) G_GAN: 3.116 G_L1: 10.343 D_real: 0.034 D_fake: 0.139 
(epoch: 72, iters: 633, time: 0.419, data: 0.016) G_GAN: 3.604 G_L1: 10.940 D_real: 0.015 D_fake: 0.068 
(epoch: 72, iters: 683, time: 0.415, data: 0.010) G_GAN: 3.621 G_L1: 9.923 D_real: 0.171 D_fake: 0.081 
(epoch: 72, iters: 733, time: 0.424, data: 0.008) G_GAN: 3.875 G_L1: 9.537 D_real: 0.024 D_fake: 0.067 
(epoch: 72, iters: 783, time: 0.400, data: 0.010) G_GAN: 4.983 G_L1: 14.187 D_real: 0.014 D_fake: 0.017 
(epoch: 72, iters: 833, time: 0.430, data: 0.010) G_GAN: 4.678 G_L1: 11.094 D_real: 0.045 D_fake: 0.022 
learning rate 0.0000148 -&gt; 0.0000131
saving the model at the end of epoch 72, iters 1734
End of epoch 72 / 80     Time Taken: 269 sec
(epoch: 73, iters: 16, time: 0.469, data: 0.010) G_GAN: 3.164 G_L1: 11.309 D_real: 0.090 D_fake: 0.101 
(epoch: 73, iters: 66, time: 2.446, data: 0.000) G_GAN: 3.092 G_L1: 9.348 D_real: 0.037 D_fake: 0.096 
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
(epoch: 73, iters: 116, time: 0.406, data: 0.000) G_GAN: 3.010 G_L1: 9.463 D_real: 0.016 D_fake: 0.133 
(epoch: 73, iters: 166, time: 0.401, data: 0.010) G_GAN: 3.447 G_L1: 10.623 D_real: 0.078 D_fake: 0.061 
(epoch: 73, iters: 216, time: 0.409, data: 0.010) G_GAN: 4.171 G_L1: 12.398 D_real: 0.014 D_fake: 0.043 
(epoch: 73, iters: 266, time: 2.678, data: 0.010) G_GAN: 3.267 G_L1: 9.164 D_real: 0.024 D_fake: 0.080 
(epoch: 73, iters: 316, time: 0.410, data: 0.007) G_GAN: 4.186 G_L1: 10.948 D_real: 0.074 D_fake: 0.031 
(epoch: 73, iters: 366, time: 0.402, data: 0.010) G_GAN: 4.728 G_L1: 16.639 D_real: 0.009 D_fake: 0.027 
(epoch: 73, iters: 416, time: 0.463, data: 0.010) G_GAN: 3.889 G_L1: 10.465 D_real: 0.064 D_fake: 0.045 
(epoch: 73, iters: 466, time: 0.464, data: 0.021) G_GAN: 4.151 G_L1: 11.755 D_real: 0.089 D_fake: 0.041 
(epoch: 73, iters: 516, time: 0.458, data: 0.011) G_GAN: 3.948 G_L1: 9.802 D_real: 0.150 D_fake: 0.052 
(epoch: 73, iters: 566, time: 0.472, data: 0.010) G_GAN: 3.030 G_L1: 12.520 D_real: 0.025 D_fake: 0.190 
(epoch: 73, iters: 616, time: 0.478, data: 0.011) G_GAN: 2.897 G_L1: 11.781 D_real: 0.088 D_fake: 0.339 
(epoch: 73, iters: 666, time: 0.459, data: 0.006) G_GAN: 3.505 G_L1: 11.404 D_real: 0.129 D_fake: 0.071 
(epoch: 73, iters: 716, time: 0.428, data: 0.021) G_GAN: 3.827 G_L1: 14.280 D_real: 0.023 D_fake: 0.047 
(epoch: 73, iters: 766, time: 0.420, data: 0.010) G_GAN: 3.961 G_L1: 12.621 D_real: 0.024 D_fake: 0.049 
(epoch: 73, iters: 816, time: 0.399, data: 0.010) G_GAN: 3.984 G_L1: 9.312 D_real: 0.031 D_fake: 0.041 
(epoch: 73, iters: 866, time: 0.399, data: 0.010) G_GAN: 4.350 G_L1: 11.175 D_real: 0.035 D_fake: 0.035 
learning rate 0.0000131 -&gt; 0.0000115
End of epoch 73 / 80     Time Taken: 270 sec
(epoch: 74, iters: 49, time: 0.434, data: 0.010) G_GAN: 4.305 G_L1: 13.526 D_real: 0.033 D_fake: 0.031 
(epoch: 74, iters: 99, time: 0.471, data: 0.011) G_GAN: 3.623 G_L1: 12.003 D_real: 0.055 D_fake: 0.064 
(epoch: 74, iters: 149, time: 0.452, data: 0.010) G_GAN: 3.031 G_L1: 14.524 D_real: 0.078 D_fake: 0.179 
(epoch: 74, iters: 199, time: 2.423, data: 0.010) G_GAN: 3.526 G_L1: 9.582 D_real: 0.073 D_fake: 0.060 
(epoch: 74, iters: 249, time: 0.461, data: 0.000) G_GAN: 3.464 G_L1: 8.855 D_real: 0.103 D_fake: 0.087 
(epoch: 74, iters: 299, time: 0.454, data: 0.017) G_GAN: 3.891 G_L1: 12.237 D_real: 0.097 D_fake: 0.046 
(epoch: 74, iters: 349, time: 0.463, data: 0.011) G_GAN: 3.701 G_L1: 12.285 D_real: 0.055 D_fake: 0.078 
(epoch: 74, iters: 399, time: 2.403, data: 0.010) G_GAN: 3.961 G_L1: 11.416 D_real: 0.057 D_fake: 0.050 
(epoch: 74, iters: 449, time: 0.409, data: 0.000) G_GAN: 3.336 G_L1: 15.965 D_real: 0.070 D_fake: 0.107 
(epoch: 74, iters: 499, time: 0.453, data: 0.008) G_GAN: 3.682 G_L1: 8.315 D_real: 0.039 D_fake: 0.070 
(epoch: 74, iters: 549, time: 0.407, data: 0.010) G_GAN: 3.097 G_L1: 9.087 D_real: 0.086 D_fake: 0.125 
(epoch: 74, iters: 599, time: 0.461, data: 0.017) G_GAN: 3.988 G_L1: 8.991 D_real: 0.059 D_fake: 0.047 
(epoch: 74, iters: 649, time: 0.458, data: 0.010) G_GAN: 4.094 G_L1: 10.780 D_real: 0.059 D_fake: 0.043 
(epoch: 74, iters: 699, time: 0.462, data: 0.013) G_GAN: 4.490 G_L1: 11.291 D_real: 0.021 D_fake: 0.041 
(epoch: 74, iters: 749, time: 0.454, data: 0.010) G_GAN: 3.806 G_L1: 9.417 D_real: 0.092 D_fake: 0.050 
(epoch: 74, iters: 799, time: 0.462, data: 0.010) G_GAN: 3.919 G_L1: 11.398 D_real: 0.035 D_fake: 0.053 
(epoch: 74, iters: 849, time: 0.465, data: 0.010) G_GAN: 4.118 G_L1: 8.817 D_real: 0.080 D_fake: 0.033 
learning rate 0.0000115 -&gt; 0.0000098
saving the model at the end of epoch 74, iters 3468
End of epoch 74 / 80     Time Taken: 287 sec
(epoch: 75, iters: 32, time: 0.469, data: 0.010) G_GAN: 4.154 G_L1: 11.308 D_real: 0.044 D_fake: 0.036 
(epoch: 75, iters: 82, time: 0.452, data: 0.010) G_GAN: 4.337 G_L1: 15.066 D_real: 0.032 D_fake: 0.035 
(epoch: 75, iters: 132, time: 2.547, data: 0.010) G_GAN: 3.908 G_L1: 11.331 D_real: 0.067 D_fake: 0.046 
(epoch: 75, iters: 182, time: 0.410, data: 0.016) G_GAN: 4.196 G_L1: 10.383 D_real: 0.084 D_fake: 0.032 
(epoch: 75, iters: 232, time: 0.412, data: 0.010) G_GAN: 4.575 G_L1: 13.253 D_real: 0.061 D_fake: 0.028 
(epoch: 75, iters: 282, time: 0.405, data: 0.000) G_GAN: 3.286 G_L1: 9.838 D_real: 0.023 D_fake: 0.098 
(epoch: 75, iters: 332, time: 0.409, data: 0.010) G_GAN: 3.580 G_L1: 9.554 D_real: 0.081 D_fake: 0.067 
(epoch: 75, iters: 382, time: 0.401, data: 0.010) G_GAN: 3.571 G_L1: 11.210 D_real: 0.068 D_fake: 0.057 
(epoch: 75, iters: 432, time: 0.395, data: 0.015) G_GAN: 4.613 G_L1: 9.397 D_real: 0.080 D_fake: 0.024 
(epoch: 75, iters: 482, time: 0.401, data: 0.011) G_GAN: 3.505 G_L1: 10.162 D_real: 0.017 D_fake: 0.065 
(epoch: 75, iters: 532, time: 2.359, data: 0.011) G_GAN: 3.455 G_L1: 14.068 D_real: 0.041 D_fake: 0.073 
(epoch: 75, iters: 582, time: 0.429, data: 0.000) G_GAN: 3.432 G_L1: 10.236 D_real: 0.060 D_fake: 0.072 
(epoch: 75, iters: 632, time: 0.409, data: 0.010) G_GAN: 4.162 G_L1: 11.424 D_real: 0.112 D_fake: 0.042 
(epoch: 75, iters: 682, time: 0.409, data: 0.010) G_GAN: 3.567 G_L1: 9.562 D_real: 0.034 D_fake: 0.071 
(epoch: 75, iters: 732, time: 0.432, data: 0.010) G_GAN: 3.404 G_L1: 14.273 D_real: 0.014 D_fake: 0.075 
(epoch: 75, iters: 782, time: 0.463, data: 0.012) G_GAN: 3.640 G_L1: 10.948 D_real: 0.066 D_fake: 0.055 
(epoch: 75, iters: 832, time: 0.458, data: 0.010) G_GAN: 3.316 G_L1: 18.198 D_real: 0.037 D_fake: 0.096 
learning rate 0.0000098 -&gt; 0.0000082
End of epoch 75 / 80     Time Taken: 265 sec
(epoch: 76, iters: 15, time: 0.400, data: 0.009) G_GAN: 5.001 G_L1: 11.577 D_real: 0.033 D_fake: 0.013 
(epoch: 76, iters: 65, time: 2.425, data: 0.010) G_GAN: 4.304 G_L1: 13.754 D_real: 0.023 D_fake: 0.029 
(epoch: 76, iters: 115, time: 0.413, data: 0.016) G_GAN: 3.970 G_L1: 12.259 D_real: 0.052 D_fake: 0.045 
(epoch: 76, iters: 165, time: 0.393, data: 0.012) G_GAN: 4.113 G_L1: 11.254 D_real: 0.050 D_fake: 0.036 
(epoch: 76, iters: 215, time: 0.412, data: 0.007) G_GAN: 4.275 G_L1: 8.841 D_real: 0.052 D_fake: 0.030 
(epoch: 76, iters: 265, time: 0.441, data: 0.007) G_GAN: 3.540 G_L1: 11.757 D_real: 0.028 D_fake: 0.065 
(epoch: 76, iters: 315, time: 0.461, data: 0.010) G_GAN: 4.552 G_L1: 9.667 D_real: 0.071 D_fake: 0.019 
(epoch: 76, iters: 365, time: 0.408, data: 0.005) G_GAN: 3.944 G_L1: 11.903 D_real: 0.057 D_fake: 0.039 
(epoch: 76, iters: 415, time: 0.398, data: 0.007) G_GAN: 4.805 G_L1: 9.870 D_real: 0.024 D_fake: 0.022 
(epoch: 76, iters: 465, time: 0.447, data: 0.012) G_GAN: 4.787 G_L1: 10.349 D_real: 0.058 D_fake: 0.021 
(epoch: 76, iters: 515, time: 0.452, data: 0.010) G_GAN: 4.103 G_L1: 10.375 D_real: 0.110 D_fake: 0.041 
(epoch: 76, iters: 565, time: 0.429, data: 0.010) G_GAN: 3.720 G_L1: 10.232 D_real: 0.071 D_fake: 0.047 
(epoch: 76, iters: 615, time: 0.473, data: 0.012) G_GAN: 3.450 G_L1: 10.972 D_real: 0.077 D_fake: 0.075 
(epoch: 76, iters: 665, time: 2.468, data: 0.010) G_GAN: 3.374 G_L1: 9.833 D_real: 0.035 D_fake: 0.087 
saving the latest model (epoch 76, total_iters 5000)
(epoch: 76, iters: 715, time: 0.464, data: 0.000) G_GAN: 4.687 G_L1: 12.663 D_real: 0.013 D_fake: 0.028 
(epoch: 76, iters: 765, time: 0.465, data: 0.010) G_GAN: 4.303 G_L1: 15.059 D_real: 0.029 D_fake: 0.028 
(epoch: 76, iters: 815, time: 0.473, data: 0.010) G_GAN: 3.902 G_L1: 10.580 D_real: 0.041 D_fake: 0.038 
(epoch: 76, iters: 865, time: 0.431, data: 0.010) G_GAN: 3.126 G_L1: 13.410 D_real: 0.025 D_fake: 0.110 
learning rate 0.0000082 -&gt; 0.0000066
saving the model at the end of epoch 76, iters 5202
End of epoch 76 / 80     Time Taken: 280 sec
(epoch: 77, iters: 48, time: 0.409, data: 0.010) G_GAN: 3.799 G_L1: 11.711 D_real: 0.107 D_fake: 0.072 
(epoch: 77, iters: 98, time: 0.405, data: 0.002) G_GAN: 4.042 G_L1: 8.752 D_real: 0.050 D_fake: 0.035 
(epoch: 77, iters: 148, time: 0.400, data: 0.008) G_GAN: 3.505 G_L1: 9.215 D_real: 0.057 D_fake: 0.061 
(epoch: 77, iters: 198, time: 2.490, data: 0.010) G_GAN: 3.074 G_L1: 12.544 D_real: 0.089 D_fake: 0.098 
(epoch: 77, iters: 248, time: 0.400, data: 0.011) G_GAN: 4.159 G_L1: 9.829 D_real: 0.057 D_fake: 0.033 
(epoch: 77, iters: 298, time: 0.402, data: 0.010) G_GAN: 4.473 G_L1: 12.055 D_real: 0.065 D_fake: 0.025 
(epoch: 77, iters: 348, time: 0.399, data: 0.010) G_GAN: 3.839 G_L1: 9.874 D_real: 0.024 D_fake: 0.042 
(epoch: 77, iters: 398, time: 0.410, data: 0.010) G_GAN: 3.877 G_L1: 10.799 D_real: 0.028 D_fake: 0.037 
(epoch: 77, iters: 448, time: 0.401, data: 0.010) G_GAN: 4.802 G_L1: 12.459 D_real: 0.031 D_fake: 0.017 
(epoch: 77, iters: 498, time: 0.410, data: 0.010) G_GAN: 3.244 G_L1: 12.368 D_real: 0.033 D_fake: 0.076 
(epoch: 77, iters: 548, time: 0.421, data: 0.010) G_GAN: 3.609 G_L1: 8.469 D_real: 0.067 D_fake: 0.054 
(epoch: 77, iters: 598, time: 0.404, data: 0.010) G_GAN: 2.478 G_L1: 8.366 D_real: 0.019 D_fake: 0.265 
(epoch: 77, iters: 648, time: 0.499, data: 0.010) G_GAN: 2.885 G_L1: 10.429 D_real: 0.072 D_fake: 0.123 
(epoch: 77, iters: 698, time: 0.467, data: 0.006) G_GAN: 3.291 G_L1: 10.866 D_real: 0.084 D_fake: 0.076 
(epoch: 77, iters: 748, time: 0.411, data: 0.000) G_GAN: 3.941 G_L1: 9.853 D_real: 0.115 D_fake: 0.033 
(epoch: 77, iters: 798, time: 2.528, data: 0.010) G_GAN: 4.571 G_L1: 9.659 D_real: 0.073 D_fake: 0.022 
(epoch: 77, iters: 848, time: 0.476, data: 0.016) G_GAN: 3.675 G_L1: 10.961 D_real: 0.059 D_fake: 0.053 
learning rate 0.0000066 -&gt; 0.0000049
End of epoch 77 / 80     Time Taken: 268 sec
(epoch: 78, iters: 31, time: 0.461, data: 0.010) G_GAN: 3.806 G_L1: 10.410 D_real: 0.070 D_fake: 0.043 
(epoch: 78, iters: 81, time: 0.405, data: 0.000) G_GAN: 3.939 G_L1: 9.284 D_real: 0.077 D_fake: 0.035 
(epoch: 78, iters: 131, time: 2.090, data: 0.007) G_GAN: 3.339 G_L1: 10.277 D_real: 0.042 D_fake: 0.075 
(epoch: 78, iters: 181, time: 0.490, data: 0.014) G_GAN: 3.781 G_L1: 9.586 D_real: 0.080 D_fake: 0.039 
(epoch: 78, iters: 231, time: 0.493, data: 0.017) G_GAN: 3.487 G_L1: 11.158 D_real: 0.035 D_fake: 0.061 
(epoch: 78, iters: 281, time: 0.494, data: 0.010) G_GAN: 4.232 G_L1: 11.175 D_real: 0.078 D_fake: 0.029 
(epoch: 78, iters: 331, time: 0.497, data: 0.003) G_GAN: 3.351 G_L1: 13.659 D_real: 0.010 D_fake: 0.085 
(epoch: 78, iters: 381, time: 0.494, data: 0.012) G_GAN: 4.029 G_L1: 9.034 D_real: 0.085 D_fake: 0.033 
(epoch: 78, iters: 431, time: 0.499, data: 0.010) G_GAN: 4.549 G_L1: 11.045 D_real: 0.087 D_fake: 0.023 
(epoch: 78, iters: 481, time: 0.485, data: 0.005) G_GAN: 3.795 G_L1: 9.945 D_real: 0.145 D_fake: 0.053 
(epoch: 78, iters: 531, time: 0.499, data: 0.010) G_GAN: 3.647 G_L1: 12.640 D_real: 0.032 D_fake: 0.053 
(epoch: 78, iters: 581, time: 0.489, data: 0.011) G_GAN: 3.702 G_L1: 9.661 D_real: 0.060 D_fake: 0.045 
(epoch: 78, iters: 631, time: 0.497, data: 0.008) G_GAN: 3.562 G_L1: 12.278 D_real: 0.057 D_fake: 0.062 
(epoch: 78, iters: 681, time: 0.497, data: 0.010) G_GAN: 3.761 G_L1: 10.093 D_real: 0.063 D_fake: 0.048 
(epoch: 78, iters: 731, time: 0.483, data: 0.012) G_GAN: 3.050 G_L1: 10.379 D_real: 0.046 D_fake: 0.096 
(epoch: 78, iters: 781, time: 0.495, data: 0.014) G_GAN: 3.418 G_L1: 12.823 D_real: 0.067 D_fake: 0.084 
(epoch: 78, iters: 831, time: 0.505, data: 0.010) G_GAN: 3.971 G_L1: 10.514 D_real: 0.079 D_fake: 0.041 
learning rate 0.0000049 -&gt; 0.0000033
saving the model at the end of epoch 78, iters 6936
End of epoch 78 / 80     Time Taken: 302 sec
(epoch: 79, iters: 14, time: 0.450, data: 0.010) G_GAN: 2.376 G_L1: 9.447 D_real: 0.019 D_fake: 0.217 
(epoch: 79, iters: 64, time: 2.528, data: 0.010) G_GAN: 4.193 G_L1: 8.136 D_real: 0.052 D_fake: 0.033 
(epoch: 79, iters: 114, time: 0.431, data: 0.009) G_GAN: 3.641 G_L1: 13.007 D_real: 0.027 D_fake: 0.056 
(epoch: 79, iters: 164, time: 0.435, data: 0.010) G_GAN: 4.091 G_L1: 11.120 D_real: 0.072 D_fake: 0.039 
(epoch: 79, iters: 214, time: 0.427, data: 0.012) G_GAN: 4.000 G_L1: 13.176 D_real: 0.056 D_fake: 0.040 
(epoch: 79, iters: 264, time: 0.451, data: 0.017) G_GAN: 4.632 G_L1: 12.126 D_real: 0.014 D_fake: 0.020 
(epoch: 79, iters: 314, time: 0.429, data: 0.009) G_GAN: 3.599 G_L1: 9.901 D_real: 0.068 D_fake: 0.047 
(epoch: 79, iters: 364, time: 0.428, data: 0.010) G_GAN: 4.142 G_L1: 7.972 D_real: 0.095 D_fake: 0.028 
(epoch: 79, iters: 414, time: 0.494, data: 0.010) G_GAN: 3.613 G_L1: 9.460 D_real: 0.068 D_fake: 0.059 
(epoch: 79, iters: 464, time: 0.497, data: 0.003) G_GAN: 3.637 G_L1: 11.124 D_real: 0.084 D_fake: 0.049 
(epoch: 79, iters: 514, time: 0.505, data: 0.006) G_GAN: 4.441 G_L1: 14.516 D_real: 0.017 D_fake: 0.022 
(epoch: 79, iters: 564, time: 0.487, data: 0.010) G_GAN: 3.481 G_L1: 8.406 D_real: 0.029 D_fake: 0.057 
(epoch: 79, iters: 614, time: 0.490, data: 0.000) G_GAN: 4.102 G_L1: 10.781 D_real: 0.017 D_fake: 0.029 
(epoch: 79, iters: 664, time: 0.499, data: 0.013) G_GAN: 3.842 G_L1: 11.528 D_real: 0.024 D_fake: 0.041 
(epoch: 79, iters: 714, time: 0.493, data: 0.015) G_GAN: 4.071 G_L1: 12.536 D_real: 0.012 D_fake: 0.039 
(epoch: 79, iters: 764, time: 0.495, data: 0.010) G_GAN: 4.759 G_L1: 8.432 D_real: 0.044 D_fake: 0.017 
(epoch: 79, iters: 814, time: 0.507, data: 0.010) G_GAN: 4.615 G_L1: 12.320 D_real: 0.045 D_fake: 0.025 
(epoch: 79, iters: 864, time: 0.433, data: 0.010) G_GAN: 4.080 G_L1: 11.433 D_real: 0.038 D_fake: 0.041 
learning rate 0.0000033 -&gt; 0.0000016
End of epoch 79 / 80     Time Taken: 302 sec
(epoch: 80, iters: 47, time: 0.428, data: 0.000) G_GAN: 3.842 G_L1: 10.239 D_real: 0.015 D_fake: 0.041 
(epoch: 80, iters: 97, time: 0.407, data: 0.010) G_GAN: 4.026 G_L1: 9.905 D_real: 0.053 D_fake: 0.034 
(epoch: 80, iters: 147, time: 0.399, data: 0.012) G_GAN: 3.765 G_L1: 7.882 D_real: 0.063 D_fake: 0.043 
(epoch: 80, iters: 197, time: 2.558, data: 0.010) G_GAN: 3.651 G_L1: 10.905 D_real: 0.020 D_fake: 0.053 
(epoch: 80, iters: 247, time: 0.403, data: 0.000) G_GAN: 4.129 G_L1: 17.967 D_real: 0.008 D_fake: 0.034 
(epoch: 80, iters: 297, time: 0.402, data: 0.003) G_GAN: 4.253 G_L1: 11.688 D_real: 0.014 D_fake: 0.025 
(epoch: 80, iters: 347, time: 0.405, data: 0.010) G_GAN: 4.714 G_L1: 9.441 D_real: 0.039 D_fake: 0.017 
(epoch: 80, iters: 397, time: 0.410, data: 0.010) G_GAN: 5.055 G_L1: 9.754 D_real: 0.030 D_fake: 0.024 
(epoch: 80, iters: 447, time: 0.402, data: 0.010) G_GAN: 3.317 G_L1: 9.029 D_real: 0.015 D_fake: 0.068 
(epoch: 80, iters: 497, time: 0.409, data: 0.010) G_GAN: 3.874 G_L1: 13.416 D_real: 0.016 D_fake: 0.039 
(epoch: 80, iters: 547, time: 0.427, data: 0.002) G_GAN: 4.197 G_L1: 8.047 D_real: 0.040 D_fake: 0.027 
(epoch: 80, iters: 597, time: 0.433, data: 0.008) G_GAN: 4.167 G_L1: 10.849 D_real: 0.054 D_fake: 0.051 
(epoch: 80, iters: 647, time: 0.451, data: 0.000) G_GAN: 4.278 G_L1: 9.839 D_real: 0.051 D_fake: 0.033 
(epoch: 80, iters: 697, time: 0.472, data: 0.010) G_GAN: 3.785 G_L1: 12.116 D_real: 0.024 D_fake: 0.048 
(epoch: 80, iters: 747, time: 0.470, data: 0.010) G_GAN: 4.213 G_L1: 10.176 D_real: 0.041 D_fake: 0.032 
(epoch: 80, iters: 797, time: 0.472, data: 0.010) G_GAN: 3.528 G_L1: 15.106 D_real: 0.051 D_fake: 0.057 
(epoch: 80, iters: 847, time: 0.484, data: 0.011) G_GAN: 4.427 G_L1: 11.452 D_real: 0.024 D_fake: 0.028 
learning rate 0.0000016 -&gt; 0.0000000
saving the model at the end of epoch 80, iters 8670
End of epoch 80 / 80     Time Taken: 282 sec
</code></pre>
</div>
</div>
<div id="963fccab-e506-424a-a092-b8251e9b3cf8" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, shlex, subprocess</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>repo_dir <span class="op">=</span> <span class="vs">r"C:</span><span class="er">\</span><span class="vs">Users</span><span class="er">\</span><span class="vs">yalda</span><span class="er">\</span><span class="vs">OneDrive</span><span class="dv">\D</span><span class="vs">esktop</span><span class="er">\</span><span class="vs">Thesis apps</span><span class="er">\</span><span class="vs">Project Folder</span><span class="er">\</span><span class="vs">pytorch-CycleGAN-and-pix2pix"</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>os.chdir(repo_dir)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CWD:"</span>, os.getcwd())</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>cmd <span class="op">=</span> <span class="vs">r"""</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="vs">python train</span><span class="dv">.</span><span class="vs">py</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="vs">--dataroot </span><span class="dv">.</span><span class="vs">/datasets/stopmotion_pix2pix</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="vs">--name stopmotion_pix2pix_1024</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="vs">--model pix2pix</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="vs">--dataset_mode aligned</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="vs">--direction AtoB</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="vs">--input_nc 3</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="vs">--output_nc 3</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="vs">--netG unet_256</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="vs">--lambda_L1 100</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="vs">--preprocess resize_and_crop</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="vs">--load_size 1088</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="vs">--crop_size 1024</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="vs">--batch_size 1</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="vs">--gpu_ids 0</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a><span class="vs">--continue_train</span></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="vs">--epoch_count 81</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a><span class="vs">--lr 0</span><span class="dv">.</span><span class="vs">0001</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a><span class="vs">--n_epochs 90</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a><span class="vs">--n_epochs_decay 70</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="vs">--save_epoch_freq 2</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a><span class="vs">--print_freq 50</span></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a><span class="vs">--display_freq 200</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="vs">"""</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>proc <span class="op">=</span> subprocess.run(shlex.split(<span class="st">" "</span>.join(cmd.split())), stdout<span class="op">=</span>subprocess.PIPE, stderr<span class="op">=</span>subprocess.STDOUT, text<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(proc.stdout)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>CWD: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix</code></pre>
</div>
</div>
<div id="a31e5d89-b1b9-4d9d-9d1a-2700f9975390" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, subprocess, shlex</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"TORCHINDUCTOR_DISABLE"</span>] <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"TORCH_COMPILE_DISABLE"</span>]  <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"TORCHDYNAMO_DISABLE"</span>]    <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co"># === CONFIG ===</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>repo_dir <span class="op">=</span> <span class="vs">r"C:</span><span class="er">\</span><span class="vs">Users</span><span class="er">\</span><span class="vs">yalda</span><span class="er">\</span><span class="vs">OneDrive</span><span class="dv">\D</span><span class="vs">esktop</span><span class="er">\</span><span class="vs">Thesis apps</span><span class="er">\</span><span class="vs">Project Folder</span><span class="er">\</span><span class="vs">pytorch-CycleGAN-and-pix2pix"</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>dataroot <span class="op">=</span> os.path.join(repo_dir, <span class="st">"datasets"</span>, <span class="st">"stopmotion_pix2pix"</span>) </span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>exp_name <span class="op">=</span> <span class="st">"stopmotion_pix2pix_1024"</span>  </span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>epoch <span class="op">=</span> <span class="st">"latest"</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>gpu_ids <span class="op">=</span> <span class="st">"0"</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>num_test <span class="op">=</span> <span class="st">"1000"</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>os.chdir(repo_dir)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CWD:"</span>, os.getcwd())</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>cmd <span class="op">=</span> <span class="ss">f'python test.py --dataroot "</span><span class="sc">{</span>dataroot<span class="sc">}</span><span class="ss">" --name </span><span class="sc">{</span>exp_name<span class="sc">}</span><span class="ss"> --model pix2pix --direction AtoB --epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss"> --num_test </span><span class="sc">{</span>num_test<span class="sc">}</span><span class="ss"> --gpu_ids </span><span class="sc">{</span>gpu_ids<span class="sc">}</span><span class="ss"> --results_dir "</span><span class="sc">{</span>os<span class="sc">.</span>path<span class="sc">.</span>join(repo_dir, <span class="st">"results"</span>)<span class="sc">}</span><span class="ss">" --load_size 1024 --crop_size 1024'</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Running:"</span>, cmd)</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>proc <span class="op">=</span> subprocess.run(shlex.split(cmd), stdout<span class="op">=</span>subprocess.PIPE, stderr<span class="op">=</span>subprocess.STDOUT, text<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(proc.stdout)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>CWD: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix
Running: python test.py --dataroot "C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\datasets\stopmotion_pix2pix" --name stopmotion_pix2pix_1024 --model pix2pix --direction AtoB --epoch latest --num_test 1000 --gpu_ids 0 --results_dir "C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results" --load_size 1024 --crop_size 1024
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
----------------- Options ---------------
             aspect_ratio: 1.0                           
               batch_size: 1                             
          checkpoints_dir: ./checkpoints                 
                crop_size: 1024                             [default: 256]
                 dataroot: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\datasets\stopmotion_pix2pix  [default: None]
             dataset_mode: aligned                       
                direction: AtoB                          
          display_winsize: 256                           
                    epoch: latest                        
                     eval: False                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: False                            [default: None]
                load_iter: 0                                [default: 0]
                load_size: 1024                             [default: 256]
         max_dataset_size: inf                           
                    model: pix2pix                          [default: test]
               n_layers_D: 3                             
                     name: stopmotion_pix2pix_1024          [default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: unet_256                      
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: False                         
                     norm: batch                         
                 num_test: 1000                             [default: 50]
              num_threads: 4                             
                output_nc: 3                             
                    phase: test                          
               preprocess: resize_and_crop               
              results_dir: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results  [default: ./results/]
           serial_batches: False                         
                   suffix:                               
                use_wandb: False                         
                  verbose: False                         
       wandb_project_name: CycleGAN-and-pix2pix          
----------------- End -------------------
dataset [AlignedDataset] was created
initialize network with normal
model [Pix2PixModel] was created
loading the model from checkpoints\stopmotion_pix2pix_1024\latest_net_G.pth
---------- Networks initialized -------------
[Network G] Total number of parameters : 54.414 M
-----------------------------------------------
[Network G] compiled with torch.compile
creating web directory C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results\stopmotion_pix2pix_1024\test_latest
processing (0000)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_Hiphopdancing_20003.png']
processing (0005)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_Hiphopdancing_20049.png']
processing (0010)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20060.png']
processing (0015)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20087.png']
processing (0020)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20137.png']
processing (0025)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20210.png']
processing (0030)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20260.png']
processing (0035)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20313.png']
processing (0040)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_sittinglaughing_20034.png']
processing (0045)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_sittinglaughing_20124.png']
processing (0050)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_walking_20030.png']
processing (0055)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Hiphopdancing_20057.png']
processing (0060)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Sittinglaughing_20026.png']
processing (0065)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Sittinglaughing_20081.png']
processing (0070)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Sittinglaughing_20114.png']
processing (0075)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_dying_20002.png']
processing (0080)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_dying_20046.png']
processing (0085)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_dying_20068.png']
processing (0090)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_sittingcrawling_20016.png']
processing (0095)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_sittingcrawling_20031.png']
</code></pre>
</div>
</div>
<div id="8306c3cd-5f51-4ba5-af4a-8fcc0b64896f" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, shlex, subprocess</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>repo_dir <span class="op">=</span> <span class="vs">r"C:</span><span class="er">\</span><span class="vs">Users</span><span class="er">\</span><span class="vs">yalda</span><span class="er">\</span><span class="vs">OneDrive</span><span class="dv">\D</span><span class="vs">esktop</span><span class="er">\</span><span class="vs">Thesis apps</span><span class="er">\</span><span class="vs">Project Folder</span><span class="er">\</span><span class="vs">pytorch-CycleGAN-and-pix2pix"</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>os.chdir(repo_dir)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CWD:"</span>, os.getcwd())</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>cmd <span class="op">=</span> <span class="vs">r"""</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="vs">python train</span><span class="dv">.</span><span class="vs">py</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="vs">--dataroot </span><span class="dv">.</span><span class="vs">/datasets/stopmotion_pix2pix</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="vs">--name stopmotion_pix2pix_1024</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="vs">--model pix2pix</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="vs">--dataset_mode aligned</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="vs">--direction AtoB</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="vs">--input_nc 3</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="vs">--output_nc 3</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="vs">--netG unet_256</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a><span class="vs">--lambda_L1 70</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a><span class="vs">--gan_mode lsgan</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a><span class="vs">--preprocess resize_and_crop</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a><span class="vs">--load_size 1088</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a><span class="vs">--crop_size 1024</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a><span class="vs">--batch_size 1</span></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a><span class="vs">--gpu_ids 0</span></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a><span class="vs">--continue_train</span></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a><span class="vs">--epoch_count 151</span></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a><span class="vs">--lr 0</span><span class="dv">.</span><span class="vs">00002</span></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a><span class="vs">--n_epochs 100</span></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a><span class="vs">--n_epochs_decay 90</span></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a><span class="vs">--save_epoch_freq 5</span></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a><span class="vs">--print_freq 50</span></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a><span class="vs">--display_freq 200</span></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a><span class="vs">"""</span></span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>proc <span class="op">=</span> subprocess.run(shlex.split(<span class="st">" "</span>.join(cmd.split())), stdout<span class="op">=</span>subprocess.PIPE, stderr<span class="op">=</span>subprocess.STDOUT, text<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(proc.stdout)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>CWD: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
----------------- Options ---------------
               batch_size: 1                             
                    beta1: 0.5                           
          checkpoints_dir: ./checkpoints                 
           continue_train: True                             [default: False]
                crop_size: 1024                             [default: 256]
                 dataroot: ./datasets/stopmotion_pix2pix    [default: None]
             dataset_mode: aligned                       
                direction: AtoB                          
             display_freq: 200                              [default: 400]
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 151                              [default: 1]
                 gan_mode: lsgan                            [default: vanilla]
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                             [default: None]
                lambda_L1: 70.0                             [default: 100.0]
                load_iter: 0                                [default: 0]
                load_size: 1088                             [default: 286]
                       lr: 2e-05                            [default: 0.0002]
           lr_decay_iters: 50                            
                lr_policy: linear                        
         max_dataset_size: inf                           
                    model: pix2pix                          [default: cycle_gan]
                 n_epochs: 100                           
           n_epochs_decay: 90                               [default: 100]
               n_layers_D: 3                             
                     name: stopmotion_pix2pix_1024          [default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: unet_256                      
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: False                         
                  no_html: False                         
                     norm: batch                         
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 0                             
               preprocess: resize_and_crop               
               print_freq: 50                               [default: 100]
             save_by_iter: False                         
          save_epoch_freq: 5                             
         save_latest_freq: 5000                          
           serial_batches: False                         
                   suffix:                               
         update_html_freq: 1000                          
                use_wandb: False                         
                  verbose: False                         
       wandb_project_name: CycleGAN-and-pix2pix          
----------------- End -------------------
dataset [AlignedDataset] was created
The number of training images = 867
initialize network with normal
initialize network with normal
model [Pix2PixModel] was created
loading the model from checkpoints\stopmotion_pix2pix_1024\latest_net_G.pth
loading the model from checkpoints\stopmotion_pix2pix_1024\latest_net_D.pth
---------- Networks initialized -------------
[Network G] Total number of parameters : 54.414 M
[Network D] Total number of parameters : 2.769 M
-----------------------------------------------
[Network G] compiled with torch.compile
[Network D] compiled with torch.compile
create web directory checkpoints\stopmotion_pix2pix_1024\web...
(epoch: 151, iters: 50, time: 0.543, data: 53.819) G_GAN: 13.269 G_L1: 10.461 D_real: 9.950 D_fake: 8.089 
(epoch: 151, iters: 100, time: 0.562, data: 0.014) G_GAN: 4.528 G_L1: 8.210 D_real: 4.881 D_fake: 2.658 
(epoch: 151, iters: 150, time: 0.579, data: 0.008) G_GAN: 3.142 G_L1: 10.260 D_real: 3.039 D_fake: 1.917 
(epoch: 151, iters: 200, time: 3.566, data: 0.007) G_GAN: 1.548 G_L1: 7.420 D_real: 3.209 D_fake: 1.232 
(epoch: 151, iters: 250, time: 0.460, data: 0.014) G_GAN: 2.042 G_L1: 7.538 D_real: 3.105 D_fake: 1.501 
(epoch: 151, iters: 300, time: 0.460, data: 0.011) G_GAN: 1.642 G_L1: 7.711 D_real: 4.386 D_fake: 1.009 
(epoch: 151, iters: 350, time: 0.440, data: 0.008) G_GAN: 1.769 G_L1: 7.192 D_real: 2.328 D_fake: 0.925 
(epoch: 151, iters: 400, time: 0.453, data: 0.009) G_GAN: 1.883 G_L1: 6.231 D_real: 3.133 D_fake: 1.169 
(epoch: 151, iters: 450, time: 0.446, data: 0.009) G_GAN: 1.783 G_L1: 9.792 D_real: 2.472 D_fake: 1.435 
(epoch: 151, iters: 500, time: 0.563, data: 0.009) G_GAN: 2.100 G_L1: 8.316 D_real: 2.120 D_fake: 0.963 
(epoch: 151, iters: 550, time: 0.566, data: 0.009) G_GAN: 1.272 G_L1: 6.181 D_real: 2.474 D_fake: 1.500 
(epoch: 151, iters: 600, time: 0.577, data: 0.009) G_GAN: 1.789 G_L1: 6.484 D_real: 2.937 D_fake: 0.894 
(epoch: 151, iters: 650, time: 0.589, data: 0.010) G_GAN: 3.704 G_L1: 8.279 D_real: 3.869 D_fake: 1.705 
(epoch: 151, iters: 700, time: 0.556, data: 0.009) G_GAN: 1.511 G_L1: 7.541 D_real: 2.080 D_fake: 1.103 
(epoch: 151, iters: 750, time: 0.532, data: 0.009) G_GAN: 1.663 G_L1: 8.506 D_real: 2.130 D_fake: 0.876 
(epoch: 151, iters: 800, time: 0.560, data: 0.008) G_GAN: 2.194 G_L1: 8.271 D_real: 1.924 D_fake: 1.023 
(epoch: 151, iters: 850, time: 0.558, data: 0.010) G_GAN: 1.733 G_L1: 9.486 D_real: 2.376 D_fake: 0.937 
learning rate 0.0000088 -&gt; 0.0000086
End of epoch 151 / 190   Time Taken: 351 sec
(epoch: 152, iters: 33, time: 0.532, data: 0.010) G_GAN: 2.661 G_L1: 7.430 D_real: 2.419 D_fake: 1.047 
(epoch: 152, iters: 83, time: 0.567, data: 0.009) G_GAN: 1.716 G_L1: 9.661 D_real: 2.022 D_fake: 0.948 
(epoch: 152, iters: 133, time: 2.810, data: 0.009) G_GAN: 1.466 G_L1: 9.848 D_real: 1.953 D_fake: 0.717 
(epoch: 152, iters: 183, time: 0.547, data: 0.010) G_GAN: 2.071 G_L1: 9.282 D_real: 1.859 D_fake: 1.077 
(epoch: 152, iters: 233, time: 0.569, data: 0.009) G_GAN: 1.490 G_L1: 9.422 D_real: 1.994 D_fake: 0.741 
(epoch: 152, iters: 283, time: 0.532, data: 0.009) G_GAN: 2.635 G_L1: 9.533 D_real: 2.344 D_fake: 1.628 
(epoch: 152, iters: 333, time: 0.533, data: 0.008) G_GAN: 1.095 G_L1: 7.984 D_real: 1.865 D_fake: 0.765 
(epoch: 152, iters: 383, time: 0.529, data: 0.008) G_GAN: 2.228 G_L1: 9.515 D_real: 4.230 D_fake: 1.629 
(epoch: 152, iters: 433, time: 0.532, data: 0.009) G_GAN: 1.275 G_L1: 9.397 D_real: 1.664 D_fake: 0.927 
(epoch: 152, iters: 483, time: 0.534, data: 0.009) G_GAN: 3.281 G_L1: 7.950 D_real: 1.919 D_fake: 1.919 
(epoch: 152, iters: 533, time: 0.532, data: 0.011) G_GAN: 1.497 G_L1: 8.646 D_real: 1.714 D_fake: 1.375 
(epoch: 152, iters: 583, time: 0.532, data: 0.009) G_GAN: 1.993 G_L1: 9.094 D_real: 1.922 D_fake: 0.966 
(epoch: 152, iters: 633, time: 0.531, data: 0.009) G_GAN: 2.415 G_L1: 9.575 D_real: 1.616 D_fake: 1.056 
(epoch: 152, iters: 683, time: 0.532, data: 0.010) G_GAN: 2.601 G_L1: 8.482 D_real: 1.711 D_fake: 1.299 
(epoch: 152, iters: 733, time: 0.532, data: 0.009) G_GAN: 1.673 G_L1: 8.627 D_real: 1.696 D_fake: 0.845 
(epoch: 152, iters: 783, time: 0.532, data: 0.008) G_GAN: 1.824 G_L1: 7.859 D_real: 2.024 D_fake: 0.912 
(epoch: 152, iters: 833, time: 0.525, data: 0.009) G_GAN: 1.471 G_L1: 9.968 D_real: 1.623 D_fake: 0.826 
learning rate 0.0000086 -&gt; 0.0000084
End of epoch 152 / 190   Time Taken: 317 sec
(epoch: 153, iters: 16, time: 0.558, data: 0.011) G_GAN: 1.373 G_L1: 9.417 D_real: 2.017 D_fake: 1.471 
(epoch: 153, iters: 66, time: 2.559, data: 0.010) G_GAN: 1.207 G_L1: 8.871 D_real: 1.624 D_fake: 1.694 
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
(epoch: 153, iters: 116, time: 0.590, data: 0.010) G_GAN: 1.242 G_L1: 10.691 D_real: 2.337 D_fake: 1.364 
(epoch: 153, iters: 166, time: 0.572, data: 0.008) G_GAN: 1.442 G_L1: 13.936 D_real: 1.765 D_fake: 1.613 
(epoch: 153, iters: 216, time: 0.569, data: 0.009) G_GAN: 2.080 G_L1: 9.891 D_real: 1.583 D_fake: 1.006 
(epoch: 153, iters: 266, time: 2.601, data: 0.010) G_GAN: 1.536 G_L1: 9.222 D_real: 1.660 D_fake: 1.436 
(epoch: 153, iters: 316, time: 0.568, data: 0.010) G_GAN: 1.560 G_L1: 8.991 D_real: 1.989 D_fake: 1.179 
(epoch: 153, iters: 366, time: 0.592, data: 0.009) G_GAN: 1.869 G_L1: 13.353 D_real: 2.465 D_fake: 1.505 
(epoch: 153, iters: 416, time: 0.578, data: 0.009) G_GAN: 1.677 G_L1: 9.474 D_real: 2.206 D_fake: 1.138 
(epoch: 153, iters: 466, time: 0.575, data: 0.009) G_GAN: 1.706 G_L1: 10.453 D_real: 1.728 D_fake: 1.206 
(epoch: 153, iters: 516, time: 0.561, data: 0.010) G_GAN: 3.435 G_L1: 10.573 D_real: 1.651 D_fake: 2.262 
(epoch: 153, iters: 566, time: 0.534, data: 0.010) G_GAN: 1.786 G_L1: 9.541 D_real: 2.045 D_fake: 1.579 
(epoch: 153, iters: 616, time: 0.534, data: 0.009) G_GAN: 1.654 G_L1: 11.397 D_real: 1.661 D_fake: 1.303 
(epoch: 153, iters: 666, time: 0.550, data: 0.009) G_GAN: 2.025 G_L1: 10.481 D_real: 1.497 D_fake: 1.538 
(epoch: 153, iters: 716, time: 0.565, data: 0.009) G_GAN: 1.481 G_L1: 11.958 D_real: 1.499 D_fake: 1.343 
(epoch: 153, iters: 766, time: 0.565, data: 0.008) G_GAN: 2.332 G_L1: 11.715 D_real: 1.723 D_fake: 1.791 
(epoch: 153, iters: 816, time: 0.567, data: 0.009) G_GAN: 1.859 G_L1: 10.246 D_real: 1.592 D_fake: 1.597 
(epoch: 153, iters: 866, time: 0.533, data: 0.010) G_GAN: 2.256 G_L1: 12.544 D_real: 3.417 D_fake: 2.121 
learning rate 0.0000084 -&gt; 0.0000081
End of epoch 153 / 190   Time Taken: 350 sec
(epoch: 154, iters: 49, time: 0.557, data: 0.010) G_GAN: 1.989 G_L1: 10.644 D_real: 1.607 D_fake: 1.735 
(epoch: 154, iters: 99, time: 0.562, data: 0.009) G_GAN: 2.704 G_L1: 12.260 D_real: 1.990 D_fake: 1.673 
(epoch: 154, iters: 149, time: 0.558, data: 0.010) G_GAN: 3.237 G_L1: 13.519 D_real: 1.937 D_fake: 1.789 
(epoch: 154, iters: 199, time: 2.609, data: 0.009) G_GAN: 1.624 G_L1: 11.762 D_real: 1.686 D_fake: 1.492 
(epoch: 154, iters: 249, time: 0.583, data: 0.010) G_GAN: 2.034 G_L1: 12.318 D_real: 1.519 D_fake: 2.285 
(epoch: 154, iters: 299, time: 0.536, data: 0.009) G_GAN: 2.097 G_L1: 10.987 D_real: 1.784 D_fake: 1.348 
(epoch: 154, iters: 349, time: 0.565, data: 0.009) G_GAN: 1.520 G_L1: 11.159 D_real: 1.641 D_fake: 1.934 
(epoch: 154, iters: 399, time: 2.474, data: 0.008) G_GAN: 1.479 G_L1: 12.588 D_real: 1.658 D_fake: 1.459 
(epoch: 154, iters: 449, time: 0.533, data: 0.009) G_GAN: 1.646 G_L1: 10.348 D_real: 1.740 D_fake: 1.591 
(epoch: 154, iters: 499, time: 0.535, data: 0.009) G_GAN: 1.796 G_L1: 10.626 D_real: 1.582 D_fake: 1.217 
(epoch: 154, iters: 549, time: 0.595, data: 0.009) G_GAN: 1.603 G_L1: 10.594 D_real: 1.518 D_fake: 1.042 
(epoch: 154, iters: 599, time: 0.564, data: 0.009) G_GAN: 1.255 G_L1: 11.572 D_real: 1.318 D_fake: 1.536 
(epoch: 154, iters: 649, time: 0.595, data: 0.009) G_GAN: 1.984 G_L1: 12.147 D_real: 1.396 D_fake: 1.170 
(epoch: 154, iters: 699, time: 0.587, data: 0.009) G_GAN: 1.476 G_L1: 9.983 D_real: 1.440 D_fake: 1.390 
(epoch: 154, iters: 749, time: 0.569, data: 0.009) G_GAN: 1.399 G_L1: 11.113 D_real: 1.588 D_fake: 1.135 
(epoch: 154, iters: 799, time: 0.589, data: 0.008) G_GAN: 1.363 G_L1: 11.330 D_real: 1.785 D_fake: 1.472 
(epoch: 154, iters: 849, time: 0.558, data: 0.010) G_GAN: 2.605 G_L1: 13.280 D_real: 1.563 D_fake: 1.627 
learning rate 0.0000081 -&gt; 0.0000079
End of epoch 154 / 190   Time Taken: 341 sec
(epoch: 155, iters: 32, time: 0.573, data: 0.011) G_GAN: 1.707 G_L1: 12.471 D_real: 1.540 D_fake: 1.321 
(epoch: 155, iters: 82, time: 0.554, data: 0.009) G_GAN: 2.392 G_L1: 12.792 D_real: 1.421 D_fake: 1.371 
(epoch: 155, iters: 132, time: 2.501, data: 0.009) G_GAN: 1.613 G_L1: 11.618 D_real: 1.288 D_fake: 1.202 
(epoch: 155, iters: 182, time: 0.559, data: 0.011) G_GAN: 1.251 G_L1: 14.134 D_real: 1.677 D_fake: 1.963 
(epoch: 155, iters: 232, time: 0.573, data: 0.009) G_GAN: 2.211 G_L1: 12.669 D_real: 2.008 D_fake: 1.271 
(epoch: 155, iters: 282, time: 0.585, data: 0.010) G_GAN: 1.798 G_L1: 11.216 D_real: 1.341 D_fake: 1.094 
(epoch: 155, iters: 332, time: 0.528, data: 0.010) G_GAN: 1.121 G_L1: 11.694 D_real: 1.473 D_fake: 1.297 
(epoch: 155, iters: 382, time: 0.528, data: 0.009) G_GAN: 1.883 G_L1: 10.563 D_real: 1.181 D_fake: 1.110 
(epoch: 155, iters: 432, time: 0.557, data: 0.009) G_GAN: 2.051 G_L1: 13.478 D_real: 1.278 D_fake: 1.244 
(epoch: 155, iters: 482, time: 0.564, data: 0.010) G_GAN: 1.249 G_L1: 10.181 D_real: 1.161 D_fake: 1.271 
(epoch: 155, iters: 532, time: 2.470, data: 0.011) G_GAN: 1.397 G_L1: 10.677 D_real: 1.503 D_fake: 1.082 
(epoch: 155, iters: 582, time: 0.567, data: 0.011) G_GAN: 2.542 G_L1: 12.360 D_real: 1.425 D_fake: 1.207 
(epoch: 155, iters: 632, time: 0.575, data: 0.009) G_GAN: 2.533 G_L1: 12.229 D_real: 1.426 D_fake: 1.268 
(epoch: 155, iters: 682, time: 0.594, data: 0.009) G_GAN: 1.868 G_L1: 12.065 D_real: 1.352 D_fake: 1.530 
(epoch: 155, iters: 732, time: 0.592, data: 0.009) G_GAN: 1.749 G_L1: 10.449 D_real: 1.095 D_fake: 1.069 
(epoch: 155, iters: 782, time: 0.576, data: 0.009) G_GAN: 1.184 G_L1: 10.467 D_real: 1.180 D_fake: 1.026 
(epoch: 155, iters: 832, time: 0.571, data: 0.010) G_GAN: 2.237 G_L1: 11.322 D_real: 1.280 D_fake: 1.460 
learning rate 0.0000079 -&gt; 0.0000077
saving the model at the end of epoch 155, iters 4335
End of epoch 155 / 190   Time Taken: 343 sec
(epoch: 156, iters: 15, time: 0.528, data: 0.010) G_GAN: 1.113 G_L1: 12.805 D_real: 1.264 D_fake: 0.839 
(epoch: 156, iters: 65, time: 2.552, data: 0.009) G_GAN: 2.113 G_L1: 11.449 D_real: 1.691 D_fake: 1.161 
(epoch: 156, iters: 115, time: 0.524, data: 0.011) G_GAN: 1.861 G_L1: 10.577 D_real: 1.118 D_fake: 0.827 
(epoch: 156, iters: 165, time: 0.526, data: 0.009) G_GAN: 1.527 G_L1: 9.822 D_real: 1.417 D_fake: 0.792 
(epoch: 156, iters: 215, time: 0.530, data: 0.010) G_GAN: 1.551 G_L1: 8.788 D_real: 1.370 D_fake: 0.933 
(epoch: 156, iters: 265, time: 0.530, data: 0.009) G_GAN: 1.397 G_L1: 9.287 D_real: 1.314 D_fake: 1.046 
(epoch: 156, iters: 315, time: 0.528, data: 0.009) G_GAN: 1.852 G_L1: 9.879 D_real: 1.083 D_fake: 0.656 
(epoch: 156, iters: 365, time: 0.531, data: 0.009) G_GAN: 1.862 G_L1: 14.326 D_real: 1.344 D_fake: 0.767 
(epoch: 156, iters: 415, time: 0.578, data: 0.009) G_GAN: 1.044 G_L1: 10.516 D_real: 1.188 D_fake: 1.638 
(epoch: 156, iters: 465, time: 0.560, data: 0.010) G_GAN: 1.485 G_L1: 8.729 D_real: 1.220 D_fake: 1.606 
(epoch: 156, iters: 515, time: 0.581, data: 0.009) G_GAN: 1.316 G_L1: 8.317 D_real: 1.166 D_fake: 0.604 
(epoch: 156, iters: 565, time: 0.570, data: 0.008) G_GAN: 1.813 G_L1: 7.724 D_real: 1.062 D_fake: 0.707 
(epoch: 156, iters: 615, time: 0.587, data: 0.009) G_GAN: 1.623 G_L1: 9.235 D_real: 1.752 D_fake: 0.743 
(epoch: 156, iters: 665, time: 2.561, data: 0.010) G_GAN: 1.641 G_L1: 9.686 D_real: 1.392 D_fake: 0.532 
saving the latest model (epoch 156, total_iters 5000)
(epoch: 156, iters: 715, time: 0.528, data: 0.011) G_GAN: 1.288 G_L1: 7.860 D_real: 1.099 D_fake: 0.420 
(epoch: 156, iters: 765, time: 0.559, data: 0.010) G_GAN: 1.346 G_L1: 8.529 D_real: 1.287 D_fake: 0.714 
(epoch: 156, iters: 815, time: 0.576, data: 0.010) G_GAN: 0.826 G_L1: 10.402 D_real: 1.123 D_fake: 0.773 
(epoch: 156, iters: 865, time: 0.531, data: 0.009) G_GAN: 1.370 G_L1: 8.477 D_real: 2.602 D_fake: 0.481 
learning rate 0.0000077 -&gt; 0.0000075
End of epoch 156 / 190   Time Taken: 336 sec
(epoch: 157, iters: 48, time: 0.570, data: 0.009) G_GAN: 1.159 G_L1: 9.273 D_real: 1.947 D_fake: 0.623 
(epoch: 157, iters: 98, time: 0.530, data: 0.009) G_GAN: 1.558 G_L1: 7.960 D_real: 1.365 D_fake: 0.573 
(epoch: 157, iters: 148, time: 0.565, data: 0.009) G_GAN: 1.316 G_L1: 8.611 D_real: 1.419 D_fake: 0.473 
(epoch: 157, iters: 198, time: 2.607, data: 0.011) G_GAN: 1.260 G_L1: 9.967 D_real: 1.255 D_fake: 0.530 
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
(epoch: 157, iters: 248, time: 0.529, data: 0.009) G_GAN: 0.815 G_L1: 7.562 D_real: 1.012 D_fake: 0.679 
(epoch: 157, iters: 298, time: 0.528, data: 0.008) G_GAN: 0.906 G_L1: 6.628 D_real: 1.029 D_fake: 0.426 
(epoch: 157, iters: 348, time: 0.533, data: 0.009) G_GAN: 0.861 G_L1: 8.747 D_real: 1.371 D_fake: 0.573 
(epoch: 157, iters: 398, time: 0.533, data: 0.011) G_GAN: 1.184 G_L1: 7.419 D_real: 1.029 D_fake: 0.339 
(epoch: 157, iters: 448, time: 0.530, data: 0.009) G_GAN: 1.835 G_L1: 8.268 D_real: 1.227 D_fake: 0.546 
(epoch: 157, iters: 498, time: 0.535, data: 0.008) G_GAN: 1.169 G_L1: 8.788 D_real: 1.122 D_fake: 0.355 
(epoch: 157, iters: 548, time: 0.535, data: 0.010) G_GAN: 1.558 G_L1: 6.782 D_real: 1.187 D_fake: 0.406 
(epoch: 157, iters: 598, time: 0.570, data: 0.010) G_GAN: 1.846 G_L1: 7.745 D_real: 1.054 D_fake: 0.417 
(epoch: 157, iters: 648, time: 0.549, data: 0.010) G_GAN: 1.259 G_L1: 7.900 D_real: 1.100 D_fake: 0.600 
(epoch: 157, iters: 698, time: 0.532, data: 0.008) G_GAN: 0.828 G_L1: 8.144 D_real: 0.927 D_fake: 0.527 
(epoch: 157, iters: 748, time: 0.583, data: 0.009) G_GAN: 1.402 G_L1: 9.195 D_real: 1.107 D_fake: 0.440 
(epoch: 157, iters: 798, time: 2.648, data: 0.009) G_GAN: 1.029 G_L1: 8.871 D_real: 1.258 D_fake: 0.336 
(epoch: 157, iters: 848, time: 0.597, data: 0.010) G_GAN: 0.922 G_L1: 8.945 D_real: 1.085 D_fake: 0.351 
learning rate 0.0000075 -&gt; 0.0000073
End of epoch 157 / 190   Time Taken: 336 sec
(epoch: 158, iters: 31, time: 0.563, data: 0.009) G_GAN: 1.038 G_L1: 7.072 D_real: 1.096 D_fake: 0.291 
(epoch: 158, iters: 81, time: 0.572, data: 0.009) G_GAN: 1.257 G_L1: 8.429 D_real: 1.133 D_fake: 0.476 
(epoch: 158, iters: 131, time: 2.590, data: 0.010) G_GAN: 0.980 G_L1: 7.529 D_real: 0.896 D_fake: 0.347 
(epoch: 158, iters: 181, time: 0.560, data: 0.010) G_GAN: 1.336 G_L1: 6.708 D_real: 1.396 D_fake: 0.379 
(epoch: 158, iters: 231, time: 0.570, data: 0.010) G_GAN: 1.183 G_L1: 6.748 D_real: 1.205 D_fake: 0.335 
(epoch: 158, iters: 281, time: 0.552, data: 0.009) G_GAN: 1.636 G_L1: 7.346 D_real: 0.956 D_fake: 0.531 
(epoch: 158, iters: 331, time: 0.536, data: 0.009) G_GAN: 1.494 G_L1: 8.150 D_real: 1.038 D_fake: 0.480 
(epoch: 158, iters: 381, time: 0.583, data: 0.010) G_GAN: 0.738 G_L1: 7.486 D_real: 0.796 D_fake: 0.439 
(epoch: 158, iters: 431, time: 0.562, data: 0.010) G_GAN: 1.012 G_L1: 8.061 D_real: 0.974 D_fake: 0.321 
(epoch: 158, iters: 481, time: 0.535, data: 0.009) G_GAN: 0.785 G_L1: 7.816 D_real: 2.010 D_fake: 0.412 
(epoch: 158, iters: 531, time: 0.534, data: 0.010) G_GAN: 1.554 G_L1: 7.327 D_real: 1.037 D_fake: 0.407 
(epoch: 158, iters: 581, time: 0.573, data: 0.009) G_GAN: 1.431 G_L1: 7.688 D_real: 0.929 D_fake: 0.328 
(epoch: 158, iters: 631, time: 0.578, data: 0.009) G_GAN: 1.710 G_L1: 9.301 D_real: 0.779 D_fake: 0.442 
(epoch: 158, iters: 681, time: 0.548, data: 0.009) G_GAN: 1.850 G_L1: 7.959 D_real: 0.984 D_fake: 0.451 
(epoch: 158, iters: 731, time: 0.617, data: 0.009) G_GAN: 0.957 G_L1: 9.895 D_real: 1.065 D_fake: 0.450 
(epoch: 158, iters: 781, time: 0.584, data: 0.010) G_GAN: 1.135 G_L1: 7.932 D_real: 0.940 D_fake: 0.324 
(epoch: 158, iters: 831, time: 0.620, data: 0.009) G_GAN: 1.290 G_L1: 11.307 D_real: 0.867 D_fake: 0.382 
learning rate 0.0000073 -&gt; 0.0000070
End of epoch 158 / 190   Time Taken: 348 sec
(epoch: 159, iters: 14, time: 0.589, data: 0.010) G_GAN: 0.880 G_L1: 6.415 D_real: 1.118 D_fake: 0.275 
(epoch: 159, iters: 64, time: 2.728, data: 0.009) G_GAN: 1.339 G_L1: 8.454 D_real: 1.043 D_fake: 0.346 
(epoch: 159, iters: 114, time: 0.594, data: 0.010) G_GAN: 2.150 G_L1: 7.990 D_real: 0.829 D_fake: 0.653 
(epoch: 159, iters: 164, time: 0.606, data: 0.011) G_GAN: 1.569 G_L1: 8.984 D_real: 0.950 D_fake: 0.397 
(epoch: 159, iters: 214, time: 0.592, data: 0.010) G_GAN: 0.922 G_L1: 6.286 D_real: 1.283 D_fake: 0.321 
(epoch: 159, iters: 264, time: 0.607, data: 0.009) G_GAN: 0.767 G_L1: 6.112 D_real: 1.183 D_fake: 0.240 
(epoch: 159, iters: 314, time: 0.603, data: 0.008) G_GAN: 0.765 G_L1: 7.328 D_real: 0.858 D_fake: 0.347 
(epoch: 159, iters: 364, time: 0.590, data: 0.010) G_GAN: 1.181 G_L1: 7.089 D_real: 1.089 D_fake: 0.289 
(epoch: 159, iters: 414, time: 0.611, data: 0.009) G_GAN: 1.425 G_L1: 10.103 D_real: 0.928 D_fake: 0.368 
(epoch: 159, iters: 464, time: 0.634, data: 0.009) G_GAN: 0.620 G_L1: 8.572 D_real: 0.740 D_fake: 0.539 
(epoch: 159, iters: 514, time: 0.601, data: 0.010) G_GAN: 0.791 G_L1: 10.305 D_real: 0.790 D_fake: 0.425 
(epoch: 159, iters: 564, time: 0.605, data: 0.011) G_GAN: 1.507 G_L1: 8.933 D_real: 0.726 D_fake: 0.324 
(epoch: 159, iters: 614, time: 0.605, data: 0.010) G_GAN: 0.878 G_L1: 7.299 D_real: 1.099 D_fake: 0.308 
(epoch: 159, iters: 664, time: 0.576, data: 0.010) G_GAN: 1.071 G_L1: 8.221 D_real: 0.864 D_fake: 0.301 
(epoch: 159, iters: 714, time: 0.600, data: 0.010) G_GAN: 1.021 G_L1: 7.117 D_real: 0.756 D_fake: 0.305 
(epoch: 159, iters: 764, time: 0.625, data: 0.011) G_GAN: 1.239 G_L1: 13.598 D_real: 0.833 D_fake: 0.382 
(epoch: 159, iters: 814, time: 0.646, data: 0.010) G_GAN: 0.976 G_L1: 7.400 D_real: 0.784 D_fake: 0.250 
(epoch: 159, iters: 864, time: 0.558, data: 0.010) G_GAN: 1.176 G_L1: 7.041 D_real: 0.815 D_fake: 0.298 
learning rate 0.0000070 -&gt; 0.0000068
End of epoch 159 / 190   Time Taken: 379 sec
(epoch: 160, iters: 47, time: 0.581, data: 0.010) G_GAN: 1.409 G_L1: 10.293 D_real: 1.005 D_fake: 0.370 
(epoch: 160, iters: 97, time: 0.601, data: 0.009) G_GAN: 0.966 G_L1: 8.102 D_real: 0.760 D_fake: 0.288 
(epoch: 160, iters: 147, time: 0.612, data: 0.009) G_GAN: 1.072 G_L1: 9.242 D_real: 0.767 D_fake: 0.224 
(epoch: 160, iters: 197, time: 2.802, data: 0.010) G_GAN: 1.079 G_L1: 6.940 D_real: 1.036 D_fake: 0.442 
(epoch: 160, iters: 247, time: 0.609, data: 0.010) G_GAN: 1.350 G_L1: 8.385 D_real: 0.778 D_fake: 0.353 
(epoch: 160, iters: 297, time: 0.605, data: 0.010) G_GAN: 1.138 G_L1: 6.663 D_real: 0.707 D_fake: 0.200 
(epoch: 160, iters: 347, time: 0.605, data: 0.011) G_GAN: 1.329 G_L1: 7.788 D_real: 0.754 D_fake: 0.278 
(epoch: 160, iters: 397, time: 0.606, data: 0.009) G_GAN: 1.177 G_L1: 7.098 D_real: 0.830 D_fake: 0.367 
(epoch: 160, iters: 447, time: 0.577, data: 0.010) G_GAN: 1.227 G_L1: 7.391 D_real: 0.814 D_fake: 0.337 
(epoch: 160, iters: 497, time: 0.592, data: 0.010) G_GAN: 0.910 G_L1: 10.118 D_real: 0.860 D_fake: 0.280 
(epoch: 160, iters: 547, time: 0.603, data: 0.009) G_GAN: 1.279 G_L1: 10.938 D_real: 1.195 D_fake: 0.354 
(epoch: 160, iters: 597, time: 0.586, data: 0.010) G_GAN: 1.542 G_L1: 9.004 D_real: 0.676 D_fake: 0.272 
(epoch: 160, iters: 647, time: 0.614, data: 0.009) G_GAN: 0.964 G_L1: 8.934 D_real: 0.696 D_fake: 0.265 
(epoch: 160, iters: 697, time: 0.619, data: 0.016) G_GAN: 0.927 G_L1: 9.739 D_real: 0.634 D_fake: 0.238 
(epoch: 160, iters: 747, time: 0.596, data: 0.010) G_GAN: 0.995 G_L1: 8.353 D_real: 0.716 D_fake: 0.303 
(epoch: 160, iters: 797, time: 0.577, data: 0.009) G_GAN: 1.264 G_L1: 8.227 D_real: 1.041 D_fake: 0.308 
(epoch: 160, iters: 847, time: 0.596, data: 0.008) G_GAN: 1.119 G_L1: 7.478 D_real: 0.612 D_fake: 0.226 
learning rate 0.0000068 -&gt; 0.0000066
saving the model at the end of epoch 160, iters 8670
End of epoch 160 / 190   Time Taken: 374 sec
(epoch: 161, iters: 30, time: 0.589, data: 0.013) G_GAN: 1.395 G_L1: 8.971 D_real: 0.569 D_fake: 0.201 
(epoch: 161, iters: 80, time: 0.592, data: 0.010) G_GAN: 1.578 G_L1: 8.167 D_real: 0.839 D_fake: 0.265 
(epoch: 161, iters: 130, time: 2.622, data: 0.010) G_GAN: 1.111 G_L1: 8.020 D_real: 0.791 D_fake: 0.440 
(epoch: 161, iters: 180, time: 0.561, data: 0.010) G_GAN: 0.933 G_L1: 7.698 D_real: 0.840 D_fake: 0.294 
(epoch: 161, iters: 230, time: 0.561, data: 0.008) G_GAN: 0.864 G_L1: 8.446 D_real: 0.696 D_fake: 0.411 
(epoch: 161, iters: 280, time: 0.572, data: 0.009) G_GAN: 1.342 G_L1: 6.526 D_real: 0.807 D_fake: 0.261 
(epoch: 161, iters: 330, time: 2.759, data: 0.011) G_GAN: 0.957 G_L1: 7.548 D_real: 0.592 D_fake: 0.236 
(epoch: 161, iters: 380, time: 0.607, data: 0.009) G_GAN: 1.220 G_L1: 6.908 D_real: 0.626 D_fake: 0.240 
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
(epoch: 161, iters: 430, time: 0.614, data: 0.009) G_GAN: 0.735 G_L1: 8.203 D_real: 0.704 D_fake: 0.326 
(epoch: 161, iters: 480, time: 0.611, data: 0.010) G_GAN: 1.242 G_L1: 7.549 D_real: 0.669 D_fake: 0.248 
(epoch: 161, iters: 530, time: 0.611, data: 0.010) G_GAN: 1.093 G_L1: 6.839 D_real: 0.531 D_fake: 0.189 
(epoch: 161, iters: 580, time: 0.649, data: 0.009) G_GAN: 1.002 G_L1: 6.232 D_real: 0.582 D_fake: 0.261 
(epoch: 161, iters: 630, time: 0.597, data: 0.011) G_GAN: 1.197 G_L1: 7.720 D_real: 0.626 D_fake: 0.228 
(epoch: 161, iters: 680, time: 0.601, data: 0.010) G_GAN: 0.992 G_L1: 7.899 D_real: 0.679 D_fake: 0.368 
(epoch: 161, iters: 730, time: 0.586, data: 0.010) G_GAN: 0.945 G_L1: 6.250 D_real: 0.729 D_fake: 0.175 
(epoch: 161, iters: 780, time: 0.617, data: 0.010) G_GAN: 1.039 G_L1: 6.362 D_real: 0.649 D_fake: 0.219 
(epoch: 161, iters: 830, time: 0.633, data: 0.010) G_GAN: 1.009 G_L1: 8.096 D_real: 0.712 D_fake: 0.383 
learning rate 0.0000066 -&gt; 0.0000064
End of epoch 161 / 190   Time Taken: 376 sec
(epoch: 162, iters: 13, time: 0.596, data: 0.009) G_GAN: 1.046 G_L1: 6.576 D_real: 0.700 D_fake: 0.267 
(epoch: 162, iters: 63, time: 2.763, data: 0.009) G_GAN: 1.103 G_L1: 6.846 D_real: 0.640 D_fake: 0.253 
(epoch: 162, iters: 113, time: 0.631, data: 0.009) G_GAN: 1.042 G_L1: 8.995 D_real: 0.937 D_fake: 0.279 
(epoch: 162, iters: 163, time: 0.602, data: 0.010) G_GAN: 0.888 G_L1: 8.398 D_real: 0.958 D_fake: 0.232 
(epoch: 162, iters: 213, time: 0.601, data: 0.009) G_GAN: 1.097 G_L1: 8.009 D_real: 0.632 D_fake: 0.212 
(epoch: 162, iters: 263, time: 0.605, data: 0.010) G_GAN: 0.632 G_L1: 6.210 D_real: 0.638 D_fake: 0.482 
(epoch: 162, iters: 313, time: 0.611, data: 0.010) G_GAN: 0.723 G_L1: 6.199 D_real: 0.550 D_fake: 0.297 
(epoch: 162, iters: 363, time: 0.595, data: 0.011) G_GAN: 1.143 G_L1: 9.039 D_real: 0.597 D_fake: 0.203 
(epoch: 162, iters: 413, time: 0.610, data: 0.010) G_GAN: 0.903 G_L1: 6.700 D_real: 0.692 D_fake: 0.244 
(epoch: 162, iters: 463, time: 2.970, data: 0.010) G_GAN: 1.156 G_L1: 8.495 D_real: 1.053 D_fake: 0.280 
saving the latest model (epoch 162, total_iters 10000)
(epoch: 162, iters: 513, time: 0.596, data: 0.008) G_GAN: 1.321 G_L1: 7.755 D_real: 0.819 D_fake: 0.388 
(epoch: 162, iters: 563, time: 0.597, data: 0.010) G_GAN: 0.943 G_L1: 6.698 D_real: 0.891 D_fake: 0.251 
(epoch: 162, iters: 613, time: 0.596, data: 0.010) G_GAN: 0.847 G_L1: 11.334 D_real: 0.867 D_fake: 0.317 
(epoch: 162, iters: 663, time: 0.591, data: 0.009) G_GAN: 1.110 G_L1: 7.458 D_real: 0.638 D_fake: 0.206 
(epoch: 162, iters: 713, time: 0.604, data: 0.010) G_GAN: 1.006 G_L1: 7.299 D_real: 0.872 D_fake: 0.278 
(epoch: 162, iters: 763, time: 0.604, data: 0.010) G_GAN: 1.023 G_L1: 6.431 D_real: 0.543 D_fake: 0.229 
(epoch: 162, iters: 813, time: 0.595, data: 0.010) G_GAN: 0.970 G_L1: 8.003 D_real: 0.601 D_fake: 0.230 
(epoch: 162, iters: 863, time: 0.591, data: 0.011) G_GAN: 1.290 G_L1: 7.099 D_real: 0.570 D_fake: 0.232 
learning rate 0.0000064 -&gt; 0.0000062
End of epoch 162 / 190   Time Taken: 376 sec
(epoch: 163, iters: 46, time: 0.593, data: 0.009) G_GAN: 0.960 G_L1: 6.642 D_real: 0.568 D_fake: 0.215 
(epoch: 163, iters: 96, time: 0.598, data: 0.010) G_GAN: 1.072 G_L1: 6.299 D_real: 0.637 D_fake: 0.247 
(epoch: 163, iters: 146, time: 0.598, data: 0.010) G_GAN: 1.056 G_L1: 6.623 D_real: 0.689 D_fake: 0.242 
(epoch: 163, iters: 196, time: 2.796, data: 0.009) G_GAN: 1.228 G_L1: 8.276 D_real: 0.576 D_fake: 0.211 
(epoch: 163, iters: 246, time: 0.575, data: 0.009) G_GAN: 1.154 G_L1: 10.098 D_real: 0.748 D_fake: 0.267 
(epoch: 163, iters: 296, time: 0.566, data: 0.009) G_GAN: 0.915 G_L1: 8.414 D_real: 0.647 D_fake: 0.251 
(epoch: 163, iters: 346, time: 0.601, data: 0.009) G_GAN: 1.121 G_L1: 7.076 D_real: 0.560 D_fake: 0.203 
(epoch: 163, iters: 396, time: 0.602, data: 0.010) G_GAN: 0.718 G_L1: 7.915 D_real: 0.705 D_fake: 0.302 
(epoch: 163, iters: 446, time: 0.605, data: 0.009) G_GAN: 1.076 G_L1: 8.185 D_real: 0.652 D_fake: 0.234 
(epoch: 163, iters: 496, time: 0.595, data: 0.009) G_GAN: 0.933 G_L1: 8.380 D_real: 0.599 D_fake: 0.279 
(epoch: 163, iters: 546, time: 0.598, data: 0.010) G_GAN: 0.739 G_L1: 7.731 D_real: 0.621 D_fake: 0.322 
(epoch: 163, iters: 596, time: 2.809, data: 0.009) G_GAN: 0.904 G_L1: 8.073 D_real: 0.776 D_fake: 0.300 
(epoch: 163, iters: 646, time: 0.590, data: 0.010) G_GAN: 1.400 G_L1: 6.254 D_real: 0.496 D_fake: 0.202 
(epoch: 163, iters: 696, time: 0.606, data: 0.008) G_GAN: 1.085 G_L1: 7.363 D_real: 0.519 D_fake: 0.254 
(epoch: 163, iters: 746, time: 0.598, data: 0.009) G_GAN: 0.876 G_L1: 7.507 D_real: 0.594 D_fake: 0.267 
(epoch: 163, iters: 796, time: 0.847, data: 0.010) G_GAN: 1.022 G_L1: 6.879 D_real: 0.610 D_fake: 0.202 
(epoch: 163, iters: 846, time: 0.698, data: 0.079) G_GAN: 1.167 G_L1: 9.086 D_real: 0.492 D_fake: 0.167 
learning rate 0.0000062 -&gt; 0.0000059
End of epoch 163 / 190   Time Taken: 418 sec
(epoch: 164, iters: 29, time: 0.532, data: 0.059) G_GAN: 1.277 G_L1: 8.400 D_real: 0.584 D_fake: 0.290 
(epoch: 164, iters: 79, time: 0.536, data: 0.009) G_GAN: 1.267 G_L1: 5.956 D_real: 0.711 D_fake: 0.352 
(epoch: 164, iters: 129, time: 2.606, data: 0.012) G_GAN: 1.101 G_L1: 7.137 D_real: 0.528 D_fake: 0.208 
(epoch: 164, iters: 179, time: 0.530, data: 0.010) G_GAN: 1.367 G_L1: 7.878 D_real: 0.724 D_fake: 0.350 
(epoch: 164, iters: 229, time: 0.534, data: 0.009) G_GAN: 0.859 G_L1: 6.517 D_real: 0.472 D_fake: 0.209 
(epoch: 164, iters: 279, time: 0.527, data: 0.009) G_GAN: 0.915 G_L1: 9.025 D_real: 0.506 D_fake: 0.241 
(epoch: 164, iters: 329, time: 0.530, data: 0.008) G_GAN: 1.032 G_L1: 7.606 D_real: 0.569 D_fake: 0.212 
(epoch: 164, iters: 379, time: 0.597, data: 0.008) G_GAN: 1.099 G_L1: 7.018 D_real: 0.531 D_fake: 0.228 
(epoch: 164, iters: 429, time: 0.569, data: 0.010) G_GAN: 1.261 G_L1: 7.589 D_real: 0.533 D_fake: 0.196 
(epoch: 164, iters: 479, time: 0.575, data: 0.009) G_GAN: 1.409 G_L1: 7.419 D_real: 0.539 D_fake: 0.293 
(epoch: 164, iters: 529, time: 0.563, data: 0.009) G_GAN: 1.037 G_L1: 7.458 D_real: 0.496 D_fake: 0.207 
(epoch: 164, iters: 579, time: 0.574, data: 0.009) G_GAN: 1.062 G_L1: 6.219 D_real: 0.459 D_fake: 0.196 
(epoch: 164, iters: 629, time: 0.575, data: 0.009) G_GAN: 0.877 G_L1: 6.683 D_real: 0.517 D_fake: 0.215 
(epoch: 164, iters: 679, time: 0.572, data: 0.010) G_GAN: 0.926 G_L1: 8.774 D_real: 0.457 D_fake: 0.258 
(epoch: 164, iters: 729, time: 2.910, data: 0.011) G_GAN: 0.959 G_L1: 7.960 D_real: 0.705 D_fake: 0.178 
(epoch: 164, iters: 779, time: 0.576, data: 0.009) G_GAN: 0.978 G_L1: 8.880 D_real: 0.464 D_fake: 0.174 
(epoch: 164, iters: 829, time: 0.576, data: 0.009) G_GAN: 1.107 G_L1: 6.668 D_real: 0.565 D_fake: 0.245 
learning rate 0.0000059 -&gt; 0.0000057
End of epoch 164 / 190   Time Taken: 339 sec
(epoch: 165, iters: 12, time: 0.564, data: 0.009) G_GAN: 0.864 G_L1: 6.066 D_real: 0.471 D_fake: 0.218 
(epoch: 165, iters: 62, time: 2.400, data: 0.008) G_GAN: 0.994 G_L1: 6.944 D_real: 0.525 D_fake: 0.389 
(epoch: 165, iters: 112, time: 0.529, data: 0.010) G_GAN: 0.896 G_L1: 11.437 D_real: 0.685 D_fake: 0.247 
(epoch: 165, iters: 162, time: 0.551, data: 0.009) G_GAN: 1.195 G_L1: 6.259 D_real: 0.498 D_fake: 0.192 
(epoch: 165, iters: 212, time: 0.575, data: 0.009) G_GAN: 1.193 G_L1: 7.681 D_real: 0.622 D_fake: 0.315 
(epoch: 165, iters: 262, time: 0.526, data: 0.009) G_GAN: 1.150 G_L1: 6.576 D_real: 0.550 D_fake: 0.238 
(epoch: 165, iters: 312, time: 0.529, data: 0.010) G_GAN: 0.965 G_L1: 6.812 D_real: 0.755 D_fake: 0.252 
(epoch: 165, iters: 362, time: 0.567, data: 0.011) G_GAN: 1.159 G_L1: 7.648 D_real: 0.587 D_fake: 0.201 
(epoch: 165, iters: 412, time: 0.590, data: 0.009) G_GAN: 1.168 G_L1: 6.959 D_real: 0.810 D_fake: 0.214 
(epoch: 165, iters: 462, time: 0.585, data: 0.009) G_GAN: 0.888 G_L1: 8.367 D_real: 0.439 D_fake: 0.288 
(epoch: 165, iters: 512, time: 0.574, data: 0.009) G_GAN: 1.110 G_L1: 8.644 D_real: 0.556 D_fake: 0.275 
(epoch: 165, iters: 562, time: 0.559, data: 0.009) G_GAN: 0.992 G_L1: 6.884 D_real: 0.531 D_fake: 0.216 
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
(epoch: 165, iters: 612, time: 0.565, data: 0.009) G_GAN: 0.862 G_L1: 11.772 D_real: 0.670 D_fake: 0.281 
(epoch: 165, iters: 662, time: 0.552, data: 0.008) G_GAN: 0.888 G_L1: 8.436 D_real: 0.576 D_fake: 0.309 
(epoch: 165, iters: 712, time: 0.566, data: 0.010) G_GAN: 1.032 G_L1: 6.740 D_real: 0.597 D_fake: 0.274 
(epoch: 165, iters: 762, time: 0.576, data: 0.009) G_GAN: 1.088 G_L1: 7.589 D_real: 0.478 D_fake: 0.190 
(epoch: 165, iters: 812, time: 0.569, data: 0.009) G_GAN: 1.036 G_L1: 5.794 D_real: 0.572 D_fake: 0.196 
(epoch: 165, iters: 862, time: 2.803, data: 0.011) G_GAN: 1.003 G_L1: 7.048 D_real: 0.468 D_fake: 0.155 
learning rate 0.0000057 -&gt; 0.0000055
saving the model at the end of epoch 165, iters 13005
End of epoch 165 / 190   Time Taken: 341 sec
(epoch: 166, iters: 45, time: 0.535, data: 0.011) G_GAN: 1.040 G_L1: 6.533 D_real: 0.576 D_fake: 0.204 
(epoch: 166, iters: 95, time: 0.559, data: 0.009) G_GAN: 1.114 G_L1: 6.743 D_real: 0.396 D_fake: 0.145 
(epoch: 166, iters: 145, time: 0.554, data: 0.009) G_GAN: 1.228 G_L1: 6.593 D_real: 0.466 D_fake: 0.186 
(epoch: 166, iters: 195, time: 2.747, data: 0.010) G_GAN: 0.959 G_L1: 10.678 D_real: 0.515 D_fake: 0.262 
(epoch: 166, iters: 245, time: 0.530, data: 0.009) G_GAN: 1.203 G_L1: 8.029 D_real: 0.471 D_fake: 0.167 
(epoch: 166, iters: 295, time: 0.536, data: 0.009) G_GAN: 0.956 G_L1: 7.880 D_real: 0.469 D_fake: 0.201 
(epoch: 166, iters: 345, time: 0.579, data: 0.011) G_GAN: 0.870 G_L1: 8.443 D_real: 0.539 D_fake: 0.287 
(epoch: 166, iters: 395, time: 0.553, data: 0.009) G_GAN: 1.326 G_L1: 7.630 D_real: 0.501 D_fake: 0.230 
(epoch: 166, iters: 445, time: 0.567, data: 0.009) G_GAN: 1.220 G_L1: 8.865 D_real: 0.453 D_fake: 0.182 
(epoch: 166, iters: 495, time: 0.581, data: 0.012) G_GAN: 0.915 G_L1: 6.223 D_real: 0.528 D_fake: 0.281 
(epoch: 166, iters: 545, time: 0.584, data: 0.009) G_GAN: 1.127 G_L1: 7.557 D_real: 0.412 D_fake: 0.139 
(epoch: 166, iters: 595, time: 0.583, data: 0.009) G_GAN: 1.221 G_L1: 7.303 D_real: 0.475 D_fake: 0.242 
(epoch: 166, iters: 645, time: 0.575, data: 0.008) G_GAN: 0.966 G_L1: 7.908 D_real: 0.589 D_fake: 0.221 
(epoch: 166, iters: 695, time: 0.571, data: 0.009) G_GAN: 1.165 G_L1: 8.169 D_real: 0.479 D_fake: 0.213 
(epoch: 166, iters: 745, time: 0.530, data: 0.011) G_GAN: 1.304 G_L1: 8.198 D_real: 0.400 D_fake: 0.163 
(epoch: 166, iters: 795, time: 0.574, data: 0.009) G_GAN: 1.105 G_L1: 8.915 D_real: 0.498 D_fake: 0.237 
(epoch: 166, iters: 845, time: 0.564, data: 0.010) G_GAN: 0.958 G_L1: 6.099 D_real: 0.642 D_fake: 0.130 
learning rate 0.0000055 -&gt; 0.0000053
End of epoch 166 / 190   Time Taken: 337 sec
(epoch: 167, iters: 28, time: 0.553, data: 0.010) G_GAN: 0.999 G_L1: 10.007 D_real: 0.443 D_fake: 0.180 
(epoch: 167, iters: 78, time: 0.548, data: 0.009) G_GAN: 1.056 G_L1: 7.137 D_real: 0.550 D_fake: 0.168 
(epoch: 167, iters: 128, time: 2.813, data: 0.009) G_GAN: 1.021 G_L1: 7.326 D_real: 0.558 D_fake: 0.181 
(epoch: 167, iters: 178, time: 0.528, data: 0.009) G_GAN: 1.105 G_L1: 7.686 D_real: 0.388 D_fake: 0.149 
(epoch: 167, iters: 228, time: 0.529, data: 0.010) G_GAN: 0.724 G_L1: 6.767 D_real: 0.728 D_fake: 0.259 
(epoch: 167, iters: 278, time: 0.535, data: 0.009) G_GAN: 0.877 G_L1: 8.384 D_real: 0.567 D_fake: 0.208 
(epoch: 167, iters: 328, time: 0.534, data: 0.009) G_GAN: 1.088 G_L1: 8.380 D_real: 0.485 D_fake: 0.295 
(epoch: 167, iters: 378, time: 0.535, data: 0.009) G_GAN: 0.913 G_L1: 6.242 D_real: 0.452 D_fake: 0.175 
(epoch: 167, iters: 428, time: 0.531, data: 0.009) G_GAN: 0.891 G_L1: 7.909 D_real: 0.633 D_fake: 0.193 
(epoch: 167, iters: 478, time: 0.564, data: 0.010) G_GAN: 1.020 G_L1: 6.375 D_real: 0.449 D_fake: 0.211 
(epoch: 167, iters: 528, time: 0.527, data: 0.009) G_GAN: 1.305 G_L1: 7.809 D_real: 0.463 D_fake: 0.210 
(epoch: 167, iters: 578, time: 0.596, data: 0.010) G_GAN: 1.035 G_L1: 7.652 D_real: 0.449 D_fake: 0.188 
(epoch: 167, iters: 628, time: 0.555, data: 0.009) G_GAN: 0.693 G_L1: 9.125 D_real: 0.457 D_fake: 0.303 
(epoch: 167, iters: 678, time: 0.563, data: 0.011) G_GAN: 1.083 G_L1: 7.297 D_real: 0.373 D_fake: 0.144 
(epoch: 167, iters: 728, time: 0.582, data: 0.010) G_GAN: 1.111 G_L1: 7.136 D_real: 0.384 D_fake: 0.189 
(epoch: 167, iters: 778, time: 0.534, data: 0.010) G_GAN: 0.946 G_L1: 7.076 D_real: 0.373 D_fake: 0.160 
(epoch: 167, iters: 828, time: 0.572, data: 0.009) G_GAN: 0.966 G_L1: 7.332 D_real: 0.462 D_fake: 0.171 
learning rate 0.0000053 -&gt; 0.0000051
End of epoch 167 / 190   Time Taken: 332 sec
(epoch: 168, iters: 11, time: 0.563, data: 0.010) G_GAN: 1.144 G_L1: 9.459 D_real: 0.527 D_fake: 0.167 
(epoch: 168, iters: 61, time: 2.617, data: 0.009) G_GAN: 1.142 G_L1: 7.250 D_real: 0.473 D_fake: 0.161 
(epoch: 168, iters: 111, time: 0.552, data: 0.009) G_GAN: 1.013 G_L1: 9.364 D_real: 0.357 D_fake: 0.125 
(epoch: 168, iters: 161, time: 0.552, data: 0.012) G_GAN: 1.143 G_L1: 12.819 D_real: 0.498 D_fake: 0.201 
(epoch: 168, iters: 211, time: 0.557, data: 0.009) G_GAN: 0.842 G_L1: 7.205 D_real: 0.407 D_fake: 0.215 
(epoch: 168, iters: 261, time: 2.802, data: 0.010) G_GAN: 0.960 G_L1: 9.461 D_real: 0.517 D_fake: 0.197 
saving the latest model (epoch 168, total_iters 15000)
(epoch: 168, iters: 311, time: 0.565, data: 0.009) G_GAN: 1.292 G_L1: 8.760 D_real: 0.536 D_fake: 0.234 
(epoch: 168, iters: 361, time: 0.575, data: 0.009) G_GAN: 1.043 G_L1: 7.906 D_real: 0.660 D_fake: 0.164 
(epoch: 168, iters: 411, time: 0.555, data: 0.010) G_GAN: 1.538 G_L1: 6.955 D_real: 0.529 D_fake: 0.187 
(epoch: 168, iters: 461, time: 0.555, data: 0.009) G_GAN: 0.846 G_L1: 10.140 D_real: 0.486 D_fake: 0.214 
(epoch: 168, iters: 511, time: 0.561, data: 0.009) G_GAN: 1.334 G_L1: 7.143 D_real: 0.429 D_fake: 0.131 
(epoch: 168, iters: 561, time: 0.571, data: 0.010) G_GAN: 0.975 G_L1: 7.304 D_real: 0.394 D_fake: 0.178 
(epoch: 168, iters: 611, time: 0.574, data: 0.010) G_GAN: 0.715 G_L1: 11.846 D_real: 0.458 D_fake: 0.308 
(epoch: 168, iters: 661, time: 0.552, data: 0.009) G_GAN: 0.887 G_L1: 6.850 D_real: 0.359 D_fake: 0.142 
(epoch: 168, iters: 711, time: 0.571, data: 0.010) G_GAN: 0.669 G_L1: 9.745 D_real: 0.405 D_fake: 0.297 
(epoch: 168, iters: 761, time: 0.572, data: 0.009) G_GAN: 0.880 G_L1: 8.932 D_real: 0.610 D_fake: 0.239 
(epoch: 168, iters: 811, time: 0.567, data: 0.009) G_GAN: 1.115 G_L1: 5.935 D_real: 0.430 D_fake: 0.126 
(epoch: 168, iters: 861, time: 0.569, data: 0.010) G_GAN: 0.882 G_L1: 6.437 D_real: 0.420 D_fake: 0.139 
learning rate 0.0000051 -&gt; 0.0000048
End of epoch 168 / 190   Time Taken: 348 sec
(epoch: 169, iters: 44, time: 0.548, data: 0.009) G_GAN: 0.952 G_L1: 6.094 D_real: 0.394 D_fake: 0.129 
(epoch: 169, iters: 94, time: 0.558, data: 0.009) G_GAN: 0.996 G_L1: 5.812 D_real: 0.522 D_fake: 0.203 
(epoch: 169, iters: 144, time: 0.576, data: 0.009) G_GAN: 0.916 G_L1: 5.874 D_real: 0.642 D_fake: 0.151 
(epoch: 169, iters: 194, time: 2.735, data: 0.009) G_GAN: 1.301 G_L1: 5.782 D_real: 0.430 D_fake: 0.152 
(epoch: 169, iters: 244, time: 0.524, data: 0.010) G_GAN: 0.879 G_L1: 10.268 D_real: 0.399 D_fake: 0.195 
(epoch: 169, iters: 294, time: 0.533, data: 0.008) G_GAN: 1.154 G_L1: 8.359 D_real: 0.402 D_fake: 0.116 
(epoch: 169, iters: 344, time: 0.532, data: 0.008) G_GAN: 0.933 G_L1: 8.830 D_real: 0.522 D_fake: 0.155 
(epoch: 169, iters: 394, time: 2.822, data: 0.009) G_GAN: 1.132 G_L1: 7.295 D_real: 0.363 D_fake: 0.131 
(epoch: 169, iters: 444, time: 0.578, data: 0.010) G_GAN: 1.270 G_L1: 6.415 D_real: 0.379 D_fake: 0.147 
(epoch: 169, iters: 494, time: 0.576, data: 0.010) G_GAN: 0.838 G_L1: 8.025 D_real: 0.659 D_fake: 0.187 
(epoch: 169, iters: 544, time: 0.560, data: 0.010) G_GAN: 0.996 G_L1: 6.992 D_real: 0.454 D_fake: 0.177 
(epoch: 169, iters: 594, time: 0.566, data: 0.009) G_GAN: 0.917 G_L1: 7.699 D_real: 0.464 D_fake: 0.144 
(epoch: 169, iters: 644, time: 0.535, data: 0.010) G_GAN: 1.164 G_L1: 6.992 D_real: 0.517 D_fake: 0.169 
(epoch: 169, iters: 694, time: 0.537, data: 0.009) G_GAN: 1.677 G_L1: 5.978 D_real: 0.518 D_fake: 0.339 
(epoch: 169, iters: 744, time: 0.718, data: 0.301) G_GAN: 1.026 G_L1: 8.541 D_real: 0.444 D_fake: 0.254 
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
(epoch: 169, iters: 794, time: 0.726, data: 0.081) G_GAN: 0.935 G_L1: 8.838 D_real: 0.482 D_fake: 0.183 
(epoch: 169, iters: 844, time: 0.663, data: 0.078) G_GAN: 0.831 G_L1: 7.384 D_real: 0.410 D_fake: 0.168 
learning rate 0.0000048 -&gt; 0.0000046
End of epoch 169 / 190   Time Taken: 424 sec
(epoch: 170, iters: 27, time: 0.521, data: 0.080) G_GAN: 0.806 G_L1: 6.183 D_real: 0.448 D_fake: 0.134 
(epoch: 170, iters: 77, time: 0.560, data: 0.009) G_GAN: 0.974 G_L1: 5.983 D_real: 0.428 D_fake: 0.125 
(epoch: 170, iters: 127, time: 2.674, data: 0.009) G_GAN: 0.982 G_L1: 9.324 D_real: 0.350 D_fake: 0.127 
(epoch: 170, iters: 177, time: 0.566, data: 0.009) G_GAN: 1.120 G_L1: 8.156 D_real: 0.370 D_fake: 0.119 
(epoch: 170, iters: 227, time: 0.570, data: 0.009) G_GAN: 0.976 G_L1: 8.947 D_real: 0.358 D_fake: 0.117 
(epoch: 170, iters: 277, time: 0.529, data: 0.009) G_GAN: 0.859 G_L1: 8.677 D_real: 0.458 D_fake: 0.233 
(epoch: 170, iters: 327, time: 0.533, data: 0.008) G_GAN: 1.066 G_L1: 6.003 D_real: 0.428 D_fake: 0.158 
(epoch: 170, iters: 377, time: 0.562, data: 0.009) G_GAN: 0.659 G_L1: 6.780 D_real: 0.372 D_fake: 0.260 
(epoch: 170, iters: 427, time: 0.535, data: 0.011) G_GAN: 0.749 G_L1: 6.537 D_real: 0.487 D_fake: 0.365 
(epoch: 170, iters: 477, time: 0.552, data: 0.009) G_GAN: 1.088 G_L1: 6.352 D_real: 0.368 D_fake: 0.107 
(epoch: 170, iters: 527, time: 2.696, data: 0.010) G_GAN: 0.704 G_L1: 7.295 D_real: 0.393 D_fake: 0.272 
(epoch: 170, iters: 577, time: 0.572, data: 0.010) G_GAN: 0.837 G_L1: 8.661 D_real: 0.348 D_fake: 0.188 
(epoch: 170, iters: 627, time: 0.572, data: 0.009) G_GAN: 0.999 G_L1: 8.736 D_real: 0.353 D_fake: 0.135 
(epoch: 170, iters: 677, time: 0.585, data: 0.010) G_GAN: 0.950 G_L1: 12.069 D_real: 0.538 D_fake: 0.203 
(epoch: 170, iters: 727, time: 0.580, data: 0.009) G_GAN: 1.089 G_L1: 6.320 D_real: 0.489 D_fake: 0.128 
(epoch: 170, iters: 777, time: 0.565, data: 0.011) G_GAN: 1.007 G_L1: 6.833 D_real: 0.409 D_fake: 0.130 
(epoch: 170, iters: 827, time: 0.567, data: 0.009) G_GAN: 0.890 G_L1: 9.052 D_real: 0.386 D_fake: 0.221 
learning rate 0.0000046 -&gt; 0.0000044
saving the model at the end of epoch 170, iters 17340
End of epoch 170 / 190   Time Taken: 340 sec
(epoch: 171, iters: 10, time: 0.549, data: 0.010) G_GAN: 1.117 G_L1: 7.496 D_real: 0.339 D_fake: 0.121 
(epoch: 171, iters: 60, time: 2.734, data: 0.009) G_GAN: 1.109 G_L1: 6.125 D_real: 0.367 D_fake: 0.112 
(epoch: 171, iters: 110, time: 0.528, data: 0.010) G_GAN: 0.926 G_L1: 6.014 D_real: 0.353 D_fake: 0.153 
(epoch: 171, iters: 160, time: 0.531, data: 0.009) G_GAN: 0.850 G_L1: 7.799 D_real: 0.429 D_fake: 0.128 
(epoch: 171, iters: 210, time: 0.533, data: 0.008) G_GAN: 1.007 G_L1: 6.652 D_real: 0.510 D_fake: 0.161 
(epoch: 171, iters: 260, time: 0.534, data: 0.009) G_GAN: 1.059 G_L1: 6.349 D_real: 0.360 D_fake: 0.133 
(epoch: 171, iters: 310, time: 0.533, data: 0.009) G_GAN: 1.030 G_L1: 6.941 D_real: 0.356 D_fake: 0.161 
(epoch: 171, iters: 360, time: 0.549, data: 0.009) G_GAN: 1.111 G_L1: 9.091 D_real: 0.475 D_fake: 0.154 
(epoch: 171, iters: 410, time: 0.564, data: 0.010) G_GAN: 1.081 G_L1: 8.241 D_real: 0.415 D_fake: 0.158 
(epoch: 171, iters: 460, time: 0.559, data: 0.007) G_GAN: 0.901 G_L1: 6.095 D_real: 0.376 D_fake: 0.150 
(epoch: 171, iters: 510, time: 0.602, data: 0.010) G_GAN: 0.982 G_L1: 6.761 D_real: 0.375 D_fake: 0.126 
(epoch: 171, iters: 560, time: 0.610, data: 0.010) G_GAN: 1.069 G_L1: 6.123 D_real: 0.420 D_fake: 0.181 
(epoch: 171, iters: 610, time: 0.615, data: 0.012) G_GAN: 1.083 G_L1: 6.582 D_real: 0.388 D_fake: 0.109 
(epoch: 171, iters: 660, time: 3.073, data: 0.009) G_GAN: 0.937 G_L1: 7.789 D_real: 0.396 D_fake: 0.151 
(epoch: 171, iters: 710, time: 0.599, data: 0.009) G_GAN: 0.987 G_L1: 7.262 D_real: 0.359 D_fake: 0.160 
(epoch: 171, iters: 760, time: 0.585, data: 0.009) G_GAN: 1.029 G_L1: 7.007 D_real: 0.327 D_fake: 0.153 
(epoch: 171, iters: 810, time: 0.606, data: 0.008) G_GAN: 0.895 G_L1: 8.174 D_real: 0.408 D_fake: 0.230 
(epoch: 171, iters: 860, time: 0.608, data: 0.010) G_GAN: 1.036 G_L1: 7.918 D_real: 0.371 D_fake: 0.130 
learning rate 0.0000044 -&gt; 0.0000042
End of epoch 171 / 190   Time Taken: 348 sec
(epoch: 172, iters: 43, time: 0.582, data: 0.009) G_GAN: 0.815 G_L1: 6.514 D_real: 0.393 D_fake: 0.213 
(epoch: 172, iters: 93, time: 0.590, data: 0.009) G_GAN: 1.156 G_L1: 7.182 D_real: 0.455 D_fake: 0.145 
(epoch: 172, iters: 143, time: 0.586, data: 0.009) G_GAN: 0.986 G_L1: 6.426 D_real: 0.533 D_fake: 0.150 
(epoch: 172, iters: 193, time: 2.807, data: 0.009) G_GAN: 1.150 G_L1: 5.342 D_real: 0.402 D_fake: 0.108 
(epoch: 172, iters: 243, time: 0.605, data: 0.012) G_GAN: 0.916 G_L1: 9.512 D_real: 0.365 D_fake: 0.153 
(epoch: 172, iters: 293, time: 0.612, data: 0.011) G_GAN: 0.763 G_L1: 9.637 D_real: 0.454 D_fake: 0.222 
(epoch: 172, iters: 343, time: 0.600, data: 0.018) G_GAN: 1.135 G_L1: 6.711 D_real: 0.336 D_fake: 0.115 
(epoch: 172, iters: 393, time: 0.596, data: 0.009) G_GAN: 1.079 G_L1: 7.521 D_real: 0.338 D_fake: 0.114 
(epoch: 172, iters: 443, time: 0.614, data: 0.012) G_GAN: 0.879 G_L1: 6.956 D_real: 0.415 D_fake: 0.178 
(epoch: 172, iters: 493, time: 0.641, data: 0.013) G_GAN: 0.818 G_L1: 9.526 D_real: 0.415 D_fake: 0.196 
(epoch: 172, iters: 543, time: 0.590, data: 0.010) G_GAN: 1.008 G_L1: 8.533 D_real: 0.390 D_fake: 0.135 
(epoch: 172, iters: 593, time: 0.569, data: 0.011) G_GAN: 1.038 G_L1: 6.186 D_real: 0.350 D_fake: 0.123 
(epoch: 172, iters: 643, time: 0.578, data: 0.009) G_GAN: 0.938 G_L1: 6.614 D_real: 0.412 D_fake: 0.124 
(epoch: 172, iters: 693, time: 0.604, data: 0.008) G_GAN: 1.111 G_L1: 6.252 D_real: 0.344 D_fake: 0.132 
(epoch: 172, iters: 743, time: 0.588, data: 0.009) G_GAN: 0.847 G_L1: 6.633 D_real: 0.347 D_fake: 0.179 
(epoch: 172, iters: 793, time: 2.790, data: 0.009) G_GAN: 0.982 G_L1: 6.501 D_real: 0.428 D_fake: 0.157 
(epoch: 172, iters: 843, time: 0.597, data: 0.010) G_GAN: 1.080 G_L1: 8.825 D_real: 0.379 D_fake: 0.168 
learning rate 0.0000042 -&gt; 0.0000040
End of epoch 172 / 190   Time Taken: 375 sec
(epoch: 173, iters: 26, time: 0.603, data: 0.012) G_GAN: 1.000 G_L1: 6.342 D_real: 0.335 D_fake: 0.152 
(epoch: 173, iters: 76, time: 0.600, data: 0.010) G_GAN: 1.062 G_L1: 8.588 D_real: 0.494 D_fake: 0.150 
(epoch: 173, iters: 126, time: 2.937, data: 0.012) G_GAN: 1.128 G_L1: 6.134 D_real: 0.333 D_fake: 0.113 
(epoch: 173, iters: 176, time: 0.588, data: 0.010) G_GAN: 1.245 G_L1: 6.259 D_real: 0.395 D_fake: 0.168 
(epoch: 173, iters: 226, time: 0.601, data: 0.009) G_GAN: 1.163 G_L1: 6.305 D_real: 0.426 D_fake: 0.134 
(epoch: 173, iters: 276, time: 0.600, data: 0.009) G_GAN: 1.016 G_L1: 6.476 D_real: 0.395 D_fake: 0.129 
(epoch: 173, iters: 326, time: 0.604, data: 0.010) G_GAN: 1.032 G_L1: 7.436 D_real: 0.362 D_fake: 0.169 
(epoch: 173, iters: 376, time: 0.596, data: 0.011) G_GAN: 1.025 G_L1: 5.824 D_real: 0.334 D_fake: 0.126 
(epoch: 173, iters: 426, time: 0.605, data: 0.010) G_GAN: 1.285 G_L1: 6.661 D_real: 0.421 D_fake: 0.227 
(epoch: 173, iters: 476, time: 0.598, data: 0.010) G_GAN: 1.080 G_L1: 6.387 D_real: 0.404 D_fake: 0.125 
(epoch: 173, iters: 526, time: 0.608, data: 0.010) G_GAN: 1.041 G_L1: 7.476 D_real: 0.363 D_fake: 0.177 
(epoch: 173, iters: 576, time: 0.608, data: 0.009) G_GAN: 0.808 G_L1: 7.556 D_real: 0.544 D_fake: 0.253 
(epoch: 173, iters: 626, time: 0.544, data: 0.010) G_GAN: 0.887 G_L1: 9.752 D_real: 0.357 D_fake: 0.178 
(epoch: 173, iters: 676, time: 0.590, data: 0.009) G_GAN: 0.964 G_L1: 6.912 D_real: 0.412 D_fake: 0.111 
(epoch: 173, iters: 726, time: 0.601, data: 0.009) G_GAN: 0.911 G_L1: 8.152 D_real: 0.306 D_fake: 0.131 
(epoch: 173, iters: 776, time: 0.606, data: 0.010) G_GAN: 1.019 G_L1: 7.013 D_real: 0.317 D_fake: 0.170 
(epoch: 173, iters: 826, time: 0.631, data: 0.010) G_GAN: 1.078 G_L1: 8.859 D_real: 0.339 D_fake: 0.124 
learning rate 0.0000040 -&gt; 0.0000037
End of epoch 173 / 190   Time Taken: 374 sec
(epoch: 174, iters: 9, time: 0.601, data: 0.009) G_GAN: 0.962 G_L1: 5.736 D_real: 0.339 D_fake: 0.114 
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
(epoch: 174, iters: 59, time: 2.963, data: 0.009) G_GAN: 0.841 G_L1: 6.437 D_real: 0.374 D_fake: 0.228 
saving the latest model (epoch 174, total_iters 20000)
(epoch: 174, iters: 109, time: 0.586, data: 0.010) G_GAN: 0.685 G_L1: 9.133 D_real: 0.332 D_fake: 0.177 
(epoch: 174, iters: 159, time: 0.625, data: 0.010) G_GAN: 1.237 G_L1: 5.743 D_real: 0.333 D_fake: 0.145 
(epoch: 174, iters: 209, time: 0.604, data: 0.010) G_GAN: 0.971 G_L1: 7.449 D_real: 0.379 D_fake: 0.131 
(epoch: 174, iters: 259, time: 0.597, data: 0.010) G_GAN: 1.019 G_L1: 6.558 D_real: 0.389 D_fake: 0.123 
(epoch: 174, iters: 309, time: 0.597, data: 0.012) G_GAN: 0.869 G_L1: 10.688 D_real: 0.392 D_fake: 0.185 
(epoch: 174, iters: 359, time: 0.607, data: 0.010) G_GAN: 0.991 G_L1: 6.106 D_real: 0.403 D_fake: 0.117 
(epoch: 174, iters: 409, time: 0.617, data: 0.009) G_GAN: 0.992 G_L1: 8.386 D_real: 0.440 D_fake: 0.228 
(epoch: 174, iters: 459, time: 0.592, data: 0.008) G_GAN: 1.020 G_L1: 7.255 D_real: 0.451 D_fake: 0.203 
(epoch: 174, iters: 509, time: 0.615, data: 0.010) G_GAN: 1.023 G_L1: 8.537 D_real: 0.352 D_fake: 0.121 
(epoch: 174, iters: 559, time: 0.604, data: 0.036) G_GAN: 1.059 G_L1: 7.228 D_real: 0.361 D_fake: 0.103 
(epoch: 174, iters: 609, time: 0.630, data: 0.010) G_GAN: 1.030 G_L1: 6.108 D_real: 0.353 D_fake: 0.142 
(epoch: 174, iters: 659, time: 0.588, data: 0.009) G_GAN: 1.053 G_L1: 6.658 D_real: 0.305 D_fake: 0.094 
(epoch: 174, iters: 709, time: 0.592, data: 0.009) G_GAN: 0.913 G_L1: 9.542 D_real: 0.323 D_fake: 0.169 
(epoch: 174, iters: 759, time: 0.598, data: 0.010) G_GAN: 1.237 G_L1: 11.636 D_real: 0.352 D_fake: 0.145 
(epoch: 174, iters: 809, time: 0.592, data: 0.010) G_GAN: 0.938 G_L1: 6.879 D_real: 0.337 D_fake: 0.103 
(epoch: 174, iters: 859, time: 0.657, data: 0.010) G_GAN: 0.977 G_L1: 6.237 D_real: 0.508 D_fake: 0.115 
learning rate 0.0000037 -&gt; 0.0000035
End of epoch 174 / 190   Time Taken: 381 sec
(epoch: 175, iters: 42, time: 0.556, data: 0.009) G_GAN: 0.928 G_L1: 6.739 D_real: 0.283 D_fake: 0.126 
(epoch: 175, iters: 92, time: 0.773, data: 0.085) G_GAN: 1.013 G_L1: 6.922 D_real: 0.348 D_fake: 0.125 
(epoch: 175, iters: 142, time: 1.697, data: 0.052) G_GAN: 0.963 G_L1: 6.659 D_real: 0.288 D_fake: 0.124 
(epoch: 175, iters: 192, time: 2.758, data: 0.154) G_GAN: 0.929 G_L1: 9.011 D_real: 0.333 D_fake: 0.132 
(epoch: 175, iters: 242, time: 0.567, data: 0.010) G_GAN: 0.914 G_L1: 7.371 D_real: 0.310 D_fake: 0.097 
(epoch: 175, iters: 292, time: 0.556, data: 0.009) G_GAN: 1.087 G_L1: 6.599 D_real: 0.315 D_fake: 0.104 
(epoch: 175, iters: 342, time: 0.584, data: 0.011) G_GAN: 0.713 G_L1: 6.313 D_real: 0.434 D_fake: 0.154 
(epoch: 175, iters: 392, time: 0.591, data: 0.010) G_GAN: 0.830 G_L1: 8.678 D_real: 0.282 D_fake: 0.140 
(epoch: 175, iters: 442, time: 0.580, data: 0.009) G_GAN: 0.914 G_L1: 6.266 D_real: 0.380 D_fake: 0.142 
(epoch: 175, iters: 492, time: 0.599, data: 0.009) G_GAN: 1.010 G_L1: 11.466 D_real: 0.422 D_fake: 0.133 
(epoch: 175, iters: 542, time: 0.594, data: 0.009) G_GAN: 0.898 G_L1: 6.968 D_real: 0.398 D_fake: 0.155 
(epoch: 175, iters: 592, time: 0.614, data: 0.025) G_GAN: 0.999 G_L1: 6.862 D_real: 0.304 D_fake: 0.165 
(epoch: 175, iters: 642, time: 0.620, data: 0.010) G_GAN: 0.824 G_L1: 6.316 D_real: 0.283 D_fake: 0.128 
(epoch: 175, iters: 692, time: 0.598, data: 0.009) G_GAN: 1.031 G_L1: 6.358 D_real: 0.335 D_fake: 0.119 
(epoch: 175, iters: 742, time: 0.598, data: 0.011) G_GAN: 0.969 G_L1: 5.982 D_real: 0.321 D_fake: 0.126 
(epoch: 175, iters: 792, time: 0.600, data: 0.010) G_GAN: 0.689 G_L1: 7.430 D_real: 0.350 D_fake: 0.291 
(epoch: 175, iters: 842, time: 0.599, data: 0.011) G_GAN: 1.153 G_L1: 6.006 D_real: 0.306 D_fake: 0.095 
learning rate 0.0000035 -&gt; 0.0000033
saving the model at the end of epoch 175, iters 21675
End of epoch 175 / 190   Time Taken: 475 sec
(epoch: 176, iters: 25, time: 0.597, data: 0.010) G_GAN: 0.996 G_L1: 6.327 D_real: 0.354 D_fake: 0.098 
(epoch: 176, iters: 75, time: 0.629, data: 0.009) G_GAN: 0.945 G_L1: 7.132 D_real: 0.450 D_fake: 0.164 
(epoch: 176, iters: 125, time: 2.970, data: 0.010) G_GAN: 0.918 G_L1: 8.890 D_real: 0.428 D_fake: 0.162 
(epoch: 176, iters: 175, time: 0.581, data: 0.011) G_GAN: 0.824 G_L1: 6.729 D_real: 0.330 D_fake: 0.154 
(epoch: 176, iters: 225, time: 0.577, data: 0.010) G_GAN: 1.255 G_L1: 6.151 D_real: 0.274 D_fake: 0.129 
(epoch: 176, iters: 275, time: 0.586, data: 0.010) G_GAN: 0.882 G_L1: 5.523 D_real: 0.346 D_fake: 0.159 
(epoch: 176, iters: 325, time: 2.744, data: 0.009) G_GAN: 0.586 G_L1: 6.212 D_real: 0.310 D_fake: 0.337 
(epoch: 176, iters: 375, time: 0.601, data: 0.009) G_GAN: 0.909 G_L1: 9.624 D_real: 0.258 D_fake: 0.111 
(epoch: 176, iters: 425, time: 0.595, data: 0.010) G_GAN: 1.002 G_L1: 7.358 D_real: 0.377 D_fake: 0.150 
(epoch: 176, iters: 475, time: 0.624, data: 0.010) G_GAN: 1.043 G_L1: 5.842 D_real: 0.281 D_fake: 0.104 
(epoch: 176, iters: 525, time: 0.536, data: 0.010) G_GAN: 1.106 G_L1: 7.068 D_real: 0.297 D_fake: 0.087 
(epoch: 176, iters: 575, time: 0.572, data: 0.009) G_GAN: 1.077 G_L1: 7.904 D_real: 0.284 D_fake: 0.119 
(epoch: 176, iters: 625, time: 0.583, data: 0.018) G_GAN: 1.047 G_L1: 7.120 D_real: 0.293 D_fake: 0.125 
(epoch: 176, iters: 675, time: 0.578, data: 0.009) G_GAN: 0.979 G_L1: 7.892 D_real: 0.302 D_fake: 0.111 
(epoch: 176, iters: 725, time: 0.565, data: 0.010) G_GAN: 0.983 G_L1: 8.776 D_real: 0.409 D_fake: 0.139 
(epoch: 176, iters: 775, time: 0.535, data: 0.009) G_GAN: 0.818 G_L1: 7.242 D_real: 0.317 D_fake: 0.160 
(epoch: 176, iters: 825, time: 0.584, data: 0.009) G_GAN: 0.955 G_L1: 6.564 D_real: 0.283 D_fake: 0.122 
learning rate 0.0000033 -&gt; 0.0000031
End of epoch 176 / 190   Time Taken: 366 sec
(epoch: 177, iters: 8, time: 0.572, data: 0.009) G_GAN: 0.955 G_L1: 6.080 D_real: 0.338 D_fake: 0.118 
(epoch: 177, iters: 58, time: 2.960, data: 0.010) G_GAN: 0.905 G_L1: 6.822 D_real: 0.322 D_fake: 0.125 
(epoch: 177, iters: 108, time: 0.573, data: 0.009) G_GAN: 1.118 G_L1: 6.157 D_real: 0.319 D_fake: 0.106 
(epoch: 177, iters: 158, time: 0.558, data: 0.010) G_GAN: 0.963 G_L1: 6.696 D_real: 0.290 D_fake: 0.112 
(epoch: 177, iters: 208, time: 0.561, data: 0.010) G_GAN: 0.955 G_L1: 5.542 D_real: 0.325 D_fake: 0.114 
(epoch: 177, iters: 258, time: 0.572, data: 0.010) G_GAN: 0.837 G_L1: 6.514 D_real: 0.349 D_fake: 0.170 
(epoch: 177, iters: 308, time: 0.559, data: 0.009) G_GAN: 0.921 G_L1: 8.218 D_real: 0.331 D_fake: 0.131 
(epoch: 177, iters: 358, time: 0.566, data: 0.010) G_GAN: 0.924 G_L1: 5.948 D_real: 0.369 D_fake: 0.092 
(epoch: 177, iters: 408, time: 0.575, data: 0.009) G_GAN: 1.063 G_L1: 6.467 D_real: 0.274 D_fake: 0.074 
(epoch: 177, iters: 458, time: 2.794, data: 0.010) G_GAN: 0.977 G_L1: 5.882 D_real: 0.302 D_fake: 0.120 
(epoch: 177, iters: 508, time: 0.538, data: 0.008) G_GAN: 1.033 G_L1: 6.692 D_real: 0.355 D_fake: 0.142 
(epoch: 177, iters: 558, time: 0.571, data: 0.009) G_GAN: 0.988 G_L1: 5.497 D_real: 0.334 D_fake: 0.106 
(epoch: 177, iters: 608, time: 0.552, data: 0.008) G_GAN: 0.964 G_L1: 7.045 D_real: 0.313 D_fake: 0.185 
(epoch: 177, iters: 658, time: 0.565, data: 0.011) G_GAN: 1.111 G_L1: 6.602 D_real: 0.266 D_fake: 0.095 
(epoch: 177, iters: 708, time: 0.559, data: 0.009) G_GAN: 0.973 G_L1: 5.429 D_real: 0.288 D_fake: 0.075 
(epoch: 177, iters: 758, time: 0.571, data: 0.009) G_GAN: 0.875 G_L1: 8.003 D_real: 0.326 D_fake: 0.175 
(epoch: 177, iters: 808, time: 0.573, data: 0.010) G_GAN: 0.936 G_L1: 10.137 D_real: 0.429 D_fake: 0.128 
(epoch: 177, iters: 858, time: 0.568, data: 0.008) G_GAN: 0.836 G_L1: 7.673 D_real: 0.265 D_fake: 0.103 
learning rate 0.0000031 -&gt; 0.0000029
End of epoch 177 / 190   Time Taken: 353 sec
(epoch: 178, iters: 41, time: 0.566, data: 0.009) G_GAN: 0.852 G_L1: 6.380 D_real: 0.271 D_fake: 0.106 
(epoch: 178, iters: 91, time: 0.573, data: 0.009) G_GAN: 0.895 G_L1: 7.262 D_real: 0.319 D_fake: 0.121 
(epoch: 178, iters: 141, time: 0.572, data: 0.010) G_GAN: 0.946 G_L1: 8.734 D_real: 0.295 D_fake: 0.101 
(epoch: 178, iters: 191, time: 2.719, data: 0.009) G_GAN: 0.997 G_L1: 7.515 D_real: 0.314 D_fake: 0.108 
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
(epoch: 178, iters: 241, time: 0.530, data: 0.009) G_GAN: 1.015 G_L1: 11.129 D_real: 0.315 D_fake: 0.124 
(epoch: 178, iters: 291, time: 0.530, data: 0.009) G_GAN: 0.982 G_L1: 8.965 D_real: 0.308 D_fake: 0.139 
(epoch: 178, iters: 341, time: 0.560, data: 0.011) G_GAN: 0.980 G_L1: 6.226 D_real: 0.280 D_fake: 0.083 
(epoch: 178, iters: 391, time: 0.563, data: 0.009) G_GAN: 0.824 G_L1: 5.402 D_real: 0.350 D_fake: 0.143 
(epoch: 178, iters: 441, time: 0.561, data: 0.010) G_GAN: 0.964 G_L1: 5.888 D_real: 0.308 D_fake: 0.099 
(epoch: 178, iters: 491, time: 0.584, data: 0.010) G_GAN: 0.972 G_L1: 6.004 D_real: 0.321 D_fake: 0.143 
(epoch: 178, iters: 541, time: 0.573, data: 0.008) G_GAN: 1.031 G_L1: 6.535 D_real: 0.285 D_fake: 0.076 
(epoch: 178, iters: 591, time: 2.841, data: 0.010) G_GAN: 0.953 G_L1: 5.331 D_real: 0.251 D_fake: 0.088 
(epoch: 178, iters: 641, time: 0.586, data: 0.009) G_GAN: 0.812 G_L1: 5.753 D_real: 0.334 D_fake: 0.111 
(epoch: 178, iters: 691, time: 0.560, data: 0.009) G_GAN: 1.026 G_L1: 6.176 D_real: 0.407 D_fake: 0.121 
(epoch: 178, iters: 741, time: 0.583, data: 0.009) G_GAN: 1.177 G_L1: 5.710 D_real: 0.324 D_fake: 0.129 
(epoch: 178, iters: 791, time: 0.531, data: 0.009) G_GAN: 0.930 G_L1: 6.525 D_real: 0.256 D_fake: 0.125 
(epoch: 178, iters: 841, time: 0.573, data: 0.008) G_GAN: 1.015 G_L1: 6.682 D_real: 0.353 D_fake: 0.089 
learning rate 0.0000029 -&gt; 0.0000026
End of epoch 178 / 190   Time Taken: 349 sec
(epoch: 179, iters: 24, time: 0.570, data: 0.010) G_GAN: 0.784 G_L1: 6.595 D_real: 0.328 D_fake: 0.133 
(epoch: 179, iters: 74, time: 0.567, data: 0.009) G_GAN: 0.863 G_L1: 5.912 D_real: 0.344 D_fake: 0.093 
(epoch: 179, iters: 124, time: 3.304, data: 0.009) G_GAN: 0.942 G_L1: 6.574 D_real: 0.260 D_fake: 0.076 
(epoch: 179, iters: 174, time: 0.577, data: 0.010) G_GAN: 1.104 G_L1: 6.370 D_real: 0.397 D_fake: 0.119 
(epoch: 179, iters: 224, time: 0.581, data: 0.010) G_GAN: 0.914 G_L1: 5.769 D_real: 0.308 D_fake: 0.134 
(epoch: 179, iters: 274, time: 0.565, data: 0.009) G_GAN: 0.875 G_L1: 8.431 D_real: 0.272 D_fake: 0.107 
(epoch: 179, iters: 324, time: 0.568, data: 0.009) G_GAN: 1.166 G_L1: 8.597 D_real: 0.319 D_fake: 0.120 
(epoch: 179, iters: 374, time: 0.574, data: 0.010) G_GAN: 0.939 G_L1: 6.655 D_real: 0.496 D_fake: 0.136 
(epoch: 179, iters: 424, time: 0.557, data: 0.009) G_GAN: 0.991 G_L1: 6.607 D_real: 0.429 D_fake: 0.113 
(epoch: 179, iters: 474, time: 0.575, data: 0.009) G_GAN: 0.953 G_L1: 10.350 D_real: 0.401 D_fake: 0.130 
(epoch: 179, iters: 524, time: 0.579, data: 0.010) G_GAN: 0.992 G_L1: 5.984 D_real: 0.257 D_fake: 0.079 
(epoch: 179, iters: 574, time: 0.575, data: 0.010) G_GAN: 0.972 G_L1: 9.475 D_real: 0.243 D_fake: 0.087 
(epoch: 179, iters: 624, time: 0.577, data: 0.009) G_GAN: 1.024 G_L1: 5.625 D_real: 0.290 D_fake: 0.117 
(epoch: 179, iters: 674, time: 0.583, data: 0.010) G_GAN: 0.876 G_L1: 5.167 D_real: 0.327 D_fake: 0.075 
(epoch: 179, iters: 724, time: 2.806, data: 0.011) G_GAN: 0.832 G_L1: 9.408 D_real: 0.259 D_fake: 0.113 
saving the latest model (epoch 179, total_iters 25000)
(epoch: 179, iters: 774, time: 0.605, data: 0.010) G_GAN: 1.018 G_L1: 6.285 D_real: 0.338 D_fake: 0.152 
(epoch: 179, iters: 824, time: 0.579, data: 0.010) G_GAN: 1.162 G_L1: 8.972 D_real: 0.315 D_fake: 0.149 
learning rate 0.0000026 -&gt; 0.0000024
End of epoch 179 / 190   Time Taken: 359 sec
(epoch: 180, iters: 7, time: 0.568, data: 0.009) G_GAN: 1.001 G_L1: 6.913 D_real: 0.276 D_fake: 0.071 
(epoch: 180, iters: 57, time: 2.791, data: 0.009) G_GAN: 0.866 G_L1: 5.481 D_real: 0.400 D_fake: 0.123 
(epoch: 180, iters: 107, time: 0.530, data: 0.009) G_GAN: 0.914 G_L1: 6.173 D_real: 0.235 D_fake: 0.093 
(epoch: 180, iters: 157, time: 0.536, data: 0.009) G_GAN: 0.986 G_L1: 6.838 D_real: 0.284 D_fake: 0.085 
(epoch: 180, iters: 207, time: 0.531, data: 0.010) G_GAN: 0.980 G_L1: 6.455 D_real: 0.286 D_fake: 0.075 
(epoch: 180, iters: 257, time: 0.538, data: 0.009) G_GAN: 1.182 G_L1: 8.343 D_real: 0.388 D_fake: 0.108 
(epoch: 180, iters: 307, time: 0.489, data: 0.010) G_GAN: 1.095 G_L1: 7.555 D_real: 0.281 D_fake: 0.113 
(epoch: 180, iters: 357, time: 0.715, data: 0.044) G_GAN: 0.920 G_L1: 10.862 D_real: 0.337 D_fake: 0.122 
(epoch: 180, iters: 407, time: 0.666, data: 0.078) G_GAN: 1.126 G_L1: 5.646 D_real: 0.255 D_fake: 0.079 
(epoch: 180, iters: 457, time: 0.506, data: 0.097) G_GAN: 1.100 G_L1: 10.137 D_real: 0.289 D_fake: 0.124 
(epoch: 180, iters: 507, time: 0.564, data: 0.013) G_GAN: 1.004 G_L1: 6.508 D_real: 0.255 D_fake: 0.100 
(epoch: 180, iters: 557, time: 0.580, data: 0.010) G_GAN: 0.971 G_L1: 5.970 D_real: 0.240 D_fake: 0.084 
(epoch: 180, iters: 607, time: 0.554, data: 0.010) G_GAN: 0.934 G_L1: 7.522 D_real: 0.307 D_fake: 0.176 
(epoch: 180, iters: 657, time: 0.574, data: 0.009) G_GAN: 1.068 G_L1: 7.939 D_real: 0.259 D_fake: 0.080 
(epoch: 180, iters: 707, time: 0.581, data: 0.009) G_GAN: 1.063 G_L1: 5.284 D_real: 0.282 D_fake: 0.076 
(epoch: 180, iters: 757, time: 0.553, data: 0.010) G_GAN: 0.959 G_L1: 7.894 D_real: 0.318 D_fake: 0.100 
(epoch: 180, iters: 807, time: 0.561, data: 0.012) G_GAN: 0.991 G_L1: 6.068 D_real: 0.244 D_fake: 0.101 
(epoch: 180, iters: 857, time: 2.922, data: 0.009) G_GAN: 1.012 G_L1: 5.544 D_real: 0.307 D_fake: 0.092 
learning rate 0.0000024 -&gt; 0.0000022
saving the model at the end of epoch 180, iters 26010
End of epoch 180 / 190   Time Taken: 405 sec
(epoch: 181, iters: 40, time: 0.546, data: 0.009) G_GAN: 0.993 G_L1: 6.527 D_real: 0.257 D_fake: 0.094 
(epoch: 181, iters: 90, time: 0.564, data: 0.011) G_GAN: 0.955 G_L1: 6.214 D_real: 0.337 D_fake: 0.085 
(epoch: 181, iters: 140, time: 0.572, data: 0.009) G_GAN: 0.983 G_L1: 7.747 D_real: 0.269 D_fake: 0.099 
(epoch: 181, iters: 190, time: 2.768, data: 0.009) G_GAN: 0.871 G_L1: 5.594 D_real: 0.344 D_fake: 0.110 
(epoch: 181, iters: 240, time: 0.534, data: 0.010) G_GAN: 1.014 G_L1: 8.248 D_real: 0.241 D_fake: 0.072 
(epoch: 181, iters: 290, time: 0.533, data: 0.009) G_GAN: 0.991 G_L1: 5.440 D_real: 0.396 D_fake: 0.097 
(epoch: 181, iters: 340, time: 0.531, data: 0.010) G_GAN: 0.988 G_L1: 5.531 D_real: 0.280 D_fake: 0.090 
(epoch: 181, iters: 390, time: 0.534, data: 0.009) G_GAN: 1.006 G_L1: 8.970 D_real: 0.254 D_fake: 0.086 
(epoch: 181, iters: 440, time: 0.559, data: 0.009) G_GAN: 0.825 G_L1: 6.492 D_real: 0.261 D_fake: 0.130 
(epoch: 181, iters: 490, time: 0.555, data: 0.008) G_GAN: 1.104 G_L1: 6.908 D_real: 0.307 D_fake: 0.095 
(epoch: 181, iters: 540, time: 0.575, data: 0.009) G_GAN: 1.033 G_L1: 10.488 D_real: 0.331 D_fake: 0.106 
(epoch: 181, iters: 590, time: 0.558, data: 0.012) G_GAN: 0.813 G_L1: 6.148 D_real: 0.281 D_fake: 0.119 
(epoch: 181, iters: 640, time: 0.580, data: 0.010) G_GAN: 0.875 G_L1: 7.165 D_real: 0.283 D_fake: 0.133 
(epoch: 181, iters: 690, time: 0.577, data: 0.010) G_GAN: 0.814 G_L1: 6.169 D_real: 0.268 D_fake: 0.122 
(epoch: 181, iters: 740, time: 0.603, data: 0.009) G_GAN: 0.991 G_L1: 8.134 D_real: 0.282 D_fake: 0.111 
(epoch: 181, iters: 790, time: 0.612, data: 0.010) G_GAN: 0.865 G_L1: 7.692 D_real: 0.249 D_fake: 0.110 
(epoch: 181, iters: 840, time: 0.594, data: 0.010) G_GAN: 0.978 G_L1: 6.626 D_real: 0.281 D_fake: 0.123 
learning rate 0.0000022 -&gt; 0.0000020
End of epoch 181 / 190   Time Taken: 347 sec
(epoch: 182, iters: 23, time: 0.586, data: 0.010) G_GAN: 0.900 G_L1: 9.461 D_real: 0.361 D_fake: 0.085 
(epoch: 182, iters: 73, time: 0.613, data: 0.009) G_GAN: 1.034 G_L1: 7.193 D_real: 0.351 D_fake: 0.109 
(epoch: 182, iters: 123, time: 3.082, data: 0.010) G_GAN: 0.883 G_L1: 6.563 D_real: 0.249 D_fake: 0.083 
(epoch: 182, iters: 173, time: 0.610, data: 0.011) G_GAN: 0.982 G_L1: 5.954 D_real: 0.469 D_fake: 0.080 
(epoch: 182, iters: 223, time: 0.605, data: 0.010) G_GAN: 0.882 G_L1: 7.014 D_real: 0.290 D_fake: 0.085 
(epoch: 182, iters: 273, time: 0.604, data: 0.009) G_GAN: 1.063 G_L1: 6.432 D_real: 0.299 D_fake: 0.086 
(epoch: 182, iters: 323, time: 0.615, data: 0.012) G_GAN: 0.844 G_L1: 8.852 D_real: 0.316 D_fake: 0.154 
(epoch: 182, iters: 373, time: 0.612, data: 0.009) G_GAN: 1.025 G_L1: 7.777 D_real: 0.282 D_fake: 0.082 
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
(epoch: 182, iters: 423, time: 0.590, data: 0.009) G_GAN: 0.893 G_L1: 6.138 D_real: 0.394 D_fake: 0.132 
(epoch: 182, iters: 473, time: 0.553, data: 0.009) G_GAN: 1.014 G_L1: 6.707 D_real: 0.276 D_fake: 0.114 
(epoch: 182, iters: 523, time: 0.616, data: 0.010) G_GAN: 1.019 G_L1: 6.156 D_real: 0.332 D_fake: 0.106 
(epoch: 182, iters: 573, time: 0.604, data: 0.009) G_GAN: 0.775 G_L1: 5.966 D_real: 0.306 D_fake: 0.123 
(epoch: 182, iters: 623, time: 0.603, data: 0.011) G_GAN: 0.717 G_L1: 6.767 D_real: 0.302 D_fake: 0.184 
(epoch: 182, iters: 673, time: 0.611, data: 0.009) G_GAN: 1.126 G_L1: 7.265 D_real: 0.265 D_fake: 0.093 
(epoch: 182, iters: 723, time: 0.599, data: 0.009) G_GAN: 0.952 G_L1: 9.347 D_real: 0.299 D_fake: 0.125 
(epoch: 182, iters: 773, time: 0.601, data: 0.010) G_GAN: 1.079 G_L1: 6.370 D_real: 0.257 D_fake: 0.079 
(epoch: 182, iters: 823, time: 0.603, data: 0.010) G_GAN: 0.917 G_L1: 8.675 D_real: 0.457 D_fake: 0.118 
learning rate 0.0000020 -&gt; 0.0000018
End of epoch 182 / 190   Time Taken: 378 sec
(epoch: 183, iters: 6, time: 0.603, data: 0.010) G_GAN: 0.934 G_L1: 6.291 D_real: 0.326 D_fake: 0.119 
(epoch: 183, iters: 56, time: 2.968, data: 0.010) G_GAN: 1.016 G_L1: 6.271 D_real: 0.301 D_fake: 0.083 
(epoch: 183, iters: 106, time: 0.549, data: 0.010) G_GAN: 1.082 G_L1: 6.087 D_real: 0.255 D_fake: 0.079 
(epoch: 183, iters: 156, time: 0.566, data: 0.009) G_GAN: 1.046 G_L1: 7.836 D_real: 0.316 D_fake: 0.159 
(epoch: 183, iters: 206, time: 0.591, data: 0.009) G_GAN: 0.808 G_L1: 8.604 D_real: 0.269 D_fake: 0.169 
(epoch: 183, iters: 256, time: 3.238, data: 0.012) G_GAN: 0.986 G_L1: 6.646 D_real: 0.276 D_fake: 0.083 
(epoch: 183, iters: 306, time: 0.587, data: 0.011) G_GAN: 0.955 G_L1: 6.027 D_real: 0.268 D_fake: 0.102 
(epoch: 183, iters: 356, time: 0.599, data: 0.011) G_GAN: 1.041 G_L1: 5.486 D_real: 0.236 D_fake: 0.091 
(epoch: 183, iters: 406, time: 0.602, data: 0.009) G_GAN: 0.943 G_L1: 6.795 D_real: 0.252 D_fake: 0.091 
(epoch: 183, iters: 456, time: 0.597, data: 0.009) G_GAN: 1.006 G_L1: 8.888 D_real: 0.259 D_fake: 0.128 
(epoch: 183, iters: 506, time: 0.599, data: 0.010) G_GAN: 1.042 G_L1: 6.040 D_real: 0.342 D_fake: 0.109 
(epoch: 183, iters: 556, time: 0.602, data: 0.010) G_GAN: 0.904 G_L1: 8.945 D_real: 0.300 D_fake: 0.136 
(epoch: 183, iters: 606, time: 0.604, data: 0.010) G_GAN: 0.941 G_L1: 8.459 D_real: 0.245 D_fake: 0.109 
(epoch: 183, iters: 656, time: 0.617, data: 0.010) G_GAN: 1.008 G_L1: 7.804 D_real: 0.273 D_fake: 0.124 
(epoch: 183, iters: 706, time: 0.589, data: 0.010) G_GAN: 1.103 G_L1: 6.811 D_real: 0.266 D_fake: 0.112 
(epoch: 183, iters: 756, time: 0.602, data: 0.011) G_GAN: 0.859 G_L1: 7.558 D_real: 0.306 D_fake: 0.129 
(epoch: 183, iters: 806, time: 0.561, data: 0.009) G_GAN: 1.250 G_L1: 6.216 D_real: 0.272 D_fake: 0.116 
(epoch: 183, iters: 856, time: 0.595, data: 0.011) G_GAN: 0.743 G_L1: 6.204 D_real: 0.275 D_fake: 0.134 
learning rate 0.0000018 -&gt; 0.0000015
End of epoch 183 / 190   Time Taken: 379 sec
(epoch: 184, iters: 39, time: 0.596, data: 0.011) G_GAN: 0.993 G_L1: 8.481 D_real: 0.317 D_fake: 0.111 
(epoch: 184, iters: 89, time: 0.602, data: 0.010) G_GAN: 0.848 G_L1: 8.185 D_real: 0.339 D_fake: 0.135 
(epoch: 184, iters: 139, time: 0.607, data: 0.012) G_GAN: 1.077 G_L1: 7.283 D_real: 0.281 D_fake: 0.118 
(epoch: 184, iters: 189, time: 2.957, data: 0.009) G_GAN: 1.187 G_L1: 7.597 D_real: 0.278 D_fake: 0.113 
(epoch: 184, iters: 239, time: 0.598, data: 0.011) G_GAN: 1.004 G_L1: 7.811 D_real: 0.262 D_fake: 0.074 
(epoch: 184, iters: 289, time: 0.596, data: 0.009) G_GAN: 1.001 G_L1: 5.789 D_real: 0.223 D_fake: 0.066 
(epoch: 184, iters: 339, time: 0.607, data: 0.009) G_GAN: 0.773 G_L1: 9.659 D_real: 0.320 D_fake: 0.166 
(epoch: 184, iters: 389, time: 2.996, data: 0.011) G_GAN: 1.044 G_L1: 7.008 D_real: 0.304 D_fake: 0.113 
(epoch: 184, iters: 439, time: 0.594, data: 0.010) G_GAN: 0.985 G_L1: 8.392 D_real: 0.286 D_fake: 0.123 
(epoch: 184, iters: 489, time: 0.586, data: 0.013) G_GAN: 0.974 G_L1: 6.349 D_real: 0.318 D_fake: 0.074 
(epoch: 184, iters: 539, time: 0.597, data: 0.010) G_GAN: 0.910 G_L1: 8.762 D_real: 0.259 D_fake: 0.126 
(epoch: 184, iters: 589, time: 0.591, data: 0.010) G_GAN: 0.959 G_L1: 7.133 D_real: 0.234 D_fake: 0.067 
(epoch: 184, iters: 639, time: 0.597, data: 0.009) G_GAN: 0.833 G_L1: 6.775 D_real: 0.245 D_fake: 0.129 
(epoch: 184, iters: 689, time: 0.565, data: 0.010) G_GAN: 0.941 G_L1: 7.452 D_real: 0.236 D_fake: 0.077 
(epoch: 184, iters: 739, time: 0.602, data: 0.010) G_GAN: 1.017 G_L1: 6.556 D_real: 0.269 D_fake: 0.092 
(epoch: 184, iters: 789, time: 0.599, data: 0.011) G_GAN: 0.988 G_L1: 6.659 D_real: 0.255 D_fake: 0.109 
(epoch: 184, iters: 839, time: 0.599, data: 0.010) G_GAN: 0.798 G_L1: 8.982 D_real: 0.304 D_fake: 0.120 
learning rate 0.0000015 -&gt; 0.0000013
End of epoch 184 / 190   Time Taken: 382 sec
(epoch: 185, iters: 22, time: 0.607, data: 0.009) G_GAN: 1.117 G_L1: 6.796 D_real: 0.290 D_fake: 0.132 
(epoch: 185, iters: 72, time: 0.599, data: 0.009) G_GAN: 1.054 G_L1: 6.557 D_real: 0.283 D_fake: 0.082 
(epoch: 185, iters: 122, time: 3.262, data: 0.010) G_GAN: 1.141 G_L1: 7.387 D_real: 0.223 D_fake: 0.065 
(epoch: 185, iters: 172, time: 0.861, data: 0.009) G_GAN: 0.704 G_L1: 7.416 D_real: 0.345 D_fake: 0.139 
(epoch: 185, iters: 222, time: 0.840, data: 0.058) G_GAN: 0.968 G_L1: 6.086 D_real: 0.246 D_fake: 0.089 
(epoch: 185, iters: 272, time: 0.964, data: 0.090) G_GAN: 0.978 G_L1: 5.713 D_real: 0.237 D_fake: 0.079 
(epoch: 185, iters: 322, time: 1.408, data: 0.154) G_GAN: 0.987 G_L1: 6.469 D_real: 0.281 D_fake: 0.086 
(epoch: 185, iters: 372, time: 0.601, data: 0.174) G_GAN: 1.032 G_L1: 5.996 D_real: 0.271 D_fake: 0.080 
(epoch: 185, iters: 422, time: 0.596, data: 0.011) G_GAN: 0.961 G_L1: 6.855 D_real: 0.230 D_fake: 0.067 
(epoch: 185, iters: 472, time: 0.603, data: 0.009) G_GAN: 1.018 G_L1: 5.493 D_real: 0.319 D_fake: 0.084 
(epoch: 185, iters: 522, time: 2.982, data: 0.010) G_GAN: 1.043 G_L1: 6.509 D_real: 0.233 D_fake: 0.082 
saving the latest model (epoch 185, total_iters 30000)
(epoch: 185, iters: 572, time: 0.590, data: 0.010) G_GAN: 0.837 G_L1: 6.533 D_real: 0.273 D_fake: 0.098 
(epoch: 185, iters: 622, time: 0.593, data: 0.011) G_GAN: 1.107 G_L1: 5.684 D_real: 0.236 D_fake: 0.070 
(epoch: 185, iters: 672, time: 0.587, data: 0.010) G_GAN: 1.189 G_L1: 7.325 D_real: 0.287 D_fake: 0.154 
(epoch: 185, iters: 722, time: 0.591, data: 0.013) G_GAN: 1.077 G_L1: 5.682 D_real: 0.293 D_fake: 0.125 
(epoch: 185, iters: 772, time: 0.551, data: 0.010) G_GAN: 1.008 G_L1: 6.656 D_real: 0.323 D_fake: 0.120 
(epoch: 185, iters: 822, time: 0.592, data: 0.010) G_GAN: 1.002 G_L1: 6.824 D_real: 0.233 D_fake: 0.069 
learning rate 0.0000013 -&gt; 0.0000011
saving the model at the end of epoch 185, iters 30345
End of epoch 185 / 190   Time Taken: 540 sec
(epoch: 186, iters: 5, time: 0.558, data: 0.010) G_GAN: 0.827 G_L1: 7.009 D_real: 0.299 D_fake: 0.135 
(epoch: 186, iters: 55, time: 2.902, data: 0.009) G_GAN: 1.271 G_L1: 6.320 D_real: 0.287 D_fake: 0.094 
(epoch: 186, iters: 105, time: 0.528, data: 0.010) G_GAN: 1.105 G_L1: 6.106 D_real: 0.258 D_fake: 0.071 
(epoch: 186, iters: 155, time: 0.530, data: 0.010) G_GAN: 0.939 G_L1: 8.678 D_real: 0.245 D_fake: 0.067 
(epoch: 186, iters: 205, time: 0.564, data: 0.009) G_GAN: 0.786 G_L1: 6.076 D_real: 0.262 D_fake: 0.119 
(epoch: 186, iters: 255, time: 0.578, data: 0.010) G_GAN: 0.968 G_L1: 7.300 D_real: 0.425 D_fake: 0.093 
(epoch: 186, iters: 305, time: 0.595, data: 0.010) G_GAN: 0.956 G_L1: 8.857 D_real: 0.225 D_fake: 0.089 
(epoch: 186, iters: 355, time: 0.566, data: 0.010) G_GAN: 1.076 G_L1: 5.888 D_real: 0.251 D_fake: 0.073 
(epoch: 186, iters: 405, time: 0.569, data: 0.009) G_GAN: 0.898 G_L1: 9.744 D_real: 0.258 D_fake: 0.090 
(epoch: 186, iters: 455, time: 0.567, data: 0.010) G_GAN: 1.172 G_L1: 7.038 D_real: 0.422 D_fake: 0.098 
(epoch: 186, iters: 505, time: 0.561, data: 0.010) G_GAN: 1.114 G_L1: 7.838 D_real: 0.277 D_fake: 0.105 
(epoch: 186, iters: 555, time: 0.573, data: 0.008) G_GAN: 0.874 G_L1: 5.955 D_real: 0.277 D_fake: 0.073 
(epoch: 186, iters: 605, time: 0.573, data: 0.009) G_GAN: 1.023 G_L1: 5.425 D_real: 0.218 D_fake: 0.071 
(epoch: 186, iters: 655, time: 2.815, data: 0.009) G_GAN: 0.960 G_L1: 9.355 D_real: 0.271 D_fake: 0.079 
(epoch: 186, iters: 705, time: 0.536, data: 0.012) G_GAN: 1.010 G_L1: 7.311 D_real: 0.238 D_fake: 0.070 
(epoch: 186, iters: 755, time: 0.567, data: 0.009) G_GAN: 0.911 G_L1: 6.856 D_real: 0.394 D_fake: 0.108 
(epoch: 186, iters: 805, time: 0.577, data: 0.008) G_GAN: 0.880 G_L1: 7.647 D_real: 0.252 D_fake: 0.089 
(epoch: 186, iters: 855, time: 0.573, data: 0.010) G_GAN: 1.122 G_L1: 5.657 D_real: 0.270 D_fake: 0.068 
learning rate 0.0000011 -&gt; 0.0000009
End of epoch 186 / 190   Time Taken: 348 sec
(epoch: 187, iters: 38, time: 0.555, data: 0.009) G_GAN: 0.885 G_L1: 9.350 D_real: 0.260 D_fake: 0.089 
(epoch: 187, iters: 88, time: 0.567, data: 0.009) G_GAN: 0.963 G_L1: 6.241 D_real: 0.288 D_fake: 0.074 
(epoch: 187, iters: 138, time: 0.569, data: 0.009) G_GAN: 0.919 G_L1: 7.223 D_real: 0.227 D_fake: 0.103 
(epoch: 187, iters: 188, time: 3.175, data: 0.010) G_GAN: 1.081 G_L1: 6.383 D_real: 0.237 D_fake: 0.061 
(epoch: 187, iters: 238, time: 0.569, data: 0.010) G_GAN: 1.013 G_L1: 6.150 D_real: 0.218 D_fake: 0.091 
(epoch: 187, iters: 288, time: 0.566, data: 0.009) G_GAN: 0.808 G_L1: 9.115 D_real: 0.274 D_fake: 0.132 
(epoch: 187, iters: 338, time: 0.586, data: 0.010) G_GAN: 0.773 G_L1: 9.067 D_real: 0.314 D_fake: 0.118 
(epoch: 187, iters: 388, time: 0.554, data: 0.009) G_GAN: 0.855 G_L1: 6.111 D_real: 0.283 D_fake: 0.081 
(epoch: 187, iters: 438, time: 0.585, data: 0.011) G_GAN: 0.946 G_L1: 5.802 D_real: 0.260 D_fake: 0.075 
(epoch: 187, iters: 488, time: 0.575, data: 0.010) G_GAN: 0.962 G_L1: 6.499 D_real: 0.205 D_fake: 0.077 
(epoch: 187, iters: 538, time: 0.579, data: 0.009) G_GAN: 0.965 G_L1: 6.140 D_real: 0.213 D_fake: 0.070 
(epoch: 187, iters: 588, time: 0.571, data: 0.010) G_GAN: 1.052 G_L1: 6.614 D_real: 0.263 D_fake: 0.071 
(epoch: 187, iters: 638, time: 0.569, data: 0.010) G_GAN: 0.878 G_L1: 5.615 D_real: 0.311 D_fake: 0.100 
(epoch: 187, iters: 688, time: 0.572, data: 0.010) G_GAN: 0.756 G_L1: 8.678 D_real: 0.274 D_fake: 0.124 
(epoch: 187, iters: 738, time: 0.532, data: 0.009) G_GAN: 0.819 G_L1: 7.815 D_real: 0.278 D_fake: 0.107 
(epoch: 187, iters: 788, time: 2.881, data: 0.009) G_GAN: 0.773 G_L1: 6.145 D_real: 0.306 D_fake: 0.109 
(epoch: 187, iters: 838, time: 0.576, data: 0.009) G_GAN: 0.936 G_L1: 5.873 D_real: 0.246 D_fake: 0.080 
learning rate 0.0000009 -&gt; 0.0000007
End of epoch 187 / 190   Time Taken: 351 sec
(epoch: 188, iters: 21, time: 0.549, data: 0.010) G_GAN: 1.049 G_L1: 7.145 D_real: 0.356 D_fake: 0.139 
(epoch: 188, iters: 71, time: 0.574, data: 0.010) G_GAN: 0.826 G_L1: 6.811 D_real: 0.294 D_fake: 0.128 
(epoch: 188, iters: 121, time: 2.816, data: 0.011) G_GAN: 1.025 G_L1: 8.480 D_real: 0.356 D_fake: 0.069 
(epoch: 188, iters: 171, time: 0.579, data: 0.010) G_GAN: 0.928 G_L1: 5.834 D_real: 0.257 D_fake: 0.093 
(epoch: 188, iters: 221, time: 0.589, data: 0.009) G_GAN: 1.049 G_L1: 10.423 D_real: 0.259 D_fake: 0.135 
(epoch: 188, iters: 271, time: 0.561, data: 0.011) G_GAN: 0.817 G_L1: 6.759 D_real: 0.234 D_fake: 0.108 
(epoch: 188, iters: 321, time: 0.580, data: 0.009) G_GAN: 0.783 G_L1: 8.081 D_real: 0.283 D_fake: 0.117 
(epoch: 188, iters: 371, time: 0.571, data: 0.010) G_GAN: 1.003 G_L1: 6.480 D_real: 0.227 D_fake: 0.122 
(epoch: 188, iters: 421, time: 0.580, data: 0.009) G_GAN: 1.110 G_L1: 6.130 D_real: 0.279 D_fake: 0.149 
(epoch: 188, iters: 471, time: 0.581, data: 0.010) G_GAN: 0.786 G_L1: 7.205 D_real: 0.264 D_fake: 0.116 
(epoch: 188, iters: 521, time: 0.567, data: 0.010) G_GAN: 1.003 G_L1: 6.466 D_real: 0.296 D_fake: 0.141 
(epoch: 188, iters: 571, time: 0.565, data: 0.009) G_GAN: 0.922 G_L1: 6.447 D_real: 0.222 D_fake: 0.071 
(epoch: 188, iters: 621, time: 0.565, data: 0.009) G_GAN: 0.938 G_L1: 5.570 D_real: 0.276 D_fake: 0.073 
(epoch: 188, iters: 671, time: 0.567, data: 0.009) G_GAN: 0.944 G_L1: 7.775 D_real: 0.269 D_fake: 0.091 
(epoch: 188, iters: 721, time: 0.556, data: 0.010) G_GAN: 1.107 G_L1: 7.497 D_real: 0.304 D_fake: 0.109 
(epoch: 188, iters: 771, time: 0.589, data: 0.010) G_GAN: 0.921 G_L1: 5.456 D_real: 0.257 D_fake: 0.069 
(epoch: 188, iters: 821, time: 0.585, data: 0.009) G_GAN: 0.764 G_L1: 9.376 D_real: 0.281 D_fake: 0.138 
learning rate 0.0000007 -&gt; 0.0000004
End of epoch 188 / 190   Time Taken: 352 sec
(epoch: 189, iters: 4, time: 0.506, data: 0.009) G_GAN: 0.883 G_L1: 5.392 D_real: 0.266 D_fake: 0.086 
(epoch: 189, iters: 54, time: 2.847, data: 0.011) G_GAN: 0.816 G_L1: 6.289 D_real: 0.256 D_fake: 0.094 
(epoch: 189, iters: 104, time: 0.554, data: 0.010) G_GAN: 0.930 G_L1: 7.123 D_real: 0.261 D_fake: 0.086 
(epoch: 189, iters: 154, time: 0.595, data: 0.011) G_GAN: 0.971 G_L1: 7.390 D_real: 0.244 D_fake: 0.082 
(epoch: 189, iters: 204, time: 0.595, data: 0.010) G_GAN: 0.815 G_L1: 7.763 D_real: 0.261 D_fake: 0.111 
(epoch: 189, iters: 254, time: 0.586, data: 0.010) G_GAN: 0.954 G_L1: 5.233 D_real: 0.234 D_fake: 0.081 
(epoch: 189, iters: 304, time: 0.531, data: 0.012) G_GAN: 0.798 G_L1: 7.819 D_real: 0.240 D_fake: 0.126 
(epoch: 189, iters: 354, time: 0.530, data: 0.008) G_GAN: 0.920 G_L1: 7.350 D_real: 0.255 D_fake: 0.082 
(epoch: 189, iters: 404, time: 0.527, data: 0.010) G_GAN: 0.883 G_L1: 7.573 D_real: 0.310 D_fake: 0.104 
(epoch: 189, iters: 454, time: 0.554, data: 0.009) G_GAN: 0.778 G_L1: 5.607 D_real: 0.350 D_fake: 0.137 
(epoch: 189, iters: 504, time: 0.533, data: 0.009) G_GAN: 0.814 G_L1: 8.996 D_real: 0.246 D_fake: 0.126 
(epoch: 189, iters: 554, time: 0.578, data: 0.011) G_GAN: 0.871 G_L1: 5.750 D_real: 0.216 D_fake: 0.081 
(epoch: 189, iters: 604, time: 0.576, data: 0.010) G_GAN: 0.695 G_L1: 7.355 D_real: 0.357 D_fake: 0.153 
(epoch: 189, iters: 654, time: 0.562, data: 0.010) G_GAN: 0.658 G_L1: 8.858 D_real: 0.278 D_fake: 0.174 
(epoch: 189, iters: 704, time: 0.568, data: 0.010) G_GAN: 0.920 G_L1: 7.211 D_real: 0.326 D_fake: 0.102 
(epoch: 189, iters: 754, time: 0.561, data: 0.010) G_GAN: 0.917 G_L1: 7.782 D_real: 0.229 D_fake: 0.089 
(epoch: 189, iters: 804, time: 0.569, data: 0.009) G_GAN: 1.144 G_L1: 7.666 D_real: 0.222 D_fake: 0.077 
(epoch: 189, iters: 854, time: 0.571, data: 0.009) G_GAN: 0.983 G_L1: 5.837 D_real: 0.292 D_fake: 0.081 
learning rate 0.0000004 -&gt; 0.0000002
End of epoch 189 / 190   Time Taken: 338 sec
(epoch: 190, iters: 37, time: 0.562, data: 0.011) G_GAN: 0.881 G_L1: 6.656 D_real: 0.302 D_fake: 0.102 
(epoch: 190, iters: 87, time: 0.565, data: 0.010) G_GAN: 0.812 G_L1: 6.251 D_real: 0.239 D_fake: 0.097 
(epoch: 190, iters: 137, time: 0.570, data: 0.009) G_GAN: 0.900 G_L1: 6.994 D_real: 0.355 D_fake: 0.128 
(epoch: 190, iters: 187, time: 2.905, data: 0.009) G_GAN: 1.287 G_L1: 5.170 D_real: 0.348 D_fake: 0.172 
(epoch: 190, iters: 237, time: 0.533, data: 0.010) G_GAN: 0.985 G_L1: 6.546 D_real: 0.272 D_fake: 0.083 
(epoch: 190, iters: 287, time: 0.534, data: 0.009) G_GAN: 1.067 G_L1: 6.492 D_real: 0.284 D_fake: 0.169 
(epoch: 190, iters: 337, time: 0.535, data: 0.009) G_GAN: 1.031 G_L1: 7.803 D_real: 0.254 D_fake: 0.086 
(epoch: 190, iters: 387, time: 0.585, data: 0.009) G_GAN: 0.877 G_L1: 6.922 D_real: 0.243 D_fake: 0.090 
(epoch: 190, iters: 437, time: 0.725, data: 0.009) G_GAN: 0.883 G_L1: 8.097 D_real: 0.276 D_fake: 0.099 
(epoch: 190, iters: 487, time: 0.783, data: 0.115) G_GAN: 0.963 G_L1: 5.304 D_real: 0.262 D_fake: 0.078 
(epoch: 190, iters: 537, time: 0.786, data: 0.075) G_GAN: 0.881 G_L1: 6.197 D_real: 0.211 D_fake: 0.095 
(epoch: 190, iters: 587, time: 0.510, data: 0.102) G_GAN: 1.028 G_L1: 5.836 D_real: 0.382 D_fake: 0.074 
(epoch: 190, iters: 637, time: 0.581, data: 0.009) G_GAN: 0.965 G_L1: 5.612 D_real: 0.239 D_fake: 0.084 
(epoch: 190, iters: 687, time: 0.571, data: 0.009) G_GAN: 1.161 G_L1: 6.880 D_real: 0.249 D_fake: 0.104 
(epoch: 190, iters: 737, time: 0.561, data: 0.009) G_GAN: 0.951 G_L1: 6.596 D_real: 0.303 D_fake: 0.128 
(epoch: 190, iters: 787, time: 0.562, data: 0.009) G_GAN: 1.032 G_L1: 6.921 D_real: 0.199 D_fake: 0.072 
(epoch: 190, iters: 837, time: 0.588, data: 0.009) G_GAN: 0.984 G_L1: 6.528 D_real: 0.308 D_fake: 0.082 
learning rate 0.0000002 -&gt; 0.0000000
saving the model at the end of epoch 190, iters 34680
End of epoch 190 / 190   Time Taken: 431 sec
</code></pre>
</div>
</div>
<div id="299e0d1f-fb20-40a6-835c-5fcddbb78b45" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, subprocess, shlex</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"TORCHINDUCTOR_DISABLE"</span>] <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"TORCH_COMPILE_DISABLE"</span>]  <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"TORCHDYNAMO_DISABLE"</span>]    <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co"># === CONFIG ===</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>repo_dir <span class="op">=</span> <span class="vs">r"C:</span><span class="er">\</span><span class="vs">Users</span><span class="er">\</span><span class="vs">yalda</span><span class="er">\</span><span class="vs">OneDrive</span><span class="dv">\D</span><span class="vs">esktop</span><span class="er">\</span><span class="vs">Thesis apps</span><span class="er">\</span><span class="vs">Project Folder</span><span class="er">\</span><span class="vs">pytorch-CycleGAN-and-pix2pix"</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>dataroot <span class="op">=</span> os.path.join(repo_dir, <span class="st">"datasets"</span>, <span class="st">"stopmotion_pix2pix"</span>)  </span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>exp_name <span class="op">=</span> <span class="st">"stopmotion_pix2pix_1024"</span>   </span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>epoch <span class="op">=</span> <span class="st">"46"</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>gpu_ids <span class="op">=</span> <span class="st">"0"</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>num_test <span class="op">=</span> <span class="st">"1000"</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>os.chdir(repo_dir)</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CWD:"</span>, os.getcwd())</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>cmd <span class="op">=</span> <span class="ss">f'python test.py --dataroot "</span><span class="sc">{</span>dataroot<span class="sc">}</span><span class="ss">" --name </span><span class="sc">{</span>exp_name<span class="sc">}</span><span class="ss"> --model pix2pix --direction AtoB --epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss"> --num_test </span><span class="sc">{</span>num_test<span class="sc">}</span><span class="ss"> --gpu_ids </span><span class="sc">{</span>gpu_ids<span class="sc">}</span><span class="ss"> --results_dir "</span><span class="sc">{</span>os<span class="sc">.</span>path<span class="sc">.</span>join(repo_dir, <span class="st">"results"</span>)<span class="sc">}</span><span class="ss">" --load_size 1024 --crop_size 1024'</span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Running:"</span>, cmd)</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>proc <span class="op">=</span> subprocess.run(shlex.split(cmd), stdout<span class="op">=</span>subprocess.PIPE, stderr<span class="op">=</span>subprocess.STDOUT, text<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(proc.stdout)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>CWD: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix
Running: python test.py --dataroot "C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\datasets\stopmotion_pix2pix" --name stopmotion_pix2pix_1024 --model pix2pix --direction AtoB --epoch 46 --num_test 1000 --gpu_ids 0 --results_dir "C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results" --load_size 1024 --crop_size 1024
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
----------------- Options ---------------
             aspect_ratio: 1.0                           
               batch_size: 1                             
          checkpoints_dir: ./checkpoints                 
                crop_size: 1024                             [default: 256]
                 dataroot: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\datasets\stopmotion_pix2pix  [default: None]
             dataset_mode: aligned                       
                direction: AtoB                          
          display_winsize: 256                           
                    epoch: 46                               [default: latest]
                     eval: False                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: False                            [default: None]
                load_iter: 0                                [default: 0]
                load_size: 1024                             [default: 256]
         max_dataset_size: inf                           
                    model: pix2pix                          [default: test]
               n_layers_D: 3                             
                     name: stopmotion_pix2pix_1024          [default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: unet_256                      
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: False                         
                     norm: batch                         
                 num_test: 1000                             [default: 50]
              num_threads: 4                             
                output_nc: 3                             
                    phase: test                          
               preprocess: resize_and_crop               
              results_dir: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results  [default: ./results/]
           serial_batches: False                         
                   suffix:                               
                use_wandb: False                         
                  verbose: False                         
       wandb_project_name: CycleGAN-and-pix2pix          
----------------- End -------------------
dataset [AlignedDataset] was created
initialize network with normal
model [Pix2PixModel] was created
loading the model from checkpoints\stopmotion_pix2pix_1024\46_net_G.pth
---------- Networks initialized -------------
[Network G] Total number of parameters : 54.414 M
-----------------------------------------------
[Network G] compiled with torch.compile
creating web directory C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results\stopmotion_pix2pix_1024\test_46
processing (0000)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_Hiphopdancing_20003.png']
processing (0005)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_Hiphopdancing_20049.png']
processing (0010)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20060.png']
processing (0015)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20087.png']
processing (0020)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20137.png']
processing (0025)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20210.png']
processing (0030)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20260.png']
processing (0035)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20313.png']
processing (0040)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_sittinglaughing_20034.png']
processing (0045)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_sittinglaughing_20124.png']
processing (0050)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_walking_20030.png']
processing (0055)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Hiphopdancing_20057.png']
processing (0060)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Sittinglaughing_20026.png']
processing (0065)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Sittinglaughing_20081.png']
processing (0070)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Sittinglaughing_20114.png']
processing (0075)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_dying_20002.png']
processing (0080)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_dying_20046.png']
processing (0085)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_dying_20068.png']
processing (0090)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_sittingcrawling_20016.png']
processing (0095)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_sittingcrawling_20031.png']
</code></pre>
</div>
</div>
<div id="a03ad1be-3f45-4c35-90dc-9d0be7603faa" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, subprocess, shlex</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"TORCHINDUCTOR_DISABLE"</span>] <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"TORCH_COMPILE_DISABLE"</span>]  <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"TORCHDYNAMO_DISABLE"</span>]    <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co"># === CONFIG ===</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>repo_dir <span class="op">=</span> <span class="vs">r"C:</span><span class="er">\</span><span class="vs">Users</span><span class="er">\</span><span class="vs">yalda</span><span class="er">\</span><span class="vs">OneDrive</span><span class="dv">\D</span><span class="vs">esktop</span><span class="er">\</span><span class="vs">Thesis apps</span><span class="er">\</span><span class="vs">Project Folder</span><span class="er">\</span><span class="vs">pytorch-CycleGAN-and-pix2pix"</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>dataroot <span class="op">=</span> os.path.join(repo_dir, <span class="st">"datasets"</span>, <span class="st">"stopmotion_pix2pix"</span>)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>exp_name <span class="op">=</span> <span class="st">"stopmotion_pix2pix_1024"</span> </span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>epoch <span class="op">=</span> <span class="st">"190"</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>gpu_ids <span class="op">=</span> <span class="st">"0"</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>num_test <span class="op">=</span> <span class="st">"1000"</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>os.chdir(repo_dir)</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CWD:"</span>, os.getcwd())</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>cmd <span class="op">=</span> <span class="ss">f'python test.py --dataroot "</span><span class="sc">{</span>dataroot<span class="sc">}</span><span class="ss">" --name </span><span class="sc">{</span>exp_name<span class="sc">}</span><span class="ss"> --model pix2pix --direction AtoB --epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss"> --num_test </span><span class="sc">{</span>num_test<span class="sc">}</span><span class="ss"> --gpu_ids </span><span class="sc">{</span>gpu_ids<span class="sc">}</span><span class="ss"> --results_dir "</span><span class="sc">{</span>os<span class="sc">.</span>path<span class="sc">.</span>join(repo_dir, <span class="st">"results"</span>)<span class="sc">}</span><span class="ss">" --load_size 1024 --crop_size 1024'</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Running:"</span>, cmd)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>proc <span class="op">=</span> subprocess.run(shlex.split(cmd), stdout<span class="op">=</span>subprocess.PIPE, stderr<span class="op">=</span>subprocess.STDOUT, text<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(proc.stdout)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>CWD: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix
Running: python test.py --dataroot "C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\datasets\stopmotion_pix2pix" --name stopmotion_pix2pix_1024 --model pix2pix --direction AtoB --epoch 190 --num_test 1000 --gpu_ids 0 --results_dir "C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results" --load_size 1024 --crop_size 1024
C:\Users\yalda\anaconda3\envs\cyclegan_env\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
----------------- Options ---------------
             aspect_ratio: 1.0                           
               batch_size: 1                             
          checkpoints_dir: ./checkpoints                 
                crop_size: 1024                             [default: 256]
                 dataroot: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\datasets\stopmotion_pix2pix  [default: None]
             dataset_mode: aligned                       
                direction: AtoB                          
          display_winsize: 256                           
                    epoch: 190                              [default: latest]
                     eval: False                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: False                            [default: None]
                load_iter: 0                                [default: 0]
                load_size: 1024                             [default: 256]
         max_dataset_size: inf                           
                    model: pix2pix                          [default: test]
               n_layers_D: 3                             
                     name: stopmotion_pix2pix_1024          [default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: unet_256                      
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: False                         
                     norm: batch                         
                 num_test: 1000                             [default: 50]
              num_threads: 4                             
                output_nc: 3                             
                    phase: test                          
               preprocess: resize_and_crop               
              results_dir: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results  [default: ./results/]
           serial_batches: False                         
                   suffix:                               
                use_wandb: False                         
                  verbose: False                         
       wandb_project_name: CycleGAN-and-pix2pix          
----------------- End -------------------
dataset [AlignedDataset] was created
initialize network with normal
model [Pix2PixModel] was created
loading the model from checkpoints\stopmotion_pix2pix_1024\190_net_G.pth
---------- Networks initialized -------------
[Network G] Total number of parameters : 54.414 M
-----------------------------------------------
[Network G] compiled with torch.compile
creating web directory C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix\results\stopmotion_pix2pix_1024\test_190
processing (0000)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_Hiphopdancing_20003.png']
processing (0005)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_Hiphopdancing_20049.png']
processing (0010)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20060.png']
processing (0015)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20087.png']
processing (0020)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20137.png']
processing (0025)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20210.png']
processing (0030)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20260.png']
processing (0035)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_falling_20313.png']
processing (0040)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_sittinglaughing_20034.png']
processing (0045)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_sittinglaughing_20124.png']
processing (0050)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter1_walking_20030.png']
processing (0055)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Hiphopdancing_20057.png']
processing (0060)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Sittinglaughing_20026.png']
processing (0065)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Sittinglaughing_20081.png']
processing (0070)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_Sittinglaughing_20114.png']
processing (0075)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_dying_20002.png']
processing (0080)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_dying_20046.png']
processing (0085)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_dying_20068.png']
processing (0090)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_sittingcrawling_20016.png']
processing (0095)-th image... ['C:\\Users\\yalda\\OneDrive\\Desktop\\Thesis apps\\Project Folder\\pytorch-CycleGAN-and-pix2pix\\datasets\\stopmotion_pix2pix\\test\\Charecter2_sittingcrawling_20031.png']
</code></pre>
</div>
</div>
<div id="3aa323de-44bb-45bd-925e-6ff0100f94d8" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, shlex, subprocess</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>repo_dir <span class="op">=</span> <span class="vs">r"C:</span><span class="er">\</span><span class="vs">Users</span><span class="er">\</span><span class="vs">yalda</span><span class="er">\</span><span class="vs">OneDrive</span><span class="dv">\D</span><span class="vs">esktop</span><span class="er">\</span><span class="vs">Thesis apps</span><span class="er">\</span><span class="vs">Project Folder</span><span class="er">\</span><span class="vs">pytorch-CycleGAN-and-pix2pix"</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>os.chdir(repo_dir)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CWD:"</span>, os.getcwd())</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>cmd <span class="op">=</span> <span class="vs">r"""</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="vs">python train</span><span class="dv">.</span><span class="vs">py</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="vs">--dataroot </span><span class="dv">.</span><span class="vs">/datasets/stopmotion_pix2pix</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="vs">--name stopmotion_pix2pix_1024</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="vs">--model pix2pix</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="vs">--dataset_mode aligned</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="vs">--direction AtoB</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="vs">--input_nc 3</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="vs">--output_nc 3</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="vs">--netG unet_256</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="vs">--lambda_L1 100</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a><span class="vs">--gan_mode lsgan</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a><span class="vs">--preprocess resize_and_crop</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="vs">--load_size 1088</span></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a><span class="vs">--crop_size 1024</span></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="vs">--batch_size 1</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="vs">--gpu_ids 0</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a><span class="vs">--continue_train</span></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a><span class="vs">--epoch 46</span></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a><span class="vs">--epoch_count 47</span></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a><span class="vs">--lr 0</span><span class="dv">.</span><span class="vs">00005</span></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a><span class="vs">--n_epochs 20</span></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a><span class="vs">--n_epochs_decay 40</span></span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a><span class="vs">--save_epoch_freq 2</span></span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a><span class="vs">--print_freq 50</span></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a><span class="vs">--display_freq 200</span></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a><span class="vs">"""</span></span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>proc <span class="op">=</span> subprocess.run(shlex.split(<span class="st">" "</span>.join(cmd.split())), stdout<span class="op">=</span>subprocess.PIPE, stderr<span class="op">=</span>subprocess.STDOUT, text<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(proc.stdout)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>CWD: C:\Users\yalda\OneDrive\Desktop\Thesis apps\Project Folder\pytorch-CycleGAN-and-pix2pix</code></pre>
</div>
</div>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>